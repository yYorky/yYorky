{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91719,"databundleVersionId":12937777,"sourceType":"competition"},{"sourceId":9293783,"sourceType":"datasetVersion","datasetId":5626665}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T06:45:28.197602Z","iopub.execute_input":"2025-08-25T06:45:28.198162Z","iopub.status.idle":"2025-08-25T06:45:28.461163Z","shell.execute_reply.started":"2025-08-25T06:45:28.198134Z","shell.execute_reply":"2025-08-25T06:45:28.460395Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# Load Dataset","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/playground-series-s5e8/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/playground-series-s5e8/test.csv\")\nsubmission = pd.read_csv(\"/kaggle/input/playground-series-s5e8/sample_submission.csv\")\n\ntrain.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T06:45:28.462452Z","iopub.execute_input":"2025-08-25T06:45:28.462842Z","iopub.status.idle":"2025-08-25T06:45:30.876723Z","shell.execute_reply.started":"2025-08-25T06:45:28.462813Z","shell.execute_reply":"2025-08-25T06:45:30.876091Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   id  age          job  marital  education default  balance housing loan  \\\n0   0   42   technician  married  secondary      no        7      no   no   \n1   1   38  blue-collar  married  secondary      no      514      no   no   \n2   2   36  blue-collar  married  secondary      no      602     yes   no   \n3   3   27      student   single  secondary      no       34     yes   no   \n4   4   26   technician  married  secondary      no      889     yes   no   \n\n    contact  day month  duration  campaign  pdays  previous poutcome  y  \n0  cellular   25   aug       117         3     -1         0  unknown  0  \n1   unknown   18   jun       185         1     -1         0  unknown  0  \n2   unknown   14   may       111         2     -1         0  unknown  0  \n3   unknown   28   may        10         2     -1         0  unknown  0  \n4  cellular    3   feb       902         1     -1         0  unknown  1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>age</th>\n      <th>job</th>\n      <th>marital</th>\n      <th>education</th>\n      <th>default</th>\n      <th>balance</th>\n      <th>housing</th>\n      <th>loan</th>\n      <th>contact</th>\n      <th>day</th>\n      <th>month</th>\n      <th>duration</th>\n      <th>campaign</th>\n      <th>pdays</th>\n      <th>previous</th>\n      <th>poutcome</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>42</td>\n      <td>technician</td>\n      <td>married</td>\n      <td>secondary</td>\n      <td>no</td>\n      <td>7</td>\n      <td>no</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>25</td>\n      <td>aug</td>\n      <td>117</td>\n      <td>3</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>38</td>\n      <td>blue-collar</td>\n      <td>married</td>\n      <td>secondary</td>\n      <td>no</td>\n      <td>514</td>\n      <td>no</td>\n      <td>no</td>\n      <td>unknown</td>\n      <td>18</td>\n      <td>jun</td>\n      <td>185</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>36</td>\n      <td>blue-collar</td>\n      <td>married</td>\n      <td>secondary</td>\n      <td>no</td>\n      <td>602</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>unknown</td>\n      <td>14</td>\n      <td>may</td>\n      <td>111</td>\n      <td>2</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>27</td>\n      <td>student</td>\n      <td>single</td>\n      <td>secondary</td>\n      <td>no</td>\n      <td>34</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>unknown</td>\n      <td>28</td>\n      <td>may</td>\n      <td>10</td>\n      <td>2</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>26</td>\n      <td>technician</td>\n      <td>married</td>\n      <td>secondary</td>\n      <td>no</td>\n      <td>889</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>3</td>\n      <td>feb</td>\n      <td>902</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"train.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T06:45:30.877683Z","iopub.execute_input":"2025-08-25T06:45:30.877914Z","iopub.status.idle":"2025-08-25T06:45:31.063618Z","shell.execute_reply.started":"2025-08-25T06:45:30.877889Z","shell.execute_reply":"2025-08-25T06:45:31.062976Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                  id            age        balance            day  \\\ncount  750000.000000  750000.000000  750000.000000  750000.000000   \nmean   374999.500000      40.926395    1204.067397      16.117209   \nstd    216506.495284      10.098829    2836.096759       8.250832   \nmin         0.000000      18.000000   -8019.000000       1.000000   \n25%    187499.750000      33.000000       0.000000       9.000000   \n50%    374999.500000      39.000000     634.000000      17.000000   \n75%    562499.250000      48.000000    1390.000000      21.000000   \nmax    749999.000000      95.000000   99717.000000      31.000000   \n\n            duration       campaign          pdays       previous  \\\ncount  750000.000000  750000.000000  750000.000000  750000.000000   \nmean      256.229144       2.577008      22.412733       0.298545   \nstd       272.555662       2.718514      77.319998       1.335926   \nmin         1.000000       1.000000      -1.000000       0.000000   \n25%        91.000000       1.000000      -1.000000       0.000000   \n50%       133.000000       2.000000      -1.000000       0.000000   \n75%       361.000000       3.000000      -1.000000       0.000000   \nmax      4918.000000      63.000000     871.000000     200.000000   \n\n                   y  \ncount  750000.000000  \nmean        0.120651  \nstd         0.325721  \nmin         0.000000  \n25%         0.000000  \n50%         0.000000  \n75%         0.000000  \nmax         1.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>age</th>\n      <th>balance</th>\n      <th>day</th>\n      <th>duration</th>\n      <th>campaign</th>\n      <th>pdays</th>\n      <th>previous</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>750000.000000</td>\n      <td>750000.000000</td>\n      <td>750000.000000</td>\n      <td>750000.000000</td>\n      <td>750000.000000</td>\n      <td>750000.000000</td>\n      <td>750000.000000</td>\n      <td>750000.000000</td>\n      <td>750000.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>374999.500000</td>\n      <td>40.926395</td>\n      <td>1204.067397</td>\n      <td>16.117209</td>\n      <td>256.229144</td>\n      <td>2.577008</td>\n      <td>22.412733</td>\n      <td>0.298545</td>\n      <td>0.120651</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>216506.495284</td>\n      <td>10.098829</td>\n      <td>2836.096759</td>\n      <td>8.250832</td>\n      <td>272.555662</td>\n      <td>2.718514</td>\n      <td>77.319998</td>\n      <td>1.335926</td>\n      <td>0.325721</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>18.000000</td>\n      <td>-8019.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>-1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>187499.750000</td>\n      <td>33.000000</td>\n      <td>0.000000</td>\n      <td>9.000000</td>\n      <td>91.000000</td>\n      <td>1.000000</td>\n      <td>-1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>374999.500000</td>\n      <td>39.000000</td>\n      <td>634.000000</td>\n      <td>17.000000</td>\n      <td>133.000000</td>\n      <td>2.000000</td>\n      <td>-1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>562499.250000</td>\n      <td>48.000000</td>\n      <td>1390.000000</td>\n      <td>21.000000</td>\n      <td>361.000000</td>\n      <td>3.000000</td>\n      <td>-1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>749999.000000</td>\n      <td>95.000000</td>\n      <td>99717.000000</td>\n      <td>31.000000</td>\n      <td>4918.000000</td>\n      <td>63.000000</td>\n      <td>871.000000</td>\n      <td>200.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"## Merge train with original data and remove duplicates","metadata":{}},{"cell_type":"code","source":"orig = pd.read_csv(\"/kaggle/input/bank-marketing-dataset-full/bank-full.csv\", sep=';')\norig['y'] = orig['y'].map({'no': 0, 'yes': 1})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T06:45:31.064608Z","iopub.execute_input":"2025-08-25T06:45:31.064792Z","iopub.status.idle":"2025-08-25T06:45:31.165412Z","shell.execute_reply.started":"2025-08-25T06:45:31.064776Z","shell.execute_reply":"2025-08-25T06:45:31.164844Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"train = pd.concat([train, orig], ignore_index=True)\ntrain = train.drop_duplicates()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T06:45:31.167029Z","iopub.execute_input":"2025-08-25T06:45:31.167256Z","iopub.status.idle":"2025-08-25T06:45:32.261596Z","shell.execute_reply.started":"2025-08-25T06:45:31.167239Z","shell.execute_reply":"2025-08-25T06:45:32.260994Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"train.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T06:45:32.262269Z","iopub.execute_input":"2025-08-25T06:45:32.262478Z","iopub.status.idle":"2025-08-25T06:45:32.457883Z","shell.execute_reply.started":"2025-08-25T06:45:32.262460Z","shell.execute_reply":"2025-08-25T06:45:32.457103Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                  id            age        balance            day  \\\ncount  750000.000000  795211.000000  795211.000000  795211.000000   \nmean   374999.500000      40.926953    1213.061980      16.099540   \nstd    216506.495284      10.129098    2848.603881       8.255231   \nmin         0.000000      18.000000   -8019.000000       1.000000   \n25%    187499.750000      33.000000       0.000000       9.000000   \n50%    374999.500000      39.000000     624.000000      17.000000   \n75%    562499.250000      48.000000    1390.000000      21.000000   \nmax    749999.000000      95.000000  102127.000000      31.000000   \n\n            duration       campaign          pdays       previous  \\\ncount  795211.000000  795211.000000  795211.000000  795211.000000   \nmean      256.339096       2.587630      23.423889       0.314566   \nstd       271.723766       2.741838      78.901465       1.410369   \nmin         0.000000       1.000000      -1.000000       0.000000   \n25%        91.000000       1.000000      -1.000000       0.000000   \n50%       135.000000       2.000000      -1.000000       0.000000   \n75%       347.500000       3.000000      -1.000000       0.000000   \nmax      4918.000000      63.000000     871.000000     275.000000   \n\n                   y  \ncount  795211.000000  \nmean        0.120442  \nstd         0.325478  \nmin         0.000000  \n25%         0.000000  \n50%         0.000000  \n75%         0.000000  \nmax         1.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>age</th>\n      <th>balance</th>\n      <th>day</th>\n      <th>duration</th>\n      <th>campaign</th>\n      <th>pdays</th>\n      <th>previous</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>750000.000000</td>\n      <td>795211.000000</td>\n      <td>795211.000000</td>\n      <td>795211.000000</td>\n      <td>795211.000000</td>\n      <td>795211.000000</td>\n      <td>795211.000000</td>\n      <td>795211.000000</td>\n      <td>795211.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>374999.500000</td>\n      <td>40.926953</td>\n      <td>1213.061980</td>\n      <td>16.099540</td>\n      <td>256.339096</td>\n      <td>2.587630</td>\n      <td>23.423889</td>\n      <td>0.314566</td>\n      <td>0.120442</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>216506.495284</td>\n      <td>10.129098</td>\n      <td>2848.603881</td>\n      <td>8.255231</td>\n      <td>271.723766</td>\n      <td>2.741838</td>\n      <td>78.901465</td>\n      <td>1.410369</td>\n      <td>0.325478</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>18.000000</td>\n      <td>-8019.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>-1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>187499.750000</td>\n      <td>33.000000</td>\n      <td>0.000000</td>\n      <td>9.000000</td>\n      <td>91.000000</td>\n      <td>1.000000</td>\n      <td>-1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>374999.500000</td>\n      <td>39.000000</td>\n      <td>624.000000</td>\n      <td>17.000000</td>\n      <td>135.000000</td>\n      <td>2.000000</td>\n      <td>-1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>562499.250000</td>\n      <td>48.000000</td>\n      <td>1390.000000</td>\n      <td>21.000000</td>\n      <td>347.500000</td>\n      <td>3.000000</td>\n      <td>-1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>749999.000000</td>\n      <td>95.000000</td>\n      <td>102127.000000</td>\n      <td>31.000000</td>\n      <td>4918.000000</td>\n      <td>63.000000</td>\n      <td>871.000000</td>\n      <td>275.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"markdown","source":"## Quick structure + target, duplicates, missing/“unknown”","metadata":{}},{"cell_type":"code","source":"TARGET = \"y\"\nID_COL = \"id\"\n\nfeat_cols = [c for c in train.columns if c not in [TARGET, ID_COL]]\nnum_cols = train[feat_cols].select_dtypes(include=[\"number\"]).columns.tolist()\ncat_cols = [c for c in feat_cols if c not in num_cols]\n\nprint(\"Shape:\", train.shape, \"| Test:\", test.shape)\nprint(\"\\nDtypes\\n\", train.dtypes)\n\n# Target balance\nprint(\"\\nTarget distribution\")\nprint(train[TARGET].value_counts().rename(\"count\"))\nprint((train[TARGET].value_counts(normalize=True)*100).round(2).rename(\"pct %\"))\n\n# Duplicates (excluding id)\ndup_rows = train.duplicated(subset=feat_cols).sum()\nprint(f\"\\nPotential duplicate rows (excluding id): {dup_rows}\")\n\n# Missing + 'unknown' audit\ndef unknown_count(s):\n    return (s.astype(str).str.lower() == \"unknown\").sum()\n\nsummary_rows = []\nfor c in train.columns:\n    summary_rows.append({\n        \"col\": c,\n        \"dtype\": train[c].dtype,\n        \"n_unique\": train[c].nunique(dropna=True),\n        \"missing\": train[c].isna().sum(),\n        \"missing_%\": train[c].isna().mean()*100,\n        \"unknown_cnt\": unknown_count(train[c]) if c in cat_cols else np.nan,\n        \"unknown_%\": (unknown_count(train[c]) / len(train) * 100) if c in cat_cols else np.nan,\n        \"example_values\": train[c].dropna().astype(str).unique()[:5]\n    })\neda_summary = pd.DataFrame(summary_rows).sort_values([\"dtype\",\"col\"])\neda_summary\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T06:45:32.458701Z","iopub.execute_input":"2025-08-25T06:45:32.459226Z","iopub.status.idle":"2025-08-25T06:45:39.537088Z","shell.execute_reply.started":"2025-08-25T06:45:32.459198Z","shell.execute_reply":"2025-08-25T06:45:39.536309Z"}},"outputs":[{"name":"stdout","text":"Shape: (795211, 18) | Test: (250000, 17)\n\nDtypes\n id           float64\nage            int64\njob           object\nmarital       object\neducation     object\ndefault       object\nbalance        int64\nhousing       object\nloan          object\ncontact       object\nday            int64\nmonth         object\nduration       int64\ncampaign       int64\npdays          int64\nprevious       int64\npoutcome      object\ny              int64\ndtype: object\n\nTarget distribution\ny\n0    699434\n1     95777\nName: count, dtype: int64\ny\n0    87.96\n1    12.04\nName: pct %, dtype: float64\n\nPotential duplicate rows (excluding id): 21\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"          col    dtype  n_unique  missing  missing_%  unknown_cnt  unknown_%  \\\n1         age    int64        78        0   0.000000          NaN        NaN   \n6     balance    int64      8393        0   0.000000          NaN        NaN   \n13   campaign    int64        52        0   0.000000          NaN        NaN   \n10        day    int64        31        0   0.000000          NaN        NaN   \n12   duration    int64      1790        0   0.000000          NaN        NaN   \n14      pdays    int64       612        0   0.000000          NaN        NaN   \n15   previous    int64        51        0   0.000000          NaN        NaN   \n17          y    int64         2        0   0.000000          NaN        NaN   \n0          id  float64    750000    45211   5.685409          NaN        NaN   \n9     contact   object         3        0   0.000000     244647.0  30.765042   \n5     default   object         2        0   0.000000          0.0   0.000000   \n4   education   object         4        0   0.000000      23156.0   2.911932   \n7     housing   object         2        0   0.000000          0.0   0.000000   \n2         job   object        12        0   0.000000       3205.0   0.403038   \n8        loan   object         2        0   0.000000          0.0   0.000000   \n3     marital   object         3        0   0.000000          0.0   0.000000   \n11      month   object        12        0   0.000000          0.0   0.000000   \n16   poutcome   object         4        0   0.000000     709409.0  89.210159   \n\n                                       example_values  \n1                                [42, 38, 36, 27, 26]  \n6                              [7, 514, 602, 34, 889]  \n13                                   [3, 1, 2, 25, 5]  \n10                                [25, 18, 14, 28, 3]  \n12                           [117, 185, 111, 10, 902]  \n14                            [-1, 175, 91, 181, 252]  \n15                                    [0, 3, 4, 2, 1]  \n17                                             [0, 1]  \n0                           [0.0, 1.0, 2.0, 3.0, 4.0]  \n9                      [cellular, unknown, telephone]  \n5                                           [no, yes]  \n4             [secondary, primary, tertiary, unknown]  \n7                                           [no, yes]  \n2   [technician, blue-collar, student, admin., man...  \n8                                           [no, yes]  \n3                         [married, single, divorced]  \n11                          [aug, jun, may, feb, apr]  \n16                 [unknown, other, failure, success]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>col</th>\n      <th>dtype</th>\n      <th>n_unique</th>\n      <th>missing</th>\n      <th>missing_%</th>\n      <th>unknown_cnt</th>\n      <th>unknown_%</th>\n      <th>example_values</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>age</td>\n      <td>int64</td>\n      <td>78</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[42, 38, 36, 27, 26]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>balance</td>\n      <td>int64</td>\n      <td>8393</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[7, 514, 602, 34, 889]</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>campaign</td>\n      <td>int64</td>\n      <td>52</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[3, 1, 2, 25, 5]</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>day</td>\n      <td>int64</td>\n      <td>31</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[25, 18, 14, 28, 3]</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>duration</td>\n      <td>int64</td>\n      <td>1790</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[117, 185, 111, 10, 902]</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>pdays</td>\n      <td>int64</td>\n      <td>612</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[-1, 175, 91, 181, 252]</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>previous</td>\n      <td>int64</td>\n      <td>51</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[0, 3, 4, 2, 1]</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>y</td>\n      <td>int64</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[0, 1]</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>id</td>\n      <td>float64</td>\n      <td>750000</td>\n      <td>45211</td>\n      <td>5.685409</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[0.0, 1.0, 2.0, 3.0, 4.0]</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>contact</td>\n      <td>object</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>244647.0</td>\n      <td>30.765042</td>\n      <td>[cellular, unknown, telephone]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>default</td>\n      <td>object</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>[no, yes]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>education</td>\n      <td>object</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>23156.0</td>\n      <td>2.911932</td>\n      <td>[secondary, primary, tertiary, unknown]</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>housing</td>\n      <td>object</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>[no, yes]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>job</td>\n      <td>object</td>\n      <td>12</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>3205.0</td>\n      <td>0.403038</td>\n      <td>[technician, blue-collar, student, admin., man...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>loan</td>\n      <td>object</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>[no, yes]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>marital</td>\n      <td>object</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>[married, single, divorced]</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>month</td>\n      <td>object</td>\n      <td>12</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>[aug, jun, may, feb, apr]</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>poutcome</td>\n      <td>object</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>709409.0</td>\n      <td>89.210159</td>\n      <td>[unknown, other, failure, success]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"## Target relationships (cats & nums)","metadata":{}},{"cell_type":"code","source":"# Category-wise target rates\ndef target_rate_table(df, col, topn=15, min_n=50):\n    g = df.groupby(col)[TARGET].agg(rate=\"mean\", n=\"size\").reset_index()\n    g = g[g[\"n\"] >= min_n].sort_values(\"rate\", ascending=False)\n    return g.head(topn)\n\ncat_insights = {c: target_rate_table(train, c) for c in cat_cols}\ncat_insights[\"job\"].head(10), cat_insights[\"contact\"].head(10), cat_insights[\"poutcome\"].head(10)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T06:45:39.538011Z","iopub.execute_input":"2025-08-25T06:45:39.538279Z","iopub.status.idle":"2025-08-25T06:45:39.986052Z","shell.execute_reply.started":"2025-08-25T06:45:39.538260Z","shell.execute_reply":"2025-08-25T06:45:39.985300Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(              job      rate       n\n 8         student  0.336797   12705\n 5         retired  0.245133   37449\n 10     unemployed  0.178117   18937\n 4      management  0.149736  184999\n 6   self-employed  0.128598   20599\n 11        unknown  0.120437    3205\n 9      technician  0.117917  145704\n 0          admin.  0.116786   86663\n 3       housemaid  0.084888   17152\n 7        services  0.083086   68363,\n      contact      rate       n\n 0   cellular  0.156160  515940\n 1  telephone  0.136582   34624\n 2    unknown  0.042833  244647,\n   poutcome      rate       n\n 2  success  0.754817   19202\n 1    other  0.166848   16584\n 0  failure  0.132138   50016\n 3  unknown  0.101362  709409)"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"## Simple informativeness scores (Mutual Information)","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.feature_selection import mutual_info_classif\n\nX = train[feat_cols].copy()\ny = train[TARGET].values\n\n# Ordinal-encode categories for MI (safe for ranking, not for final model)\noe = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\nX_enc = X.copy()\nX_enc[cat_cols] = oe.fit_transform(X_enc[cat_cols])\n\nmi = mutual_info_classif(\n    X_enc, y,\n    discrete_features=[X_enc.columns.get_loc(c) for c in cat_cols],\n    random_state=42\n)\nmi_series = pd.Series(mi, index=feat_cols).sort_values(ascending=False)\nmi_series.head(15)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T06:45:39.986842Z","iopub.execute_input":"2025-08-25T06:45:39.987125Z","iopub.status.idle":"2025-08-25T06:46:21.490792Z","shell.execute_reply.started":"2025-08-25T06:45:39.987101Z","shell.execute_reply":"2025-08-25T06:46:21.489954Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"duration     0.148780\nbalance      0.068309\npdays        0.029613\npoutcome     0.027729\ncampaign     0.026107\nmonth        0.024863\nage          0.018548\ncontact      0.014944\nday          0.014419\nprevious     0.011933\nhousing      0.011696\njob          0.010970\nloan         0.003875\neducation    0.003825\nmarital      0.003769\ndtype: float64"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"## Train–Test sanity: unseen categories & distribution shift","metadata":{}},{"cell_type":"code","source":"# Unseen categories in test\ndef unseen_levels(train_df, test_df, cols):\n    rows=[]\n    for c in cols:\n        tr = set(train_df[c].astype(str).unique())\n        te = set(test_df[c].astype(str).unique())\n        unseen = sorted(te - tr)\n        rows.append({\"col\": c, \"n_unseen_in_test\": len(unseen), \"example_unseen\": unseen[:5]})\n    return pd.DataFrame(rows).sort_values(\"n_unseen_in_test\", ascending=False)\n\nunseen_df = unseen_levels(train, test, cat_cols)\nunseen_df.head(20)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T06:46:21.491584Z","iopub.execute_input":"2025-08-25T06:46:21.491963Z","iopub.status.idle":"2025-08-25T06:46:21.976696Z","shell.execute_reply.started":"2025-08-25T06:46:21.491945Z","shell.execute_reply":"2025-08-25T06:46:21.976088Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"         col  n_unseen_in_test example_unseen\n0        job                 0             []\n1    marital                 0             []\n2  education                 0             []\n3    default                 0             []\n4    housing                 0             []\n5       loan                 0             []\n6    contact                 0             []\n7      month                 0             []\n8   poutcome                 0             []","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>col</th>\n      <th>n_unseen_in_test</th>\n      <th>example_unseen</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>job</td>\n      <td>0</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>marital</td>\n      <td>0</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>education</td>\n      <td>0</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>default</td>\n      <td>0</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>housing</td>\n      <td>0</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>loan</td>\n      <td>0</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>contact</td>\n      <td>0</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>month</td>\n      <td>0</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>poutcome</td>\n      <td>0</td>\n      <td>[]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"# KS test for numeric shift\nfrom scipy.stats import ks_2samp\n\nrows=[]\nfor c in num_cols:\n    t = train[c].dropna()\n    u = test[c].dropna()\n    if len(t) > 0 and len(u) > 0:\n        stat,p = ks_2samp(t,u)\n        rows.append({\"col\": c, \"ks_stat\": stat, \"p_value\": p, \"train_median\": t.median(), \"test_median\": u.median()})\nks_report = pd.DataFrame(rows).sort_values(\"ks_stat\", ascending=False)\nks_report\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T06:46:21.977443Z","iopub.execute_input":"2025-08-25T06:46:21.977715Z","iopub.status.idle":"2025-08-25T06:46:23.674862Z","shell.execute_reply.started":"2025-08-25T06:46:21.977688Z","shell.execute_reply":"2025-08-25T06:46:23.674089Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"        col   ks_stat       p_value  train_median  test_median\n3  duration  0.009956  8.345680e-17         135.0        133.0\n1   balance  0.007390  1.890388e-09         624.0        631.0\n5     pdays  0.004437  1.113161e-03          -1.0         -1.0\n6  previous  0.004369  1.402264e-03           0.0          0.0\n4  campaign  0.002355  2.416873e-01           2.0          2.0\n0       age  0.002215  3.078053e-01          39.0         39.0\n2       day  0.001537  7.591500e-01          17.0         17.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>col</th>\n      <th>ks_stat</th>\n      <th>p_value</th>\n      <th>train_median</th>\n      <th>test_median</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>duration</td>\n      <td>0.009956</td>\n      <td>8.345680e-17</td>\n      <td>135.0</td>\n      <td>133.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>balance</td>\n      <td>0.007390</td>\n      <td>1.890388e-09</td>\n      <td>624.0</td>\n      <td>631.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>pdays</td>\n      <td>0.004437</td>\n      <td>1.113161e-03</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>previous</td>\n      <td>0.004369</td>\n      <td>1.402264e-03</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>campaign</td>\n      <td>0.002355</td>\n      <td>2.416873e-01</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>age</td>\n      <td>0.002215</td>\n      <td>3.078053e-01</td>\n      <td>39.0</td>\n      <td>39.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>day</td>\n      <td>0.001537</td>\n      <td>7.591500e-01</td>\n      <td>17.0</td>\n      <td>17.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"## Leakage check for duration","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\n\n# Using raw feature as a score is valid for AUC ranking\nauc_duration = roc_auc_score(y, train[\"duration\"])\nauc_pdays     = roc_auc_score(y, train[\"pdays\"].replace(-1, np.nan).fillna(train[\"pdays\"].max()+1))\nauc_campaign  = roc_auc_score(y, train[\"campaign\"])\nauc_prev      = roc_auc_score(y, train[\"previous\"])\nprint(f\"AUC(duration) ~ {auc_duration:.3f}, AUC(pdays) ~ {auc_pdays:.3f}, AUC(campaign) ~ {auc_campaign:.3f}, AUC(previous) ~ {auc_prev:.3f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T06:46:23.675713Z","iopub.execute_input":"2025-08-25T06:46:23.675911Z","iopub.status.idle":"2025-08-25T06:46:24.715607Z","shell.execute_reply.started":"2025-08-25T06:46:23.675895Z","shell.execute_reply":"2025-08-25T06:46:24.714831Z"}},"outputs":[{"name":"stdout","text":"AUC(duration) ~ 0.886, AUC(pdays) ~ 0.415, AUC(campaign) ~ 0.422, AUC(previous) ~ 0.581\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"# EDA Key takeaways:","metadata":{"execution":{"iopub.status.busy":"2025-08-25T02:34:46.443174Z","iopub.execute_input":"2025-08-25T02:34:46.443553Z","iopub.status.idle":"2025-08-25T02:34:46.448388Z","shell.execute_reply.started":"2025-08-25T02:34:46.443528Z","shell.execute_reply":"2025-08-25T02:34:46.447414Z"}}},{"cell_type":"markdown","source":"1. **Severe class imbalance**\n* `y=1` is only **12.04%** → use **StratifiedKFold**, and set **class weights / scale\\_pos\\_weight ≈ 7.3** (699,434 / 95,777) in XGB/LGBM/CatBoost. Optimize **ROC‑AUC** (Kaggle metric) but also watch **PR‑AUC** for sanity.\n\n2. **`duration` is massive leakage**\n\n* `AUC(duration) ≈ 0.886` (alone!). Build **two runs**:\n\n  * **LB‑max**: keep `duration`.\n  * **Realistic**: **drop `duration`** in FE (`use_duration=False`).\n\n3. **Huge “unknown” prevalence in a few columns**\n\n* `contact`: **30.77% unknown** with **low target rate (4.28%)** → very informative “unknown”. Keep as a **distinct level** + add a **flag** feature.\n* `poutcome`: **89.21% unknown**; but when **success**, target rate is **0.755** (very predictive). Engineer features that capture “previous success” cleanly (see FE plan).\n\n4. **`pdays == -1` sentinel**\n\n* Classic UCI convention meaning “never contacted.” Convert `-1 → NaN`, and add **`ever_contacted = 1(pdays != -1)`**.\n\n5. **`previous` and `campaign` matter**\n\n* `previous` alone yields **AUC ≈ 0.581** (solid). Create **`has_previous = 1(previous>0)`** and **`prev_success = 1(poutcome==\"success\")`**, forcing that to `0` when `previous==0`.\n* `campaign` is heavy‑tailed; helpful but weaker (AUC \\~0.422). For linear/NNs I’d log/winsorize, but trees can handle it; optional `log1p(campaign)` won’t hurt.\n\n6. **Mild train–test drift**\n\n* KS stats are tiny across numerics (e.g., `duration` 0.0099; medians close). No special reweighting needed.\n\n7. **`id` is float with \\~5.7% missing**\n\n* Not a feature; **drop it** from modeling. Keep `test.id` only for submission mapping.\n\n8. **Duplicates: 21 rows (excluding id)**\n\n* Tiny volume. **Drop exact duplicate rows**; if you find duplicate features with **conflicting targets**, drop those pairs to avoid noisy supervision.\n\n9. **Categoricals are modest in cardinality**\n\n* OHE with rare‑category folding is fine. Keep **`handle_unknown=\"ignore\"`** (you’ll have unseen levels in test).\n\n# Concrete data cleaning & feature engineering (do this next)\n\n**Always**\n\n* Drop: `id` (feature), optionally `day` if it adds noise (I usually keep it; it’s harmless).\n* Impute: numerics **median**, categoricals **most frequent**.\n* Encode: OHE with `min_frequency=0.01` (merge very rare levels to “other”).\n* Class imbalance: set model weights `(neg/pos) ≈ 7.3`.\n\n**Sentinels and flags**\n\n* `pdays`: `ever_contacted = 1(pdays != -1)`; then `pdays=-1 → NaN` (median impute).\n* `previous`: `has_previous = 1(previous > 0)`.\n* `poutcome`: `prev_success = 1(poutcome==\"success\")`; if `previous==0`, force `prev_success=0`. (Optionally also `prev_failure`, `prev_other`.)\n* `contact`: `contact_unknown = 1(contact==\"unknown\")`.\n\n**Transformations**\n\n* `balance_log = log1p(balance)` (very skewed). Keep original `balance` too; trees will decide.\n* `month_num` (map `jan..dec → 1..12`) + cyclical `sin/cos` to capture seasonality; keep the original `month` categorical as well.\n* Optional: age bins (`[18,25,35,45,55,65,100]`) as an extra categorical (`age_bin`).\n* Optional (linear‑friendly): `log1p(campaign)`, `log1p(previous)`.\n\n**Leakage handling**\n\n* Two FE modes:\n\n  * **`use_duration=True`** (for LB probing).\n  * **`use_duration=False`** (deployment‑realistic).\n\n**Duplicates**\n\n* Remove exact duplicates (`subset=all_features_incl_y`).\n* If duplicates with different `y` exist, remove both sides of the conflict (they’re label noise).\n","metadata":{"execution":{"iopub.status.busy":"2025-08-25T02:36:31.888259Z","iopub.execute_input":"2025-08-25T02:36:31.888678Z","iopub.status.idle":"2025-08-25T02:36:31.905267Z","shell.execute_reply.started":"2025-08-25T02:36:31.888644Z","shell.execute_reply":"2025-08-25T02:36:31.904036Z"}}},{"cell_type":"markdown","source":"# Data Cleaning + Feature Engineering","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom typing import Tuple, Dict, Any, Optional, List\n\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.compose import ColumnTransformer, make_column_selector as selector\nfrom sklearn.preprocessing import OneHotEncoder, RobustScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T06:46:24.716425Z","iopub.execute_input":"2025-08-25T06:46:24.716687Z","iopub.status.idle":"2025-08-25T06:46:24.746767Z","shell.execute_reply.started":"2025-08-25T06:46:24.716669Z","shell.execute_reply":"2025-08-25T06:46:24.745999Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"## Utility: Duplicate handling","metadata":{}},{"cell_type":"code","source":"def drop_exact_duplicates(df: pd.DataFrame, target: str, id_col: Optional[str]=None) -> pd.DataFrame:\n    \"\"\"\n    Drop exact duplicate rows based on all columns including y (if present),\n    but excluding id_col if provided.\n    If there are duplicates with conflicting target labels, drop all copies of those rows.\n    \"\"\"\n    cols = [c for c in df.columns if c != id_col] if id_col in df.columns else df.columns.tolist()\n\n    # duplicates including target\n    dup_mask = df.duplicated(subset=cols, keep=\"first\")\n    df1 = df.loc[~dup_mask].copy()\n\n    # Detect conflicting duplicates (same features, different y)\n    if target in df.columns:\n        feat_cols = [c for c in df.columns if c not in [target, id_col]]\n        # group by features, check if multiple unique targets\n        g = df.groupby(feat_cols, dropna=False)[target].nunique()\n        conflict_keys = g[g > 1].index\n        if len(conflict_keys) > 0:\n            # Drop all rows whose feature tuple is in conflict_keys\n            feat_tuple = df[feat_cols].apply(lambda r: tuple(r.values.tolist()), axis=1)\n            conflict_set = set(conflict_keys)\n            keep_mask = ~feat_tuple.isin(conflict_set)\n            df1 = df.loc[keep_mask].copy()\n\n    return df1\n\ntrain = drop_exact_duplicates(train, TARGET, ID_COL)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T06:46:24.749403Z","iopub.execute_input":"2025-08-25T06:46:24.749605Z","iopub.status.idle":"2025-08-25T06:46:30.294004Z","shell.execute_reply.started":"2025-08-25T06:46:24.749589Z","shell.execute_reply":"2025-08-25T06:46:30.293424Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"## Feature engineering transformer","metadata":{}},{"cell_type":"code","source":"class FeatureEngineer(BaseEstimator, TransformerMixin):\n    \"\"\"\n    - Drops ID column (if present)\n    - Maps yes/no to 1/0 for ['default','housing','loan']\n    - pdays: add ever_contacted, convert -1 -> NaN\n    - previous/poutcome: has_previous, prev_success (zeroed when has_previous==0)\n    - contact: contact_unknown flag\n    - month: month_num + sin/cos\n    - balance: balance_log = log1p(balance)\n    - optional age bins\n    - optional drop of 'duration' to avoid leakage\n    \"\"\"\n    def __init__(self, use_duration: bool = False, age_bins: Optional[List[int]] = None):\n        self.use_duration = use_duration\n        self.age_bins = age_bins\n        self.month_map = {m:i for i,m in enumerate(\n            [\"jan\",\"feb\",\"mar\",\"apr\",\"may\",\"jun\",\"jul\",\"aug\",\"sep\",\"oct\",\"nov\",\"dec\"], start=1)}\n\n    def fit(self, X: pd.DataFrame, y=None):\n        return self\n\n    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n        X = X.copy()\n\n        # Drop ID if present\n        if \"id\" in X.columns:\n            X = X.drop(columns=[\"id\"])\n\n        # yes/no → 1/0\n        for c in [\"default\",\"housing\",\"loan\"]:\n            if c in X.columns:\n                X[c] = X[c].map({\"yes\":1, \"no\":0}).astype(\"float\")\n\n        # pdays engineering\n        if \"pdays\" in X.columns:\n            X[\"ever_contacted\"] = (X[\"pdays\"] != -1).astype(int)\n            X[\"pdays\"] = X[\"pdays\"].replace(-1, np.nan)\n\n        # previous / poutcome\n        if \"previous\" in X.columns:\n            X[\"has_previous\"] = (X[\"previous\"] > 0).astype(int)\n        if \"poutcome\" in X.columns:\n            X[\"prev_success\"] = (X[\"poutcome\"].astype(str).str.lower() == \"success\").astype(int)\n            if \"has_previous\" in X.columns:\n                X.loc[X[\"has_previous\"] == 0, \"prev_success\"] = 0\n\n        # contact unknown flag\n        if \"contact\" in X.columns:\n            X[\"contact_unknown\"] = (X[\"contact\"].astype(str).str.lower() == \"unknown\").astype(int)\n\n        # month features\n        if \"month\" in X.columns:\n            X[\"month_num\"] = X[\"month\"].astype(str).str[:3].str.lower().map(self.month_map)\n            X[\"month_sin\"] = np.sin(2*np.pi*X[\"month_num\"]/12)\n            X[\"month_cos\"] = np.cos(2*np.pi*X[\"month_num\"]/12)\n\n        # balance log\n        if \"balance\" in X.columns:\n            # guard against negatives; UCI balance can be negative; log1p handles >= -1 safely if we clip\n            X[\"balance_log\"] = np.log1p(np.clip(X[\"balance\"], a_min=0, a_max=None))\n\n        # optional age bins\n        if self.age_bins is not None and \"age\" in X.columns:\n            X[\"age_bin\"] = pd.cut(X[\"age\"], bins=self.age_bins, include_lowest=True).astype(str)\n\n        # optionally drop duration to avoid leakage\n        if not self.use_duration and \"duration\" in X.columns:\n            X = X.drop(columns=[\"duration\"])\n\n        return X\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T06:46:30.294815Z","iopub.execute_input":"2025-08-25T06:46:30.295081Z","iopub.status.idle":"2025-08-25T06:46:30.305501Z","shell.execute_reply.started":"2025-08-25T06:46:30.295056Z","shell.execute_reply":"2025-08-25T06:46:30.304723Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Two FE variants\nfe_no_leak   = FeatureEngineer(use_duration=False, age_bins=[17,25,35,45,55,65,120])\nfe_with_leak = FeatureEngineer(use_duration=True,  age_bins=[17,25,35,45,55,65,120])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T06:46:30.306211Z","iopub.execute_input":"2025-08-25T06:46:30.306442Z","iopub.status.idle":"2025-08-25T06:46:30.322228Z","shell.execute_reply.started":"2025-08-25T06:46:30.306417Z","shell.execute_reply":"2025-08-25T06:46:30.321608Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"## ColumnTransformer (impute + encode +scale)","metadata":{}},{"cell_type":"code","source":"numeric_selector = selector(dtype_include=np.number)\ncategorical_selector = selector(dtype_include=[\"object\",\"category\"])\n\nnum_pipe = Pipeline([\n    (\"impute\", SimpleImputer(strategy=\"median\")),\n    (\"scale\", RobustScaler())\n])\n\ncat_pipe = Pipeline([\n    (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n    # min_frequency folds ultra-rare levels (helps generalisation, keeps matrix compact)\n    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", min_frequency=0.01, sparse=False))\n])\n\npreprocess = ColumnTransformer([\n    (\"num\", num_pipe, numeric_selector),\n    (\"cat\", cat_pipe, categorical_selector),\n], verbose_feature_names_out=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T06:46:30.322964Z","iopub.execute_input":"2025-08-25T06:46:30.323434Z","iopub.status.idle":"2025-08-25T06:46:30.337941Z","shell.execute_reply.started":"2025-08-25T06:46:30.323411Z","shell.execute_reply":"2025-08-25T06:46:30.337429Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"## Build preprocessing pipelines (without model for now)","metadata":{}},{"cell_type":"code","source":"prep_no_leak   = Pipeline([(\"fe\", fe_no_leak),   (\"prep\", preprocess)])\nprep_with_leak = Pipeline([(\"fe\", fe_with_leak), (\"prep\", preprocess)])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T06:46:30.338710Z","iopub.execute_input":"2025-08-25T06:46:30.338951Z","iopub.status.idle":"2025-08-25T06:46:30.351244Z","shell.execute_reply.started":"2025-08-25T06:46:30.338930Z","shell.execute_reply":"2025-08-25T06:46:30.350610Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"## Prepare matrices for modeling (choose one)","metadata":{}},{"cell_type":"code","source":"def prepare_data(pipeline: Pipeline, train_df: pd.DataFrame, test_df: pd.DataFrame,\n                 target: str) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, List[str]]:\n    \"\"\"\n    Fits the given preprocessing pipeline on train, transforms both train and test,\n    and returns (X_train, y_train, X_test, test_ids, feature_names).\n    \"\"\"\n    X = train_df.drop(columns=[target])\n    y = train_df[target].values\n    pipe = pipeline.fit(X, y)\n\n    X_train = pipe.transform(X)\n    X_test  = pipe.transform(test_df)\n\n    # Try to expose generated feature names (Sklearn >=1.0 on OneHot)\n    try:\n        feature_names = pipe.get_feature_names_out().tolist()\n    except Exception:\n        feature_names = [f\"f{i}\" for i in range(X_train.shape[1])]\n\n    test_ids = test_df[ID_COL].values if ID_COL in test_df.columns else np.arange(len(test_df))\n    return X_train, y, X_test, test_ids, feature_names\n\n# Example: create both preprocessed datasets for future modeling\nX_train_no_leak, y, X_test_no_leak, test_ids, feat_names_no_leak = prepare_data(\n    prep_no_leak, train, test, TARGET\n)\nX_train_with_leak, _, X_test_with_leak, _, feat_names_with_leak = prepare_data(\n    prep_with_leak, train, test, TARGET\n)\n\nprint(\"X_train_no_leak:\", X_train_no_leak.shape, \"| X_test_no_leak:\", X_test_no_leak.shape)\nprint(\"X_train_with_leak:\", X_train_with_leak.shape, \"| X_test_with_leak:\", X_test_with_leak.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T06:46:30.351872Z","iopub.execute_input":"2025-08-25T06:46:30.352081Z","iopub.status.idle":"2025-08-25T06:46:56.835528Z","shell.execute_reply.started":"2025-08-25T06:46:30.352065Z","shell.execute_reply":"2025-08-25T06:46:56.834799Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"X_train_no_leak: (795169, 60) | X_test_no_leak: (250000, 60)\nX_train_with_leak: (795169, 61) | X_test_with_leak: (250000, 61)\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"## Class weight helper for imbalanced y","metadata":{}},{"cell_type":"code","source":"def compute_scale_pos_weight(y: np.ndarray) -> float:\n    neg = (y == 0).sum()\n    pos = (y == 1).sum()\n    return float(neg / max(pos, 1))\n\nscale_pos_weight = compute_scale_pos_weight(y)\nprint(f\"scale_pos_weight ≈ {scale_pos_weight:.3f}  (use in XGB/LGBM/Cat)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T06:46:56.836337Z","iopub.execute_input":"2025-08-25T06:46:56.836598Z","iopub.status.idle":"2025-08-25T06:46:56.844317Z","shell.execute_reply.started":"2025-08-25T06:46:56.836575Z","shell.execute_reply":"2025-08-25T06:46:56.843673Z"}},"outputs":[{"name":"stdout","text":"scale_pos_weight ≈ 7.304  (use in XGB/LGBM/Cat)\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"# Modeling + Submission","metadata":{}},{"cell_type":"code","source":"import logging, time\nfrom tqdm.auto import tqdm\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\n\nfrom xgboost import XGBClassifier\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\n\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s | %(levelname)s | %(message)s\",\n    datefmt=\"%H:%M:%S\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T02:54:16.992181Z","iopub.execute_input":"2025-08-25T02:54:16.992480Z","iopub.status.idle":"2025-08-25T02:54:16.998527Z","shell.execute_reply.started":"2025-08-25T02:54:16.992459Z","shell.execute_reply":"2025-08-25T02:54:16.997676Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Define base models","metadata":{}},{"cell_type":"code","source":"xgb_params = dict(\n    n_estimators=500,\n    learning_rate=0.05,\n    max_depth=6,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    eval_metric=\"auc\",\n    tree_method=\"hist\",\n    scale_pos_weight=scale_pos_weight,\n    random_state=42,\n    n_jobs=-1,\n)\n\nlgbm_params = dict(\n    n_estimators=500,\n    learning_rate=0.05,\n    max_depth=-1,\n    num_leaves=64,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    objective=\"binary\",\n    verbosity = -1,\n    metric=\"auc\",\n    scale_pos_weight=scale_pos_weight,\n    random_state=42,\n    n_jobs=-1,\n)\n\ncat_params = dict(\n    iterations=500,\n    learning_rate=0.05,\n    depth=6,\n    eval_metric=\"AUC\",\n    scale_pos_weight=scale_pos_weight,\n    random_seed=42,\n    verbose=0,\n    thread_count=-1,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T02:54:52.207156Z","iopub.execute_input":"2025-08-25T02:54:52.207493Z","iopub.status.idle":"2025-08-25T02:54:52.214553Z","shell.execute_reply.started":"2025-08-25T02:54:52.207468Z","shell.execute_reply":"2025-08-25T02:54:52.213219Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Cross-validation training function","metadata":{}},{"cell_type":"code","source":"def _make_models(early_stopping_rounds: int):\n    # XGB: put early_stopping_rounds in constructor to avoid deprecation warning\n    xgb = XGBClassifier(**{**xgb_params, \"early_stopping_rounds\": early_stopping_rounds})\n    # LGBM: callbacks handle early stopping & logging silence\n    lgbm = LGBMClassifier(**{**lgbm_params})\n    # CatBoost: use od_* for early stopping (robust across versions)\n    cat = CatBoostClassifier(**{**cat_params, \"od_type\": \"Iter\", \"od_wait\": early_stopping_rounds})\n    return xgb, lgbm, cat\n\ndef _best_iter_safe(model):\n    for attr in [\"best_iteration_\", \"best_iteration\", \"best_ntree_limit\"]:\n        if hasattr(model, attr) and getattr(model, attr) is not None:\n            return getattr(model, attr)\n    try:\n        return model.get_booster().best_ntree_limit\n    except Exception:\n        return None\n\ndef train_and_predict(\n    X, y, X_test, label=\"no_leak\",\n    n_splits=5, early_stopping_rounds=100\n):\n    logging.info(f\"Start CV training: label='{label}', folds={n_splits}, samples={len(y):,}, features={X.shape[1]}\")\n    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n\n    oof_preds = np.zeros(len(y), dtype=float)\n    test_preds = np.zeros(len(X_test), dtype=float)\n\n    for fold, (tr_idx, va_idx) in enumerate(tqdm(skf.split(X, y), total=n_splits, desc=f\"CV ({label})\"), start=1):\n        t0 = time.time()\n        X_tr, y_tr = X[tr_idx], y[tr_idx]\n        X_va, y_va = X[va_idx], y[va_idx]\n\n        model_xgb, model_lgb, model_cat = _make_models(early_stopping_rounds)\n\n        # --- XGB (early stopping via constructor) ---\n        model_xgb.fit(\n            X_tr, y_tr,\n            eval_set=[(X_va, y_va)],\n            verbose=False\n        )\n\n        # --- LGBM (callbacks for ES + silence) ---\n        model_lgb.fit(\n            X_tr, y_tr,\n            eval_set=[(X_va, y_va)],\n            callbacks=[\n                lgb.early_stopping(early_stopping_rounds),\n                lgb.log_evaluation(period=0),  # 0 = silence\n            ],\n        )\n\n        # --- CatBoost (od_wait for ES; silent training) ---\n        model_cat.fit(\n            X_tr, y_tr,\n            eval_set=[(X_va, y_va)],\n            use_best_model=True,\n            verbose=False\n        )\n\n        # Validation probs (soft vote)\n        val_pred = (\n            model_xgb.predict_proba(X_va)[:, 1] +\n            model_lgb.predict_proba(X_va)[:, 1] +\n            model_cat.predict_proba(X_va)[:, 1]\n        ) / 3.0\n        oof_preds[va_idx] = val_pred\n        fold_auc = roc_auc_score(y_va, val_pred)\n\n        # Test probs averaged across folds\n        test_fold_pred = (\n            model_xgb.predict_proba(X_test)[:, 1] +\n            model_lgb.predict_proba(X_test)[:, 1] +\n            model_cat.predict_proba(X_test)[:, 1]\n        ) / 3.0\n        test_preds += test_fold_pred / n_splits\n\n        sec = time.time() - t0\n        logging.info(\n            f\"Fold {fold}/{n_splits} | AUC={fold_auc:.5f} | \"\n            f\"best_iter(xgb={_best_iter_safe(model_xgb)}, lgb={_best_iter_safe(model_lgb)}, cat={_best_iter_safe(model_cat)}) | \"\n            f\"{sec:.1f}s\"\n        )\n\n    overall_auc = roc_auc_score(y, oof_preds)\n    logging.info(f\"Finished CV: {label} | Overall AUC={overall_auc:.5f}\")\n\n    # Save submission with clear name\n    sub_df = pd.DataFrame({\"id\": test_ids, \"y\": test_preds})\n    filename = f\"submission_{label}.csv\"\n    sub_df.to_csv(filename, index=False)\n    logging.info(f\"Saved {filename}\")\n\n    return oof_preds, test_preds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T02:55:06.341404Z","iopub.execute_input":"2025-08-25T02:55:06.341744Z","iopub.status.idle":"2025-08-25T02:55:06.358608Z","shell.execute_reply.started":"2025-08-25T02:55:06.341717Z","shell.execute_reply":"2025-08-25T02:55:06.357368Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Train both pipelines","metadata":{}},{"cell_type":"code","source":"print(\"=== Training WITHOUT duration (realistic) ===\")\noof_no_leak, test_no_leak = train_and_predict(\n    X_train_no_leak, y, X_test_no_leak, label=\"no_leak\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T02:55:16.809115Z","iopub.execute_input":"2025-08-25T02:55:16.809432Z","iopub.status.idle":"2025-08-25T03:09:25.531744Z","shell.execute_reply.started":"2025-08-25T02:55:16.809407Z","shell.execute_reply":"2025-08-25T03:09:25.530876Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\n=== Training WITH duration (leakage version) ===\")\noof_with_leak, test_with_leak = train_and_predict(\n    X_train_with_leak, y, X_test_with_leak, label=\"with_leak\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T03:09:47.508255Z","iopub.execute_input":"2025-08-25T03:09:47.508574Z","iopub.status.idle":"2025-08-25T03:24:31.316644Z","shell.execute_reply.started":"2025-08-25T03:09:47.508546Z","shell.execute_reply":"2025-08-25T03:24:31.315743Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Optuna HPO for WITH-LEAK pipeline","metadata":{}},{"cell_type":"code","source":"import sys, subprocess, importlib\ndef _ensure_pkg(pkg):\n    try:\n        importlib.import_module(pkg)\n    except ImportError:\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pkg])\n_ensure_pkg(\"optuna\")\n\nimport optuna\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\n\nfrom xgboost import XGBClassifier\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\n\nRANDOM_STATE = 42","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T06:46:56.844950Z","iopub.execute_input":"2025-08-25T06:46:56.845154Z","iopub.status.idle":"2025-08-25T06:47:01.421769Z","shell.execute_reply.started":"2025-08-25T06:46:56.845139Z","shell.execute_reply":"2025-08-25T06:47:01.420995Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"## Helpers","metadata":{}},{"cell_type":"code","source":"def cv_auc_for_model(make_model_fn, X, y, n_splits=3, early_stopping_rounds=100):\n    \"\"\"3-fold CV AUC for speed during tuning; uses early stopping.\"\"\"\n    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_STATE)\n    aucs=[]\n    for tr_idx, va_idx in skf.split(X, y):\n        X_tr, X_va = X[tr_idx], X[va_idx]\n        y_tr, y_va = y[tr_idx], y[va_idx]\n        model = make_model_fn(early_stopping_rounds)\n        # Fit with the right early-stopping mechanics per library\n        if isinstance(model, XGBClassifier):\n            model.fit(X_tr, y_tr, eval_set=[(X_va, y_va)], verbose=False)\n        elif isinstance(model, LGBMClassifier):\n            model.fit(\n                X_tr, y_tr, eval_set=[(X_va, y_va)],\n                callbacks=[lgb.early_stopping(early_stopping_rounds), lgb.log_evaluation(period=0)]\n            )\n        elif isinstance(model, CatBoostClassifier):\n            model.fit(X_tr, y_tr, eval_set=[(X_va, y_va)], use_best_model=True, verbose=False)\n        else:\n            model.fit(X_tr, y_tr)\n        preds = model.predict_proba(X_va)[:,1]\n        aucs.append(roc_auc_score(y_va, preds))\n    return float(np.mean(aucs))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T06:47:01.422614Z","iopub.execute_input":"2025-08-25T06:47:01.423207Z","iopub.status.idle":"2025-08-25T06:47:01.429673Z","shell.execute_reply.started":"2025-08-25T06:47:01.423184Z","shell.execute_reply":"2025-08-25T06:47:01.428868Z"}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"## Tune XGBoost","metadata":{}},{"cell_type":"code","source":"def tune_xgb(X, y, n_trials=30, timeout=None, early_stopping_rounds=100):\n    def objective(trial: optuna.Trial):\n        params = {\n            \"n_estimators\": 1000,  # rely on ES\n            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.02, 0.2, log=True),\n            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n            \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 1.0, 10.0),\n            \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n            \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.0, 1.0),\n            \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.5, 3.0),\n            \"gamma\": trial.suggest_float(\"gamma\", 0.0, 5.0),\n            \"tree_method\": \"hist\",\n            \"device\": \"cuda\",\n            \"eval_metric\": \"auc\",\n            \"random_state\": RANDOM_STATE,\n            \"n_jobs\": -1,\n            \"scale_pos_weight\": scale_pos_weight,\n            \"early_stopping_rounds\": early_stopping_rounds,  # set in constructor to avoid warning\n        }\n        def make_model(esr):\n            return XGBClassifier(**params)\n        return cv_auc_for_model(make_model, X, y, n_splits=3, early_stopping_rounds=early_stopping_rounds)\n\n    study = optuna.create_study(direction=\"maximize\", study_name=\"xgb_with_leak\")\n    study.optimize(objective, n_trials=n_trials, timeout=timeout, show_progress_bar=True)\n    return study","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T06:47:01.431102Z","iopub.execute_input":"2025-08-25T06:47:01.431658Z","iopub.status.idle":"2025-08-25T06:47:01.452095Z","shell.execute_reply.started":"2025-08-25T06:47:01.431626Z","shell.execute_reply":"2025-08-25T06:47:01.451508Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"## Tune LightGBM","metadata":{}},{"cell_type":"code","source":"def tune_lgbm(X, y, n_trials=30, timeout=None, early_stopping_rounds=100):\n    def objective(trial: optuna.Trial):\n        params = {\n            \"objective\": \"binary\",\n            \"metric\": \"auc\",\n            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.02, 0.2, log=True),\n            \"num_leaves\": trial.suggest_int(\"num_leaves\", 31, 255),\n            \"max_depth\": trial.suggest_int(\"max_depth\", 4, 12),\n            \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 10, 200),\n            \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n            \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 0.0, 1.0),\n            \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 0.0, 3.0),\n            \"min_split_gain\": trial.suggest_float(\"min_split_gain\", 0.0, 1.0),\n            \"verbosity\": -1,\n            \"random_state\": RANDOM_STATE,\n            \"n_estimators\": 4000,  # let ES pick best\n            \"n_jobs\": -1,\n            \"scale_pos_weight\": scale_pos_weight,\n            \"device_type\": \"gpu\",   # << GPU\n        }\n        def make_model(esr):\n            return LGBMClassifier(**params)\n        return cv_auc_for_model(make_model, X, y, n_splits=3, early_stopping_rounds=early_stopping_rounds)\n\n    study = optuna.create_study(direction=\"maximize\", study_name=\"lgbm_with_leak\")\n    study.optimize(objective, n_trials=n_trials, timeout=timeout, show_progress_bar=True)\n    return study","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T06:47:01.452749Z","iopub.execute_input":"2025-08-25T06:47:01.452928Z","iopub.status.idle":"2025-08-25T06:47:01.469829Z","shell.execute_reply.started":"2025-08-25T06:47:01.452914Z","shell.execute_reply":"2025-08-25T06:47:01.469296Z"}},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":"## Tune CatBoost","metadata":{}},{"cell_type":"code","source":"def tune_cat(X, y, n_trials=30, timeout=None, early_stopping_rounds=100):\n    def objective(trial: optuna.Trial):\n        params = {\n            \"loss_function\": \"Logloss\",\n            \"eval_metric\": \"AUC\",\n            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.02, 0.2, log=True),\n            \"depth\": trial.suggest_int(\"depth\", 4, 10),\n            \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1.0, 10.0),\n            # \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n            \"random_strength\": trial.suggest_float(\"random_strength\", 0.0, 2.0),\n            \"bagging_temperature\": trial.suggest_float(\"bagging_temperature\", 0.0, 5.0),\n            \"border_count\": trial.suggest_int(\"border_count\", 32, 255),\n            \"iterations\": 4000,\n            \"od_type\": \"Iter\",\n            \"od_wait\": early_stopping_rounds,\n            \"random_seed\": RANDOM_STATE,\n            \"thread_count\": -1,\n            \"scale_pos_weight\": scale_pos_weight,\n            \"verbose\": False,\n            \"task_type\": \"GPU\",   # << GPU\n        }\n        def make_model(esr):\n            return CatBoostClassifier(**params)\n        return cv_auc_for_model(make_model, X, y, n_splits=3, early_stopping_rounds=early_stopping_rounds)\n\n    study = optuna.create_study(direction=\"maximize\", study_name=\"cat_with_leak\")\n    study.optimize(objective, n_trials=n_trials, timeout=timeout, show_progress_bar=True)\n    return study","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T06:47:01.470569Z","iopub.execute_input":"2025-08-25T06:47:01.470774Z","iopub.status.idle":"2025-08-25T06:47:01.488895Z","shell.execute_reply.started":"2025-08-25T06:47:01.470757Z","shell.execute_reply":"2025-08-25T06:47:01.488171Z"}},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":"## Run tuning (Adjust trials for runtime)","metadata":{}},{"cell_type":"markdown","source":"### Optuna-Tuned Ensemble Training with AUC²-Weighted Blending (With-Leak Pipeline)","metadata":{}},{"cell_type":"code","source":"N_TRIALS_XGB = 5\nN_TRIALS_LGB = 5\nN_TRIALS_CAT = 5\nES_ROUNDS = 100","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T06:47:01.489736Z","iopub.execute_input":"2025-08-25T06:47:01.489967Z","iopub.status.idle":"2025-08-25T06:47:01.507304Z","shell.execute_reply.started":"2025-08-25T06:47:01.489942Z","shell.execute_reply":"2025-08-25T06:47:01.506615Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"study_xgb = tune_xgb(X_train_with_leak, y, n_trials=N_TRIALS_XGB, early_stopping_rounds=ES_ROUNDS)\nstudy_lgb = tune_lgbm(X_train_with_leak, y, n_trials=N_TRIALS_LGB, early_stopping_rounds=ES_ROUNDS)\nstudy_cat = tune_cat(X_train_with_leak, y, n_trials=N_TRIALS_CAT, early_stopping_rounds=ES_ROUNDS)\n\nprint(\"Best XGB:\", study_xgb.best_params, \"AUC:\", study_xgb.best_value)\nprint(\"Best LGB:\", study_lgb.best_params, \"AUC:\", study_lgb.best_value)\nprint(\"Best CAT:\", study_cat.best_params, \"AUC:\", study_cat.best_value)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T06:47:01.507972Z","iopub.execute_input":"2025-08-25T06:47:01.508345Z","iopub.status.idle":"2025-08-25T07:22:00.448964Z","shell.execute_reply.started":"2025-08-25T06:47:01.508327Z","shell.execute_reply":"2025-08-25T07:22:00.448140Z"}},"outputs":[{"name":"stderr","text":"[I 2025-08-25 06:47:01,518] A new study created in memory with name: xgb_with_leak\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f3f756ceba644a2a4b327d0ca5882a3"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [06:47:10] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\nPotential solutions:\n- Use a data structure that matches the device ordinal in the booster.\n- Set the device for booster before call to inplace_predict.\n\nThis warning will only be shown once.\n\n  warnings.warn(smsg, UserWarning)\n","output_type":"stream"},{"name":"stdout","text":"[I 2025-08-25 06:47:29,315] Trial 0 finished with value: 0.9649294285855623 and parameters: {'learning_rate': 0.03968377847350871, 'max_depth': 5, 'min_child_weight': 8.404044883154855, 'subsample': 0.8734615308262792, 'colsample_bytree': 0.6279588580947923, 'reg_alpha': 0.22649677940955382, 'reg_lambda': 1.6809592024123639, 'gamma': 0.23285076230208646}. Best is trial 0 with value: 0.9649294285855623.\n[I 2025-08-25 06:48:06,915] Trial 1 finished with value: 0.9664033138186688 and parameters: {'learning_rate': 0.042708844588483875, 'max_depth': 9, 'min_child_weight': 2.689948116561219, 'subsample': 0.7339284064672769, 'colsample_bytree': 0.6547444698580706, 'reg_alpha': 0.15818705979045533, 'reg_lambda': 1.0093618046055304, 'gamma': 4.262546398318409}. Best is trial 1 with value: 0.9664033138186688.\n[I 2025-08-25 06:48:31,913] Trial 2 finished with value: 0.9637009374944009 and parameters: {'learning_rate': 0.042763393352116624, 'max_depth': 4, 'min_child_weight': 2.899536416068301, 'subsample': 0.9190057964355354, 'colsample_bytree': 0.8649620946395615, 'reg_alpha': 0.08144838266379673, 'reg_lambda': 2.527112121301651, 'gamma': 1.764502936217725}. Best is trial 1 with value: 0.9664033138186688.\n[I 2025-08-25 06:48:50,581] Trial 3 finished with value: 0.9657445568732853 and parameters: {'learning_rate': 0.11641439282431612, 'max_depth': 10, 'min_child_weight': 7.288028245912066, 'subsample': 0.6704664566806264, 'colsample_bytree': 0.6835548395442691, 'reg_alpha': 0.7983290368141812, 'reg_lambda': 0.9238590696253399, 'gamma': 1.7734497920700747}. Best is trial 1 with value: 0.9664033138186688.\n","output_type":"stream"},{"name":"stderr","text":"[I 2025-08-25 06:49:18,006] A new study created in memory with name: lgbm_with_leak\n","output_type":"stream"},{"name":"stdout","text":"[I 2025-08-25 06:49:18,003] Trial 4 finished with value: 0.9654661202676215 and parameters: {'learning_rate': 0.051591132826618605, 'max_depth': 5, 'min_child_weight': 3.5281689808583865, 'subsample': 0.6207520337542779, 'colsample_bytree': 0.8107895844140063, 'reg_alpha': 0.035938406360413344, 'reg_lambda': 1.9446087129863296, 'gamma': 2.5346642836306152}. Best is trial 1 with value: 0.9664033138186688.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e5f74b46f5d43dd8083dff408605934"}},"metadata":{}},{"name":"stderr","text":"1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n","output_type":"stream"},{"name":"stdout","text":"Training until validation scores don't improve for 100 rounds\nEarly stopping, best iteration is:\n[569]\tvalid_0's auc: 0.965926\nTraining until validation scores don't improve for 100 rounds\nEarly stopping, best iteration is:\n[583]\tvalid_0's auc: 0.966692\nTraining until validation scores don't improve for 100 rounds\nEarly stopping, best iteration is:\n[599]\tvalid_0's auc: 0.966736\n[I 2025-08-25 06:51:19,806] Trial 0 finished with value: 0.9664515957198798 and parameters: {'learning_rate': 0.07446444499079431, 'num_leaves': 116, 'max_depth': 8, 'min_child_samples': 83, 'subsample': 0.6609801356553962, 'colsample_bytree': 0.8679242975549873, 'lambda_l1': 0.47106519414210246, 'lambda_l2': 1.4169201992508662, 'min_split_gain': 0.5003291181824434}. Best is trial 0 with value: 0.9664515957198798.\nTraining until validation scores don't improve for 100 rounds\nDid not meet early stopping. Best iteration is:\n[4000]\tvalid_0's auc: 0.964879\nTraining until validation scores don't improve for 100 rounds\nDid not meet early stopping. Best iteration is:\n[4000]\tvalid_0's auc: 0.96545\nTraining until validation scores don't improve for 100 rounds\nDid not meet early stopping. Best iteration is:\n[4000]\tvalid_0's auc: 0.965483\n[I 2025-08-25 06:59:01,589] Trial 1 finished with value: 0.9652704749809908 and parameters: {'learning_rate': 0.020935729073271892, 'num_leaves': 167, 'max_depth': 4, 'min_child_samples': 166, 'subsample': 0.9167762021279583, 'colsample_bytree': 0.915039011712349, 'lambda_l1': 0.6819711484030767, 'lambda_l2': 1.4283798608633007, 'min_split_gain': 0.4890448121688754}. Best is trial 0 with value: 0.9664515957198798.\nTraining until validation scores don't improve for 100 rounds\nEarly stopping, best iteration is:\n[3095]\tvalid_0's auc: 0.965432\nTraining until validation scores don't improve for 100 rounds\nEarly stopping, best iteration is:\n[3212]\tvalid_0's auc: 0.965849\nTraining until validation scores don't improve for 100 rounds\nEarly stopping, best iteration is:\n[3085]\tvalid_0's auc: 0.966028\n[I 2025-08-25 07:05:21,327] Trial 2 finished with value: 0.9657697544186995 and parameters: {'learning_rate': 0.035113625987477075, 'num_leaves': 241, 'max_depth': 4, 'min_child_samples': 199, 'subsample': 0.8395847239163442, 'colsample_bytree': 0.5147712516932579, 'lambda_l1': 0.24568424060255212, 'lambda_l2': 0.1582321803283856, 'min_split_gain': 0.45428462387045576}. Best is trial 0 with value: 0.9664515957198798.\nTraining until validation scores don't improve for 100 rounds\nEarly stopping, best iteration is:\n[1344]\tvalid_0's auc: 0.966129\nTraining until validation scores don't improve for 100 rounds\nEarly stopping, best iteration is:\n[1355]\tvalid_0's auc: 0.96658\nTraining until validation scores don't improve for 100 rounds\nEarly stopping, best iteration is:\n[1293]\tvalid_0's auc: 0.966822\n[I 2025-08-25 07:08:22,478] Trial 3 finished with value: 0.9665100310008544 and parameters: {'learning_rate': 0.1004568552585223, 'num_leaves': 94, 'max_depth': 5, 'min_child_samples': 129, 'subsample': 0.8740944395002588, 'colsample_bytree': 0.912587317178716, 'lambda_l1': 0.2332853393542932, 'lambda_l2': 1.4273799004462022, 'min_split_gain': 0.18863817737052757}. Best is trial 3 with value: 0.9665100310008544.\nTraining until validation scores don't improve for 100 rounds\nEarly stopping, best iteration is:\n[887]\tvalid_0's auc: 0.965622\nTraining until validation scores don't improve for 100 rounds\nEarly stopping, best iteration is:\n[892]\tvalid_0's auc: 0.966436\nTraining until validation scores don't improve for 100 rounds\nEarly stopping, best iteration is:\n[891]\tvalid_0's auc: 0.966351\n","output_type":"stream"},{"name":"stderr","text":"[I 2025-08-25 07:10:59,914] A new study created in memory with name: cat_with_leak\n","output_type":"stream"},{"name":"stdout","text":"[I 2025-08-25 07:10:59,911] Trial 4 finished with value: 0.9661361486783372 and parameters: {'learning_rate': 0.04911378010244407, 'num_leaves': 81, 'max_depth': 8, 'min_child_samples': 31, 'subsample': 0.998429695506945, 'colsample_bytree': 0.9124670259887907, 'lambda_l1': 0.08980383873451403, 'lambda_l2': 0.7663170714636113, 'min_split_gain': 0.708316840842705}. Best is trial 3 with value: 0.9665100310008544.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"500ec586471944a29930444b56a32645"}},"metadata":{}},{"name":"stderr","text":"Default metric period is 5 because AUC is/are not implemented for GPU\nDefault metric period is 5 because AUC is/are not implemented for GPU\nDefault metric period is 5 because AUC is/are not implemented for GPU\n","output_type":"stream"},{"name":"stdout","text":"[I 2025-08-25 07:12:51,566] Trial 0 finished with value: 0.9628295428821412 and parameters: {'learning_rate': 0.19551298530868647, 'depth': 10, 'l2_leaf_reg': 3.189988715623757, 'random_strength': 0.8341497086107279, 'bagging_temperature': 1.3980086270981, 'border_count': 197}. Best is trial 0 with value: 0.9628295428821412.\n","output_type":"stream"},{"name":"stderr","text":"Default metric period is 5 because AUC is/are not implemented for GPU\nDefault metric period is 5 because AUC is/are not implemented for GPU\nDefault metric period is 5 because AUC is/are not implemented for GPU\n","output_type":"stream"},{"name":"stdout","text":"[I 2025-08-25 07:15:13,812] Trial 1 finished with value: 0.9617002069013308 and parameters: {'learning_rate': 0.054743865085166286, 'depth': 4, 'l2_leaf_reg': 7.704204827339372, 'random_strength': 0.43151191398979516, 'bagging_temperature': 4.607990227870827, 'border_count': 111}. Best is trial 0 with value: 0.9628295428821412.\n","output_type":"stream"},{"name":"stderr","text":"Default metric period is 5 because AUC is/are not implemented for GPU\nDefault metric period is 5 because AUC is/are not implemented for GPU\nDefault metric period is 5 because AUC is/are not implemented for GPU\n","output_type":"stream"},{"name":"stdout","text":"[I 2025-08-25 07:16:52,321] Trial 2 finished with value: 0.9630899207541069 and parameters: {'learning_rate': 0.19837420215535823, 'depth': 6, 'l2_leaf_reg': 9.49941839523351, 'random_strength': 0.11731267793573785, 'bagging_temperature': 3.4605613408042855, 'border_count': 125}. Best is trial 2 with value: 0.9630899207541069.\n","output_type":"stream"},{"name":"stderr","text":"Default metric period is 5 because AUC is/are not implemented for GPU\nDefault metric period is 5 because AUC is/are not implemented for GPU\nDefault metric period is 5 because AUC is/are not implemented for GPU\n","output_type":"stream"},{"name":"stdout","text":"[I 2025-08-25 07:19:17,603] Trial 3 finished with value: 0.9645645459207647 and parameters: {'learning_rate': 0.042842630592792814, 'depth': 4, 'l2_leaf_reg': 4.182157264319844, 'random_strength': 0.039219049421542085, 'bagging_temperature': 0.8819911643568784, 'border_count': 173}. Best is trial 3 with value: 0.9645645459207647.\n","output_type":"stream"},{"name":"stderr","text":"Default metric period is 5 because AUC is/are not implemented for GPU\nDefault metric period is 5 because AUC is/are not implemented for GPU\nDefault metric period is 5 because AUC is/are not implemented for GPU\n","output_type":"stream"},{"name":"stdout","text":"[I 2025-08-25 07:22:00,442] Trial 4 finished with value: 0.9622133099561458 and parameters: {'learning_rate': 0.02443746572311223, 'depth': 6, 'l2_leaf_reg': 4.656604933471254, 'random_strength': 0.4361769141143186, 'bagging_temperature': 3.1956608586239628, 'border_count': 49}. Best is trial 3 with value: 0.9645645459207647.\nBest XGB: {'learning_rate': 0.042708844588483875, 'max_depth': 9, 'min_child_weight': 2.689948116561219, 'subsample': 0.7339284064672769, 'colsample_bytree': 0.6547444698580706, 'reg_alpha': 0.15818705979045533, 'reg_lambda': 1.0093618046055304, 'gamma': 4.262546398318409} AUC: 0.9664033138186688\nBest LGB: {'learning_rate': 0.1004568552585223, 'num_leaves': 94, 'max_depth': 5, 'min_child_samples': 129, 'subsample': 0.8740944395002588, 'colsample_bytree': 0.912587317178716, 'lambda_l1': 0.2332853393542932, 'lambda_l2': 1.4273799004462022, 'min_split_gain': 0.18863817737052757} AUC: 0.9665100310008544\nBest CAT: {'learning_rate': 0.042842630592792814, 'depth': 4, 'l2_leaf_reg': 4.182157264319844, 'random_strength': 0.039219049421542085, 'bagging_temperature': 0.8819911643568784, 'border_count': 173} AUC: 0.9645645459207647\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"xgb_best = {\n    \"tree_method\": \"hist\",\n    \"eval_metric\": \"auc\",\n    \"random_state\": RANDOM_STATE,\n    \"n_jobs\": -1,\n    \"scale_pos_weight\": scale_pos_weight,\n    \"n_estimators\": 1000,\n    \"early_stopping_rounds\": ES_ROUNDS,\n    \"device\": \"cuda\",\n    **study_xgb.best_params\n}\nlgb_best = {\n    \"objective\": \"binary\",\n    \"metric\": \"auc\",\n    \"verbosity\": -1,\n    \"random_state\": RANDOM_STATE,\n    \"n_estimators\": 4000,\n    \"n_jobs\": -1,\n    \"scale_pos_weight\": scale_pos_weight,\n    \"device_type\": \"gpu\",   # << GPU\n    **study_lgb.best_params\n}\ncat_best = {\n    \"loss_function\": \"Logloss\",\n    \"eval_metric\": \"AUC\",\n    \"iterations\": 4000,\n    \"od_type\": \"Iter\",\n    \"od_wait\": ES_ROUNDS,\n    \"random_seed\": RANDOM_STATE,\n    \"thread_count\": -1,\n    \"scale_pos_weight\": scale_pos_weight,\n    \"verbose\": False,\n    \"task_type\": \"GPU\",   # << GPU\n    **study_cat.best_params\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T07:22:32.983601Z","iopub.execute_input":"2025-08-25T07:22:32.983878Z","iopub.status.idle":"2025-08-25T07:22:32.989887Z","shell.execute_reply.started":"2025-08-25T07:22:32.983857Z","shell.execute_reply":"2025-08-25T07:22:32.989080Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nimport lightgbm as lgb\nfrom catboost import CatBoostClassifier\nfrom tqdm.auto import tqdm\nimport numpy as np, pandas as pd, time\n\nRANDOM_STATE = 42\nES_ROUNDS = xgb_best.get(\"early_stopping_rounds\", 100)  # reuse your ES value\n\ndef train_and_predict_with_weights(\n    X, y, X_test, test_ids,\n    xgb_params, lgbm_params, cat_params,\n    label_base=\"with_leak_optuna\", n_splits=5\n):\n    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_STATE)\n\n    # --- OOF holders per model ---\n    oof_xgb = np.zeros(len(y), dtype=float)\n    oof_lgb = np.zeros(len(y), dtype=float)\n    oof_cat = np.zeros(len(y), dtype=float)\n\n    # --- Test holders per model (fold-averaged) ---\n    test_xgb = np.zeros(len(X_test), dtype=float)\n    test_lgb = np.zeros(len(X_test), dtype=float)\n    test_cat = np.zeros(len(X_test), dtype=float)\n\n    # --- Equal-blend OOF holder (for reference) ---\n    oof_eq = np.zeros(len(y), dtype=float)\n\n    for fold, (tr_idx, va_idx) in enumerate(tqdm(skf.split(X, y), total=n_splits, desc=f\"CV ({label_base})\"), start=1):\n        X_tr, X_va = X[tr_idx], X[va_idx]\n        y_tr, y_va = y[tr_idx], y[va_idx]\n\n        m_xgb = XGBClassifier(**xgb_params)\n        m_lgb = LGBMClassifier(**lgbm_params)\n        m_cat = CatBoostClassifier(**cat_params)\n\n        t0 = time.time()\n        # XGB: ES in constructor\n        m_xgb.fit(X_tr, y_tr, eval_set=[(X_va, y_va)], verbose=False)\n\n        # LGB: callbacks for ES + silent logging\n        m_lgb.fit(\n            X_tr, y_tr, eval_set=[(X_va, y_va)],\n            callbacks=[lgb.early_stopping(ES_ROUNDS), lgb.log_evaluation(period=0)]\n        )\n\n        # Cat: od_wait for ES, silent\n        m_cat.fit(X_tr, y_tr, eval_set=[(X_va, y_va)], use_best_model=True, verbose=False)\n\n        # --- OOF preds per model ---\n        pv_xgb = m_xgb.predict_proba(X_va)[:, 1]\n        pv_lgb = m_lgb.predict_proba(X_va)[:, 1]\n        pv_cat = m_cat.predict_proba(X_va)[:, 1]\n\n        oof_xgb[va_idx] = pv_xgb\n        oof_lgb[va_idx] = pv_lgb\n        oof_cat[va_idx] = pv_cat\n\n        # Equal-weight blend (reference)\n        pv_eq = (pv_xgb + pv_lgb + pv_cat) / 3.0\n        oof_eq[va_idx] = pv_eq\n\n        # --- Test preds per model (fold-averaged) ---\n        test_xgb += m_xgb.predict_proba(X_test)[:, 1] / n_splits\n        test_lgb += m_lgb.predict_proba(X_test)[:, 1] / n_splits\n        test_cat += m_cat.predict_proba(X_test)[:, 1] / n_splits\n\n        fold_auc = roc_auc_score(y_va, pv_eq)\n        print(f\"Fold {fold} AUC (equal-blend): {fold_auc:.5f} | {time.time()-t0:.1f}s\")\n\n    # --- Per-model OOF AUCs ---\n    auc_xgb = roc_auc_score(y, oof_xgb)\n    auc_lgb = roc_auc_score(y, oof_lgb)\n    auc_cat = roc_auc_score(y, oof_cat)\n    auc_eq  = roc_auc_score(y, oof_eq)\n\n    print(\"\\nPer-model OOF AUCs:\")\n    print(f\"  XGB: {auc_xgb:.6f}\")\n    print(f\"  LGB: {auc_lgb:.6f}\")\n    print(f\"  CAT: {auc_cat:.6f}\")\n    print(f\"  Equal-blend OOF AUC: {auc_eq:.6f}\")\n\n    # --- AUC^2 weights ---\n    w_raw = np.array([auc_xgb**2, auc_lgb**2, auc_cat**2], dtype=float)\n    w = w_raw / w_raw.sum()\n    print(f\"\\nBlend weights (AUC^2 normalized): XGB={w[0]:.4f}, LGB={w[1]:.4f}, CAT={w[2]:.4f}\")\n\n    # --- Weighted OOF & Test ---\n    oof_w = w[0]*oof_xgb + w[1]*oof_lgb + w[2]*oof_cat\n    auc_w = roc_auc_score(y, oof_w)\n    print(f\"Weighted-blend OOF AUC: {auc_w:.6f} (vs equal {auc_eq:.6f})\")\n\n    test_w = w[0]*test_xgb + w[1]*test_lgb + w[2]*test_cat\n    test_eq = (test_xgb + test_lgb + test_cat) / 3.0\n\n    # --- Save submissions ---\n    sub_eq = pd.DataFrame({\"id\": test_ids, \"y\": test_eq})\n    sub_w  = pd.DataFrame({\"id\": test_ids, \"y\": test_w})\n\n    fname_eq = f\"submission_{label_base}.csv\"\n    fname_w  = f\"submission_{label_base}_wblend.csv\"\n\n    sub_eq.to_csv(fname_eq, index=False)\n    sub_w.to_csv(fname_w, index=False)\n\n    print(f\"Saved {fname_eq} (equal blend) and {fname_w} (AUC^2‑weighted)\")\n\n    # Return everything useful\n    per_model_aucs = {\"xgb\": auc_xgb, \"lgb\": auc_lgb, \"cat\": auc_cat, \"equal_blend\": auc_eq, \"weighted_blend\": auc_w}\n    weights = {\"xgb\": w[0], \"lgb\": w[1], \"cat\": w[2]}\n    test_preds = {\"equal\": test_eq, \"weighted\": test_w}\n    oof_preds  = {\"xgb\": oof_xgb, \"lgb\": oof_lgb, \"cat\": oof_cat, \"equal\": oof_eq, \"weighted\": oof_w}\n\n    return oof_preds, test_preds, per_model_aucs, weights\n\n# === Train with best params & save both submissions ===\noof_dict, test_dict, aucs_dict, weights = train_and_predict_with_weights(\n    X_train_with_leak, y, X_test_with_leak, test_ids,\n    xgb_best, lgb_best, cat_best,\n    label_base=\"with_leak_optuna\", n_splits=5\n)\n\nprint(\"\\nFinal weights:\", weights)\nprint(\"Final AUCs:\", {k: f\"{v:.6f}\" for k, v in aucs_dict.items()})\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T07:22:35.403430Z","iopub.execute_input":"2025-08-25T07:22:35.403672Z","iopub.status.idle":"2025-08-25T07:33:13.107527Z","shell.execute_reply.started":"2025-08-25T07:22:35.403655Z","shell.execute_reply":"2025-08-25T07:33:13.106786Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"CV (with_leak_optuna):   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"472ac45adf934047836d679b2e51cf0b"}},"metadata":{}},{"name":"stdout","text":"Training until validation scores don't improve for 100 rounds\nEarly stopping, best iteration is:\n[1447]\tvalid_0's auc: 0.966185\n","output_type":"stream"},{"name":"stderr","text":"Default metric period is 5 because AUC is/are not implemented for GPU\n","output_type":"stream"},{"name":"stdout","text":"Fold 1 AUC (equal-blend): 0.96652 | 128.2s\nTraining until validation scores don't improve for 100 rounds\nEarly stopping, best iteration is:\n[1296]\tvalid_0's auc: 0.966463\n","output_type":"stream"},{"name":"stderr","text":"Default metric period is 5 because AUC is/are not implemented for GPU\n","output_type":"stream"},{"name":"stdout","text":"Fold 2 AUC (equal-blend): 0.96675 | 123.1s\nTraining until validation scores don't improve for 100 rounds\nEarly stopping, best iteration is:\n[1383]\tvalid_0's auc: 0.966665\n","output_type":"stream"},{"name":"stderr","text":"Default metric period is 5 because AUC is/are not implemented for GPU\n","output_type":"stream"},{"name":"stdout","text":"Fold 3 AUC (equal-blend): 0.96713 | 126.7s\nTraining until validation scores don't improve for 100 rounds\nEarly stopping, best iteration is:\n[1417]\tvalid_0's auc: 0.966698\n","output_type":"stream"},{"name":"stderr","text":"Default metric period is 5 because AUC is/are not implemented for GPU\n","output_type":"stream"},{"name":"stdout","text":"Fold 4 AUC (equal-blend): 0.96707 | 126.7s\nTraining until validation scores don't improve for 100 rounds\nEarly stopping, best iteration is:\n[1468]\tvalid_0's auc: 0.967022\n","output_type":"stream"},{"name":"stderr","text":"Default metric period is 5 because AUC is/are not implemented for GPU\n","output_type":"stream"},{"name":"stdout","text":"Fold 5 AUC (equal-blend): 0.96730 | 129.2s\n\nPer-model OOF AUCs:\n  XGB: 0.966694\n  LGB: 0.966605\n  CAT: 0.964647\n  Equal-blend OOF AUC: 0.966951\n\nBlend weights (AUC^2 normalized): XGB=0.3338, LGB=0.3338, CAT=0.3324\nWeighted-blend OOF AUC: 0.966953 (vs equal 0.966951)\nSaved submission_with_leak_optuna.csv (equal blend) and submission_with_leak_optuna_wblend.csv (AUC^2‑weighted)\n\nFinal weights: {'xgb': 0.33382467260115745, 'lgb': 0.3337629946624783, 'cat': 0.3324123327363643}\nFinal AUCs: {'xgb': '0.966694', 'lgb': '0.966605', 'cat': '0.964647', 'equal_blend': '0.966951', 'weighted_blend': '0.966953'}\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}