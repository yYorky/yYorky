{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":18599,"databundleVersionId":1236839,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/yorkyong/m5-forecasting-autogluon-scalability?scriptVersionId=205931189\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"<div class =\"alert alert-block alert-warning\">\n    \n- This notebook aims to apply AutoGluon-TimeSeries as covered by https://paperswithcode.com/paper/autogluon-timeseries-automl-for-probabilistic on the M5 dataset\n\n- we aim to deploy it and run on the validation set having successfully implemented on 1 time-series in https://www.kaggle.com/code/yorkyong/m5-forecasting-autogluon-1series","metadata":{}},{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"pip install autogluon thinc==8.2.5","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-11-08T04:31:40.953647Z","iopub.execute_input":"2024-11-08T04:31:40.954231Z","iopub.status.idle":"2024-11-08T04:36:58.20631Z","shell.execute_reply.started":"2024-11-08T04:31:40.954162Z","shell.execute_reply":"2024-11-08T04:36:58.203453Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting autogluon\n  Downloading autogluon-1.1.1-py3-none-any.whl.metadata (11 kB)\nCollecting thinc==8.2.5\n  Downloading thinc-8.2.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\nCollecting blis<0.8.0,>=0.7.8 (from thinc==8.2.5)\n  Downloading blis-0.7.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\nRequirement already satisfied: murmurhash<1.1.0,>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from thinc==8.2.5) (1.0.10)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from thinc==8.2.5) (2.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from thinc==8.2.5) (3.0.9)\nRequirement already satisfied: wasabi<1.2.0,>=0.8.1 in /opt/conda/lib/python3.10/site-packages (from thinc==8.2.5) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from thinc==8.2.5) (2.4.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.4 in /opt/conda/lib/python3.10/site-packages (from thinc==8.2.5) (2.0.10)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc==8.2.5) (0.1.5)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from thinc==8.2.5) (70.0.0)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from thinc==8.2.5) (2.9.2)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from thinc==8.2.5) (21.3)\nRequirement already satisfied: numpy<2.0.0,>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from thinc==8.2.5) (1.26.4)\nCollecting autogluon.core==1.1.1 (from autogluon.core[all]==1.1.1->autogluon)\n  Downloading autogluon.core-1.1.1-py3-none-any.whl.metadata (11 kB)\nCollecting autogluon.features==1.1.1 (from autogluon)\n  Downloading autogluon.features-1.1.1-py3-none-any.whl.metadata (11 kB)\nCollecting autogluon.tabular==1.1.1 (from autogluon.tabular[all]==1.1.1->autogluon)\n  Downloading autogluon.tabular-1.1.1-py3-none-any.whl.metadata (13 kB)\nCollecting autogluon.multimodal==1.1.1 (from autogluon)\n  Downloading autogluon.multimodal-1.1.1-py3-none-any.whl.metadata (12 kB)\nCollecting autogluon.timeseries==1.1.1 (from autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading autogluon.timeseries-1.1.1-py3-none-any.whl.metadata (12 kB)\nCollecting scipy<1.13,>=1.5.4 (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n  Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting scikit-learn<1.4.1,>=1.3.0 (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n  Downloading scikit_learn-1.4.0-1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: networkx<4,>=3.0 in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.3)\nRequirement already satisfied: pandas<2.3.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2.2.3)\nRequirement already satisfied: tqdm<5,>=4.38 in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (4.66.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2.32.3)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.7.5)\nRequirement already satisfied: boto3<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.26.100)\nCollecting autogluon.common==1.1.1 (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n  Downloading autogluon.common-1.1.1-py3-none-any.whl.metadata (11 kB)\nCollecting ray<2.11,>=2.10.0 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n  Downloading ray-2.10.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (13 kB)\nRequirement already satisfied: hyperopt<0.2.8,>=0.2.7 in /opt/conda/lib/python3.10/site-packages (from autogluon.core[all]==1.1.1->autogluon) (0.2.7)\nRequirement already satisfied: Pillow<11,>=10.0.1 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (10.3.0)\nCollecting torch<2.4,>=2.2 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\nCollecting lightning<2.4,>=2.2 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading lightning-2.3.3-py3-none-any.whl.metadata (35 kB)\nCollecting transformers<4.41.0,>=4.38.0 (from transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon)\n  Downloading transformers-4.40.2-py3-none-any.whl.metadata (137 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting accelerate<0.22.0,>=0.21.0 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)\nCollecting jsonschema<4.22,>=4.18 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading jsonschema-4.21.1-py3-none-any.whl.metadata (7.8 kB)\nCollecting seqeval<1.3.0,>=1.2.2 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting evaluate<0.5.0,>=0.4.0 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nCollecting timm<0.10.0,>=0.9.5 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading timm-0.9.16-py3-none-any.whl.metadata (38 kB)\nCollecting torchvision<0.19.0,>=0.16.0 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\nCollecting scikit-image<0.21.0,>=0.19.1 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading scikit_image-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\nRequirement already satisfied: text-unidecode<1.4,>=1.3 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (1.3)\nCollecting torchmetrics<1.3.0,>=1.2.0 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading torchmetrics-1.2.1-py3-none-any.whl.metadata (20 kB)\nCollecting nptyping<2.5.0,>=1.4.4 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading nptyping-2.4.1-py3-none-any.whl.metadata (7.7 kB)\nCollecting omegaconf<2.3.0,>=2.1.1 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading omegaconf-2.2.3-py3-none-any.whl.metadata (3.9 kB)\nCollecting pytorch-metric-learning<2.4,>=1.3.0 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading pytorch_metric_learning-2.3.0-py3-none-any.whl.metadata (17 kB)\nCollecting nlpaug<1.2.0,>=1.1.10 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\nCollecting nltk<4.0.0,>=3.4.5 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\nCollecting openmim<0.4.0,>=0.3.7 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading openmim-0.3.9-py2.py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: defusedxml<0.7.2,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (0.7.1)\nRequirement already satisfied: jinja2<3.2,>=3.0.3 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (3.1.4)\nRequirement already satisfied: tensorboard<3,>=2.9 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (2.16.2)\nCollecting pytesseract<0.3.11,>=0.3.9 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading pytesseract-0.3.10-py3-none-any.whl.metadata (11 kB)\nCollecting nvidia-ml-py3==7.352.0 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: pdf2image<1.19,>=1.17.0 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (1.17.0)\nRequirement already satisfied: xgboost<2.1,>=1.6 in /opt/conda/lib/python3.10/site-packages (from autogluon.tabular[all]==1.1.1->autogluon) (2.0.3)\nRequirement already satisfied: fastai<2.8,>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from autogluon.tabular[all]==1.1.1->autogluon) (2.7.17)\nRequirement already satisfied: lightgbm<4.4,>=3.3 in /opt/conda/lib/python3.10/site-packages (from autogluon.tabular[all]==1.1.1->autogluon) (4.2.0)\nRequirement already satisfied: catboost<1.3,>=1.1 in /opt/conda/lib/python3.10/site-packages (from autogluon.tabular[all]==1.1.1->autogluon) (1.2.7)\nRequirement already satisfied: joblib<2,>=1.1 in /opt/conda/lib/python3.10/site-packages (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (1.4.2)\nCollecting pytorch-lightning<2.4,>=2.2 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading pytorch_lightning-2.3.3-py3-none-any.whl.metadata (21 kB)\nCollecting gluonts==0.15.1 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading gluonts-0.15.1-py3-none-any.whl.metadata (9.9 kB)\nCollecting statsforecast<1.5,>=1.4.0 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading statsforecast-1.4.0-py3-none-any.whl.metadata (19 kB)\nCollecting mlforecast<0.10.1,>=0.10.0 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading mlforecast-0.10.0-py3-none-any.whl.metadata (11 kB)\nCollecting utilsforecast<0.0.11,>=0.0.10 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading utilsforecast-0.0.10-py3-none-any.whl.metadata (7.0 kB)\nRequirement already satisfied: orjson~=3.9 in /opt/conda/lib/python3.10/site-packages (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (3.10.4)\nCollecting optimum<1.19,>=1.17 (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading optimum-1.18.1-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: psutil<6,>=5.7.3 in /opt/conda/lib/python3.10/site-packages (from autogluon.common==1.1.1->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (5.9.3)\nRequirement already satisfied: toolz~=0.10 in /opt/conda/lib/python3.10/site-packages (from gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.12.1)\nRequirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.10/site-packages (from gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->thinc==8.2.5) (3.1.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->thinc==8.2.5) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->thinc==8.2.5) (2.23.4)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate<0.22.0,>=0.21.0->autogluon.multimodal==1.1.1->autogluon) (6.0.2)\nCollecting botocore<1.30.0,>=1.29.100 (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n  Downloading botocore-1.29.165-py3-none-any.whl.metadata (5.9 kB)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.0.1)\nRequirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (0.6.2)\nRequirement already satisfied: graphviz in /opt/conda/lib/python3.10/site-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (0.20.3)\nRequirement already satisfied: plotly in /opt/conda/lib/python3.10/site-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (5.22.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (1.16.0)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (3.0.1)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (0.3.8)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (2024.6.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (0.25.1)\nRequirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (24.0)\nRequirement already satisfied: fastdownload<2,>=0.0.5 in /opt/conda/lib/python3.10/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.0.7)\nRequirement already satisfied: fastcore<1.8,>=1.5.29 in /opt/conda/lib/python3.10/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.7.10)\nRequirement already satisfied: fastprogress>=0.2.4 in /opt/conda/lib/python3.10/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.0.3)\nRequirement already satisfied: spacy<4 in /opt/conda/lib/python3.10/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (3.8.2)\nRequirement already satisfied: future in /opt/conda/lib/python3.10/site-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.1->autogluon) (1.0.0)\nRequirement already satisfied: cloudpickle in /opt/conda/lib/python3.10/site-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.1->autogluon) (3.0.0)\nRequirement already satisfied: py4j in /opt/conda/lib/python3.10/site-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.1->autogluon) (0.10.9.7)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2<3.2,>=3.0.3->autogluon.multimodal==1.1.1->autogluon) (2.1.5)\nRequirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon) (23.2.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon) (0.35.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon) (0.18.1)\nRequirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from lightning<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon) (0.11.7)\nRequirement already satisfied: numba in /opt/conda/lib/python3.10/site-packages (from mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.60.0)\nCollecting window-ops (from mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading window_ops-0.0.15-py3-none-any.whl.metadata (6.8 kB)\nCollecting gdown>=4.0.0 (from nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon)\n  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==1.1.1->autogluon) (8.1.7)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==1.1.1->autogluon) (2024.5.15)\nCollecting antlr4-python3-runtime==4.9.* (from omegaconf<2.3.0,>=2.1.1->autogluon.multimodal==1.1.1->autogluon)\n  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (0.4.6)\nCollecting model-index (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n  Downloading model_index-0.1.11-py3-none-any.whl.metadata (3.9 kB)\nCollecting opendatalab (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n  Downloading opendatalab-0.0.10-py3-none-any.whl.metadata (6.4 kB)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (13.7.1)\nRequirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (0.9.0)\nCollecting coloredlogs (from optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (1.12)\nCollecting transformers<4.41.0,>=4.38.0 (from transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon)\n  Downloading transformers-4.39.3-py3-none-any.whl.metadata (134 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: onnx in /opt/conda/lib/python3.10/site-packages (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (1.17.0)\nCollecting onnxruntime>=1.11.0 (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading onnxruntime-1.20.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.4 kB)\nRequirement already satisfied: protobuf>=3.20.1 in /opt/conda/lib/python3.10/site-packages (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (3.20.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2024.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (3.15.1)\nRequirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.0.8)\nRequirement already satisfied: aiosignal in /opt/conda/lib/python3.10/site-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.3.1)\nRequirement already satisfied: frozenlist in /opt/conda/lib/python3.10/site-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.4.1)\nRequirement already satisfied: aiohttp>=3.7 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (3.9.5)\nCollecting aiohttp-cors (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n  Downloading aiohttp_cors-0.7.0-py3-none-any.whl.metadata (20 kB)\nRequirement already satisfied: colorful in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.5.6)\nRequirement already satisfied: py-spy>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.3.14)\nRequirement already satisfied: opencensus in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.11.4)\nRequirement already satisfied: prometheus-client>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.20.0)\nRequirement already satisfied: smart-open in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (7.0.4)\nRequirement already satisfied: virtualenv!=20.21.1,>=20.0.24 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (20.21.0)\nRequirement already satisfied: grpcio>=1.42.0 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.64.1)\nRequirement already satisfied: tensorboardX>=1.9 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (2.6.2.2)\nRequirement already satisfied: pyarrow>=6.0.1 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (17.0.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2024.8.30)\nRequirement already satisfied: imageio>=2.4.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon) (2.34.1)\nRequirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.10/site-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon) (2024.5.22)\nRequirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon) (1.6.0)\nRequirement already satisfied: lazy_loader>=0.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon) (0.4)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<1.4.1,>=1.3.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.5.0)\nRequirement already satisfied: statsmodels>=0.13.2 in /opt/conda/lib/python3.10/site-packages (from statsforecast<1.5,>=1.4.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.14.2)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (1.4.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (3.6)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (3.0.4)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm<0.10.0,>=0.9.5->autogluon.multimodal==1.1.1->autogluon) (0.4.5)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.1.3.1 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.0.2.54 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.2.106 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.20.5 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.1.105 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\nCollecting triton==2.3.1 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_nvjitlink_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting tokenizers<0.19,>=0.14 (from transformers<4.41.0,>=4.38.0->transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon)\n  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon) (0.2.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.4.5)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (4.0.3)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon) (4.12.3)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba->mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.43.0)\nRequirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.11.0->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (24.3.25)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.0.5)\nINFO: pip is looking at multiple versions of spacy to determine which version is compatible with other requirements. This could take a while.\nCollecting spacy<4 (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\n  Downloading spacy-3.7.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.12.3)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (3.4.1)\nRequirement already satisfied: patsy>=0.5.6 in /opt/conda/lib/python3.10/site-packages (from statsmodels>=0.13.2->statsforecast<1.5,>=1.4.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.5.6)\nRequirement already satisfied: distlib<1,>=0.3.6 in /opt/conda/lib/python3.10/site-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.3.8)\nRequirement already satisfied: platformdirs<4,>=2.4 in /opt/conda/lib/python3.10/site-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (3.11.0)\nCollecting humanfriendly>=9.1 (from coloredlogs->optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nCollecting ordered-set (from model-index->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n  Downloading ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\nRequirement already satisfied: opencensus-context>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.1.3)\nRequirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (2.11.1)\nRequirement already satisfied: pycryptodome in /opt/conda/lib/python3.10/site-packages (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (3.20.0)\nCollecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n  Downloading openxlab-0.1.2-py3-none-any.whl.metadata (3.8 kB)\nRequirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly->catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (8.3.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (2.18.0)\nRequirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from smart-open->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.16.0)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (1.3.0)\nRequirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.63.1)\nRequirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (2.30.0)\nRequirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.2.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (0.1.2)\nRequirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.5.4)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.19.0)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon) (2.5)\nCollecting filelock (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\nCollecting oss2~=2.17.0 (from openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n  Downloading oss2-2.17.0.tar.gz (259 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting packaging>=20.0 (from thinc==8.2.5)\n  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\nCollecting pytz>=2020.1 (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n  Downloading pytz-2023.4-py2.py3-none-any.whl.metadata (22 kB)\nINFO: pip is looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\nCollecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n  Downloading openxlab-0.1.1-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.1.0-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.38-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.37-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.36-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.35-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.34-py3-none-any.whl.metadata (3.8 kB)\nINFO: pip is still looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\n  Downloading openxlab-0.0.33-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.32-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.31-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.30-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.29-py3-none-any.whl.metadata (3.8 kB)\nINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n  Downloading openxlab-0.0.28-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.27-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.26-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.25-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.24-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.23-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.22-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.21-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.20-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.19-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.18-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.17-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.16-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.15-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.14-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.13-py3-none-any.whl.metadata (4.5 kB)\n  Downloading openxlab-0.0.12-py3-none-any.whl.metadata (4.5 kB)\n  Downloading openxlab-0.0.11-py3-none-any.whl.metadata (4.3 kB)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon) (1.7.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.4.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (4.9)\nRequirement already satisfied: marisa-trie>=0.7.7 in /opt/conda/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.2.0)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.6.0)\nDownloading thinc-8.2.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (922 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m922.4/922.4 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading autogluon-1.1.1-py3-none-any.whl (9.7 kB)\nDownloading autogluon.core-1.1.1-py3-none-any.whl (234 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m234.8/234.8 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading autogluon.features-1.1.1-py3-none-any.whl (63 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.4/63.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading autogluon.multimodal-1.1.1-py3-none-any.whl (427 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m428.0/428.0 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading autogluon.tabular-1.1.1-py3-none-any.whl (312 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.1/312.1 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading autogluon.timeseries-1.1.1-py3-none-any.whl (148 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.2/148.2 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading autogluon.common-1.1.1-py3-none-any.whl (64 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.6/64.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading gluonts-0.15.1-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading blis-0.7.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading jsonschema-4.21.1-py3-none-any.whl (85 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading lightning-2.3.3-py3-none-any.whl (808 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m808.5/808.5 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading mlforecast-0.10.0-py3-none-any.whl (47 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.6/47.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading nptyping-2.4.1-py3-none-any.whl (36 kB)\nDownloading omegaconf-2.2.3-py3-none-any.whl (79 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading optimum-1.18.1-py3-none-any.whl (410 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.0/410.0 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\nDownloading pytorch_lightning-2.3.3-py3-none-any.whl (812 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.3/812.3 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pytorch_metric_learning-2.3.0-py3-none-any.whl (115 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ray-2.10.0-cp310-cp310-manylinux2014_x86_64.whl (65.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.1/65.1 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading scikit_image-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading scikit_learn-1.4.0-1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading statsforecast-1.4.0-py3-none-any.whl (91 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading timm-0.9.16-py3-none-any.whl (2.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torchmetrics-1.2.1-py3-none-any.whl (806 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.1/806.1 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading transformers-4.39.3-py3-none-any.whl (8.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading utilsforecast-0.0.10-py3-none-any.whl (30 kB)\nDownloading botocore-1.29.165-py3-none-any.whl (11.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading gdown-5.2.0-py3-none-any.whl (18 kB)\nDownloading onnxruntime-1.20.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading spacy-3.7.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\nDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading model_index-0.1.11-py3-none-any.whl (34 kB)\nDownloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\nDownloading window_ops-0.0.15-py3-none-any.whl (15 kB)\nDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading openxlab-0.0.11-py3-none-any.whl (55 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\nBuilding wheels for collected packages: nvidia-ml-py3, antlr4-python3-runtime, seqeval\n  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19172 sha256=30c9076e91b9ddc3366381c1cc0ae27440c535a5fa14a85fc9b89d4ea60b369d\n  Stored in directory: /root/.cache/pip/wheels/5c/d8/c0/46899f8be7a75a2ffd197a23c8797700ea858b9b34819fbf9e\n  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=39d5fcf330157664783f5289ab7d42a824a9f08c2ee83d50a548762ffcecc4bf\n  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=11be429ec0c0f3de1771ead4ebb41d6037c15673b517124ca8a846e3d6093699\n  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\nSuccessfully built nvidia-ml-py3 antlr4-python3-runtime seqeval\nInstalling collected packages: nvidia-ml-py3, antlr4-python3-runtime, triton, scipy, ordered-set, openxlab, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nptyping, nltk, humanfriendly, blis, window-ops, scikit-learn, pytesseract, nvidia-cusparse-cu12, nvidia-cudnn-cu12, model-index, coloredlogs, botocore, utilsforecast, tokenizers, seqeval, scikit-image, opendatalab, onnxruntime, nvidia-cusolver-cu12, jsonschema, gluonts, gdown, aiohttp-cors, transformers, torch, thinc, statsforecast, ray, openmim, nlpaug, mlforecast, torchvision, torchmetrics, spacy, pytorch-metric-learning, evaluate, autogluon.common, accelerate, timm, pytorch-lightning, optimum, autogluon.features, autogluon.core, lightning, autogluon.tabular, autogluon.multimodal, autogluon.timeseries, autogluon\n  Attempting uninstall: scipy\n    Found existing installation: scipy 1.14.1\n    Uninstalling scipy-1.14.1:\n      Successfully uninstalled scipy-1.14.1\n  Attempting uninstall: nltk\n    Found existing installation: nltk 3.2.4\n    Uninstalling nltk-3.2.4:\n      Successfully uninstalled nltk-3.2.4\n  Attempting uninstall: blis\n    Found existing installation: blis 1.0.1\n    Uninstalling blis-1.0.1:\n      Successfully uninstalled blis-1.0.1\n  Attempting uninstall: scikit-learn\n    Found existing installation: scikit-learn 1.2.2\n    Uninstalling scikit-learn-1.2.2:\n      Successfully uninstalled scikit-learn-1.2.2\n  Attempting uninstall: pytesseract\n    Found existing installation: pytesseract 0.3.13\n    Uninstalling pytesseract-0.3.13:\n      Successfully uninstalled pytesseract-0.3.13\n  Attempting uninstall: botocore\n    Found existing installation: botocore 1.35.23\n    Uninstalling botocore-1.35.23:\n      Successfully uninstalled botocore-1.35.23\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.20.0\n    Uninstalling tokenizers-0.20.0:\n      Successfully uninstalled tokenizers-0.20.0\n  Attempting uninstall: scikit-image\n    Found existing installation: scikit-image 0.23.2\n    Uninstalling scikit-image-0.23.2:\n      Successfully uninstalled scikit-image-0.23.2\n  Attempting uninstall: jsonschema\n    Found existing installation: jsonschema 4.22.0\n    Uninstalling jsonschema-4.22.0:\n      Successfully uninstalled jsonschema-4.22.0\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.45.1\n    Uninstalling transformers-4.45.1:\n      Successfully uninstalled transformers-4.45.1\n  Attempting uninstall: torch\n    Found existing installation: torch 2.4.0+cpu\n    Uninstalling torch-2.4.0+cpu:\n      Successfully uninstalled torch-2.4.0+cpu\n  Attempting uninstall: thinc\n    Found existing installation: thinc 8.3.2\n    Uninstalling thinc-8.3.2:\n      Successfully uninstalled thinc-8.3.2\n  Attempting uninstall: ray\n    Found existing installation: ray 2.24.0\n    Uninstalling ray-2.24.0:\n      Successfully uninstalled ray-2.24.0\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.19.0+cpu\n    Uninstalling torchvision-0.19.0+cpu:\n      Successfully uninstalled torchvision-0.19.0+cpu\n  Attempting uninstall: torchmetrics\n    Found existing installation: torchmetrics 1.4.2\n    Uninstalling torchmetrics-1.4.2:\n      Successfully uninstalled torchmetrics-1.4.2\n  Attempting uninstall: spacy\n    Found existing installation: spacy 3.8.2\n    Uninstalling spacy-3.8.2:\n      Successfully uninstalled spacy-3.8.2\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.34.2\n    Uninstalling accelerate-0.34.2:\n      Successfully uninstalled accelerate-0.34.2\n  Attempting uninstall: timm\n    Found existing installation: timm 1.0.9\n    Uninstalling timm-1.0.9:\n      Successfully uninstalled timm-1.0.9\n  Attempting uninstall: pytorch-lightning\n    Found existing installation: pytorch-lightning 2.4.0\n    Uninstalling pytorch-lightning-2.4.0:\n      Successfully uninstalled pytorch-lightning-2.4.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\naiobotocore 2.15.1 requires botocore<1.35.24,>=1.35.16, but you have botocore 1.29.165 which is incompatible.\nalbumentations 1.4.17 requires scikit-image>=0.21.0, but you have scikit-image 0.20.0 which is incompatible.\nbigframes 0.22.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.10.0, but you have google-cloud-bigquery 2.34.4 which is incompatible.\nbigframes 0.22.0 requires google-cloud-storage>=2.0.0, but you have google-cloud-storage 1.44.0 which is incompatible.\nbigframes 0.22.0 requires pandas<2.1.4,>=1.5.0, but you have pandas 2.2.3 which is incompatible.\ncesium 0.12.3 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ndataproc-jupyter-plugin 0.1.79 requires pydantic~=1.10.0, but you have pydantic 2.9.2 which is incompatible.\njupyterlab 4.2.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\npreprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.9.1 which is incompatible.\ntorchaudio 2.4.0+cpu requires torch==2.4.0, but you have torch 2.3.1 which is incompatible.\ntsfresh 0.20.3 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.12.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed accelerate-0.21.0 aiohttp-cors-0.7.0 antlr4-python3-runtime-4.9.3 autogluon-1.1.1 autogluon.common-1.1.1 autogluon.core-1.1.1 autogluon.features-1.1.1 autogluon.multimodal-1.1.1 autogluon.tabular-1.1.1 autogluon.timeseries-1.1.1 blis-0.7.11 botocore-1.29.165 coloredlogs-15.0.1 evaluate-0.4.3 gdown-5.2.0 gluonts-0.15.1 humanfriendly-10.0 jsonschema-4.21.1 lightning-2.3.3 mlforecast-0.10.0 model-index-0.1.11 nlpaug-1.1.11 nltk-3.9.1 nptyping-2.4.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-ml-py3-7.352.0 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.77 nvidia-nvtx-cu12-12.1.105 omegaconf-2.2.3 onnxruntime-1.20.0 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.0.11 optimum-1.18.1 ordered-set-4.1.0 pytesseract-0.3.10 pytorch-lightning-2.3.3 pytorch-metric-learning-2.3.0 ray-2.10.0 scikit-image-0.20.0 scikit-learn-1.4.0 scipy-1.12.0 seqeval-1.2.2 spacy-3.7.5 statsforecast-1.4.0 thinc-8.2.5 timm-0.9.16 tokenizers-0.15.2 torch-2.3.1 torchmetrics-1.2.1 torchvision-0.18.1 transformers-4.39.3 triton-2.3.1 utilsforecast-0.0.10 window-ops-0.0.15\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import gc\nimport os\nimport psutil\n\nimport pandas as pd  # For data manipulation\nimport numpy as np  # For numerical operations\nimport warnings  # To suppress warnings\nfrom autogluon.timeseries import TimeSeriesDataFrame, TimeSeriesPredictor\nfrom autogluon.timeseries.utils.forecast import get_forecast_horizon_index_ts_dataframe\nfrom sklearn.preprocessing import LabelEncoder\n\nwarnings.filterwarnings('ignore')  # Suppress warnings for cleaner output\n\nimport random  # For generating random numbers\n\n# Function to set a fixed random seed for reproducibility\ndef seed_everything(seed):\n    np.random.seed(seed)  # Set numpy random seed\n    random.seed(seed)  # Set built-in random seed\n\nseed_everything(seed=2024)  # Set the seed to 2024\n","metadata":{"execution":{"iopub.status.busy":"2024-11-08T04:36:58.211746Z","iopub.execute_input":"2024-11-08T04:36:58.212452Z","iopub.status.idle":"2024-11-08T04:37:01.157232Z","shell.execute_reply.started":"2024-11-08T04:36:58.212385Z","shell.execute_reply":"2024-11-08T04:37:01.155943Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Load Dataset","metadata":{}},{"cell_type":"code","source":"calendar = pd.read_csv(\"/kaggle/input/m5-forecasting-accuracy/calendar.csv\")  # Load calendar dataset\nprint(f\"len(calendar):{len(calendar)}\")  # Print the number of rows in calendar\ncalendar","metadata":{"execution":{"iopub.status.busy":"2024-11-08T04:37:01.158706Z","iopub.execute_input":"2024-11-08T04:37:01.15934Z","iopub.status.idle":"2024-11-08T04:37:01.241849Z","shell.execute_reply.started":"2024-11-08T04:37:01.159294Z","shell.execute_reply":"2024-11-08T04:37:01.240537Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"len(calendar):1969\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"            date  wm_yr_wk    weekday  wday  month  year       d  \\\n0     2011-01-29     11101   Saturday     1      1  2011     d_1   \n1     2011-01-30     11101     Sunday     2      1  2011     d_2   \n2     2011-01-31     11101     Monday     3      1  2011     d_3   \n3     2011-02-01     11101    Tuesday     4      2  2011     d_4   \n4     2011-02-02     11101  Wednesday     5      2  2011     d_5   \n...          ...       ...        ...   ...    ...   ...     ...   \n1964  2016-06-15     11620  Wednesday     5      6  2016  d_1965   \n1965  2016-06-16     11620   Thursday     6      6  2016  d_1966   \n1966  2016-06-17     11620     Friday     7      6  2016  d_1967   \n1967  2016-06-18     11621   Saturday     1      6  2016  d_1968   \n1968  2016-06-19     11621     Sunday     2      6  2016  d_1969   \n\n      event_name_1 event_type_1  event_name_2 event_type_2  snap_CA  snap_TX  \\\n0              NaN          NaN           NaN          NaN        0        0   \n1              NaN          NaN           NaN          NaN        0        0   \n2              NaN          NaN           NaN          NaN        0        0   \n3              NaN          NaN           NaN          NaN        1        1   \n4              NaN          NaN           NaN          NaN        1        0   \n...            ...          ...           ...          ...      ...      ...   \n1964           NaN          NaN           NaN          NaN        0        1   \n1965           NaN          NaN           NaN          NaN        0        0   \n1966           NaN          NaN           NaN          NaN        0        0   \n1967           NaN          NaN           NaN          NaN        0        0   \n1968  NBAFinalsEnd     Sporting  Father's day     Cultural        0        0   \n\n      snap_WI  \n0           0  \n1           0  \n2           0  \n3           0  \n4           1  \n...       ...  \n1964        1  \n1965        0  \n1966        0  \n1967        0  \n1968        0  \n\n[1969 rows x 14 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>wm_yr_wk</th>\n      <th>weekday</th>\n      <th>wday</th>\n      <th>month</th>\n      <th>year</th>\n      <th>d</th>\n      <th>event_name_1</th>\n      <th>event_type_1</th>\n      <th>event_name_2</th>\n      <th>event_type_2</th>\n      <th>snap_CA</th>\n      <th>snap_TX</th>\n      <th>snap_WI</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2011-01-29</td>\n      <td>11101</td>\n      <td>Saturday</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2011</td>\n      <td>d_1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2011-01-30</td>\n      <td>11101</td>\n      <td>Sunday</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2011</td>\n      <td>d_2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2011-01-31</td>\n      <td>11101</td>\n      <td>Monday</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2011</td>\n      <td>d_3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2011-02-01</td>\n      <td>11101</td>\n      <td>Tuesday</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2011</td>\n      <td>d_4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2011-02-02</td>\n      <td>11101</td>\n      <td>Wednesday</td>\n      <td>5</td>\n      <td>2</td>\n      <td>2011</td>\n      <td>d_5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1964</th>\n      <td>2016-06-15</td>\n      <td>11620</td>\n      <td>Wednesday</td>\n      <td>5</td>\n      <td>6</td>\n      <td>2016</td>\n      <td>d_1965</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1965</th>\n      <td>2016-06-16</td>\n      <td>11620</td>\n      <td>Thursday</td>\n      <td>6</td>\n      <td>6</td>\n      <td>2016</td>\n      <td>d_1966</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1966</th>\n      <td>2016-06-17</td>\n      <td>11620</td>\n      <td>Friday</td>\n      <td>7</td>\n      <td>6</td>\n      <td>2016</td>\n      <td>d_1967</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1967</th>\n      <td>2016-06-18</td>\n      <td>11621</td>\n      <td>Saturday</td>\n      <td>1</td>\n      <td>6</td>\n      <td>2016</td>\n      <td>d_1968</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1968</th>\n      <td>2016-06-19</td>\n      <td>11621</td>\n      <td>Sunday</td>\n      <td>2</td>\n      <td>6</td>\n      <td>2016</td>\n      <td>d_1969</td>\n      <td>NBAFinalsEnd</td>\n      <td>Sporting</td>\n      <td>Father's day</td>\n      <td>Cultural</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1969 rows × 14 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"sales_train_evaluation = pd.read_csv(\"/kaggle/input/m5-forecasting-accuracy/sales_train_evaluation.csv\")\nprint(f\"len(sales_train_evaluation): {len(sales_train_evaluation)}\")\nsales_train_evaluation.head()","metadata":{"execution":{"iopub.status.busy":"2024-11-08T04:37:01.243613Z","iopub.execute_input":"2024-11-08T04:37:01.244035Z","iopub.status.idle":"2024-11-08T04:37:09.146227Z","shell.execute_reply.started":"2024-11-08T04:37:01.243992Z","shell.execute_reply":"2024-11-08T04:37:09.144883Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"len(sales_train_evaluation): 30490\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                              id        item_id    dept_id   cat_id store_id  \\\n0  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n1  HOBBIES_1_002_CA_1_evaluation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n2  HOBBIES_1_003_CA_1_evaluation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n3  HOBBIES_1_004_CA_1_evaluation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n4  HOBBIES_1_005_CA_1_evaluation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n\n  state_id  d_1  d_2  d_3  d_4  ...  d_1932  d_1933  d_1934  d_1935  d_1936  \\\n0       CA    0    0    0    0  ...       2       4       0       0       0   \n1       CA    0    0    0    0  ...       0       1       2       1       1   \n2       CA    0    0    0    0  ...       1       0       2       0       0   \n3       CA    0    0    0    0  ...       1       1       0       4       0   \n4       CA    0    0    0    0  ...       0       0       0       2       1   \n\n   d_1937  d_1938  d_1939  d_1940  d_1941  \n0       0       3       3       0       1  \n1       0       0       0       0       0  \n2       0       2       3       0       1  \n3       1       3       0       2       6  \n4       0       0       2       1       0  \n\n[5 rows x 1947 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>item_id</th>\n      <th>dept_id</th>\n      <th>cat_id</th>\n      <th>store_id</th>\n      <th>state_id</th>\n      <th>d_1</th>\n      <th>d_2</th>\n      <th>d_3</th>\n      <th>d_4</th>\n      <th>...</th>\n      <th>d_1932</th>\n      <th>d_1933</th>\n      <th>d_1934</th>\n      <th>d_1935</th>\n      <th>d_1936</th>\n      <th>d_1937</th>\n      <th>d_1938</th>\n      <th>d_1939</th>\n      <th>d_1940</th>\n      <th>d_1941</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HOBBIES_1_001_CA_1_evaluation</td>\n      <td>HOBBIES_1_001</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HOBBIES_1_002_CA_1_evaluation</td>\n      <td>HOBBIES_1_002</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HOBBIES_1_003_CA_1_evaluation</td>\n      <td>HOBBIES_1_003</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>HOBBIES_1_004_CA_1_evaluation</td>\n      <td>HOBBIES_1_004</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HOBBIES_1_005_CA_1_evaluation</td>\n      <td>HOBBIES_1_005</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 1947 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"sell_prices = pd.read_csv(\"/kaggle/input/m5-forecasting-accuracy/sell_prices.csv\")\nprint(f\"len(sell_prices):{len(sell_prices)}\")\nsell_prices","metadata":{"execution":{"iopub.status.busy":"2024-11-08T04:37:09.149655Z","iopub.execute_input":"2024-11-08T04:37:09.150093Z","iopub.status.idle":"2024-11-08T04:37:16.044065Z","shell.execute_reply.started":"2024-11-08T04:37:09.150048Z","shell.execute_reply":"2024-11-08T04:37:16.042821Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"len(sell_prices):6841121\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"        store_id        item_id  wm_yr_wk  sell_price\n0           CA_1  HOBBIES_1_001     11325        9.58\n1           CA_1  HOBBIES_1_001     11326        9.58\n2           CA_1  HOBBIES_1_001     11327        8.26\n3           CA_1  HOBBIES_1_001     11328        8.26\n4           CA_1  HOBBIES_1_001     11329        8.26\n...          ...            ...       ...         ...\n6841116     WI_3    FOODS_3_827     11617        1.00\n6841117     WI_3    FOODS_3_827     11618        1.00\n6841118     WI_3    FOODS_3_827     11619        1.00\n6841119     WI_3    FOODS_3_827     11620        1.00\n6841120     WI_3    FOODS_3_827     11621        1.00\n\n[6841121 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>store_id</th>\n      <th>item_id</th>\n      <th>wm_yr_wk</th>\n      <th>sell_price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>CA_1</td>\n      <td>HOBBIES_1_001</td>\n      <td>11325</td>\n      <td>9.58</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CA_1</td>\n      <td>HOBBIES_1_001</td>\n      <td>11326</td>\n      <td>9.58</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>CA_1</td>\n      <td>HOBBIES_1_001</td>\n      <td>11327</td>\n      <td>8.26</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CA_1</td>\n      <td>HOBBIES_1_001</td>\n      <td>11328</td>\n      <td>8.26</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>CA_1</td>\n      <td>HOBBIES_1_001</td>\n      <td>11329</td>\n      <td>8.26</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6841116</th>\n      <td>WI_3</td>\n      <td>FOODS_3_827</td>\n      <td>11617</td>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>6841117</th>\n      <td>WI_3</td>\n      <td>FOODS_3_827</td>\n      <td>11618</td>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>6841118</th>\n      <td>WI_3</td>\n      <td>FOODS_3_827</td>\n      <td>11619</td>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>6841119</th>\n      <td>WI_3</td>\n      <td>FOODS_3_827</td>\n      <td>11620</td>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>6841120</th>\n      <td>WI_3</td>\n      <td>FOODS_3_827</td>\n      <td>11621</td>\n      <td>1.00</td>\n    </tr>\n  </tbody>\n</table>\n<p>6841121 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Enhanced memory optimization function with object datatype handling\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2  # Initial memory usage in MB\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:  # Downcast numerics\n            c_min, c_max = df[col].min(), df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n        elif col_type == 'object':  # Handle object types\n            if col == 'date':  # Convert date column to datetime\n                df[col] = pd.to_datetime(df[col], format='%Y-%m-%d')\n            else:\n                df[col] = df[col].astype('category')  # Convert other object types to category\n    end_mem = df.memory_usage().sum() / 1024**2  # Final memory usage in MB\n    if verbose:\n        print(f'Memory usage reduced to {end_mem:5.2f} Mb ({100 * (start_mem - end_mem) / start_mem:.1f}% reduction)')\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-11-08T04:37:16.045755Z","iopub.execute_input":"2024-11-08T04:37:16.046198Z","iopub.status.idle":"2024-11-08T04:37:16.062702Z","shell.execute_reply.started":"2024-11-08T04:37:16.046157Z","shell.execute_reply":"2024-11-08T04:37:16.061442Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Apply the optimized memory reduction function to each dataframe\ncalendar = reduce_mem_usage(calendar)\nsell_prices = reduce_mem_usage(sell_prices)\nsales_train_evaluation = reduce_mem_usage(sales_train_evaluation)","metadata":{"execution":{"iopub.status.busy":"2024-11-08T04:37:16.064693Z","iopub.execute_input":"2024-11-08T04:37:16.065856Z","iopub.status.idle":"2024-11-08T04:37:19.063527Z","shell.execute_reply.started":"2024-11-08T04:37:16.065779Z","shell.execute_reply":"2024-11-08T04:37:19.062234Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Memory usage reduced to  0.13 Mb (40.4% reduction)\nMemory usage reduced to 45.76 Mb (78.1% reduction)\nMemory usage reduced to 96.30 Mb (78.7% reduction)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Convert Sales Data to Long format","metadata":{}},{"cell_type":"code","source":"# Specify day columns up to d_1941 for the extended dataset\nd_cols_eval = [f\"d_{i}\" for i in range(1, 1942)]\nsales_train_evaluation_long = sales_train_evaluation.melt(\n    id_vars=[\"id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"],\n    value_vars=d_cols_eval,\n    var_name=\"d\",\n    value_name=\"sales\"\n)\nprint(f\"len(sales_train_evaluation_long): {len(sales_train_evaluation_long)}\")\nsales_train_evaluation_long.head()","metadata":{"execution":{"iopub.status.busy":"2024-11-08T04:37:19.065391Z","iopub.execute_input":"2024-11-08T04:37:19.0659Z","iopub.status.idle":"2024-11-08T04:37:32.588565Z","shell.execute_reply.started":"2024-11-08T04:37:19.065833Z","shell.execute_reply":"2024-11-08T04:37:32.587298Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"len(sales_train_evaluation_long): 59181090\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                              id        item_id    dept_id   cat_id store_id  \\\n0  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n1  HOBBIES_1_002_CA_1_evaluation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n2  HOBBIES_1_003_CA_1_evaluation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n3  HOBBIES_1_004_CA_1_evaluation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n4  HOBBIES_1_005_CA_1_evaluation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n\n  state_id    d  sales  \n0       CA  d_1      0  \n1       CA  d_1      0  \n2       CA  d_1      0  \n3       CA  d_1      0  \n4       CA  d_1      0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>item_id</th>\n      <th>dept_id</th>\n      <th>cat_id</th>\n      <th>store_id</th>\n      <th>state_id</th>\n      <th>d</th>\n      <th>sales</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HOBBIES_1_001_CA_1_evaluation</td>\n      <td>HOBBIES_1_001</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HOBBIES_1_002_CA_1_evaluation</td>\n      <td>HOBBIES_1_002</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HOBBIES_1_003_CA_1_evaluation</td>\n      <td>HOBBIES_1_003</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>HOBBIES_1_004_CA_1_evaluation</td>\n      <td>HOBBIES_1_004</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HOBBIES_1_005_CA_1_evaluation</td>\n      <td>HOBBIES_1_005</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Label Endcode Calendar event","metadata":{}},{"cell_type":"code","source":"# Encode event-related features in the calendar dataframe\nevent_columns = ['event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']\nle = LabelEncoder()\nfor col in event_columns:\n    calendar[col] = le.fit_transform(calendar[col].astype(str))","metadata":{"execution":{"iopub.status.busy":"2024-11-08T04:37:32.590503Z","iopub.execute_input":"2024-11-08T04:37:32.591033Z","iopub.status.idle":"2024-11-08T04:37:32.604168Z","shell.execute_reply.started":"2024-11-08T04:37:32.590976Z","shell.execute_reply":"2024-11-08T04:37:32.602827Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Merge with Calender data","metadata":{}},{"cell_type":"code","source":"sales_train_evaluation_long = sales_train_evaluation_long.merge(calendar, on=\"d\", how=\"left\")\nsales_train_evaluation_long.head()","metadata":{"execution":{"iopub.status.busy":"2024-11-08T04:37:32.606011Z","iopub.execute_input":"2024-11-08T04:37:32.606524Z","iopub.status.idle":"2024-11-08T04:38:07.673989Z","shell.execute_reply.started":"2024-11-08T04:37:32.606468Z","shell.execute_reply":"2024-11-08T04:38:07.671958Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                              id        item_id    dept_id   cat_id store_id  \\\n0  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n1  HOBBIES_1_002_CA_1_evaluation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n2  HOBBIES_1_003_CA_1_evaluation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n3  HOBBIES_1_004_CA_1_evaluation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n4  HOBBIES_1_005_CA_1_evaluation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n\n  state_id    d  sales       date  wm_yr_wk  ... wday  month  year  \\\n0       CA  d_1      0 2011-01-29     11101  ...    1      1  2011   \n1       CA  d_1      0 2011-01-29     11101  ...    1      1  2011   \n2       CA  d_1      0 2011-01-29     11101  ...    1      1  2011   \n3       CA  d_1      0 2011-01-29     11101  ...    1      1  2011   \n4       CA  d_1      0 2011-01-29     11101  ...    1      1  2011   \n\n   event_name_1  event_type_1  event_name_2  event_type_2  snap_CA  snap_TX  \\\n0            30             4             4             2        0        0   \n1            30             4             4             2        0        0   \n2            30             4             4             2        0        0   \n3            30             4             4             2        0        0   \n4            30             4             4             2        0        0   \n\n   snap_WI  \n0        0  \n1        0  \n2        0  \n3        0  \n4        0  \n\n[5 rows x 21 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>item_id</th>\n      <th>dept_id</th>\n      <th>cat_id</th>\n      <th>store_id</th>\n      <th>state_id</th>\n      <th>d</th>\n      <th>sales</th>\n      <th>date</th>\n      <th>wm_yr_wk</th>\n      <th>...</th>\n      <th>wday</th>\n      <th>month</th>\n      <th>year</th>\n      <th>event_name_1</th>\n      <th>event_type_1</th>\n      <th>event_name_2</th>\n      <th>event_type_2</th>\n      <th>snap_CA</th>\n      <th>snap_TX</th>\n      <th>snap_WI</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HOBBIES_1_001_CA_1_evaluation</td>\n      <td>HOBBIES_1_001</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1</td>\n      <td>0</td>\n      <td>2011-01-29</td>\n      <td>11101</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2011</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HOBBIES_1_002_CA_1_evaluation</td>\n      <td>HOBBIES_1_002</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1</td>\n      <td>0</td>\n      <td>2011-01-29</td>\n      <td>11101</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2011</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HOBBIES_1_003_CA_1_evaluation</td>\n      <td>HOBBIES_1_003</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1</td>\n      <td>0</td>\n      <td>2011-01-29</td>\n      <td>11101</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2011</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>HOBBIES_1_004_CA_1_evaluation</td>\n      <td>HOBBIES_1_004</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1</td>\n      <td>0</td>\n      <td>2011-01-29</td>\n      <td>11101</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2011</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HOBBIES_1_005_CA_1_evaluation</td>\n      <td>HOBBIES_1_005</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1</td>\n      <td>0</td>\n      <td>2011-01-29</td>\n      <td>11101</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2011</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 21 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Merge with Price data","metadata":{}},{"cell_type":"code","source":"sales_train_evaluation_long = sales_train_evaluation_long.merge(\n    sell_prices, \n    on=[\"store_id\", \"item_id\", \"wm_yr_wk\"], \n    how=\"left\"\n)\nsales_train_evaluation_long.head()","metadata":{"execution":{"iopub.status.busy":"2024-11-08T04:38:07.676153Z","iopub.execute_input":"2024-11-08T04:38:07.677869Z","iopub.status.idle":"2024-11-08T04:38:26.068879Z","shell.execute_reply.started":"2024-11-08T04:38:07.677792Z","shell.execute_reply":"2024-11-08T04:38:26.067768Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                              id        item_id    dept_id   cat_id store_id  \\\n0  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n1  HOBBIES_1_002_CA_1_evaluation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n2  HOBBIES_1_003_CA_1_evaluation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n3  HOBBIES_1_004_CA_1_evaluation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n4  HOBBIES_1_005_CA_1_evaluation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n\n  state_id    d  sales       date  wm_yr_wk  ... month  year  event_name_1  \\\n0       CA  d_1      0 2011-01-29     11101  ...     1  2011            30   \n1       CA  d_1      0 2011-01-29     11101  ...     1  2011            30   \n2       CA  d_1      0 2011-01-29     11101  ...     1  2011            30   \n3       CA  d_1      0 2011-01-29     11101  ...     1  2011            30   \n4       CA  d_1      0 2011-01-29     11101  ...     1  2011            30   \n\n   event_type_1  event_name_2  event_type_2  snap_CA  snap_TX  snap_WI  \\\n0             4             4             2        0        0        0   \n1             4             4             2        0        0        0   \n2             4             4             2        0        0        0   \n3             4             4             2        0        0        0   \n4             4             4             2        0        0        0   \n\n   sell_price  \n0         NaN  \n1         NaN  \n2         NaN  \n3         NaN  \n4         NaN  \n\n[5 rows x 22 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>item_id</th>\n      <th>dept_id</th>\n      <th>cat_id</th>\n      <th>store_id</th>\n      <th>state_id</th>\n      <th>d</th>\n      <th>sales</th>\n      <th>date</th>\n      <th>wm_yr_wk</th>\n      <th>...</th>\n      <th>month</th>\n      <th>year</th>\n      <th>event_name_1</th>\n      <th>event_type_1</th>\n      <th>event_name_2</th>\n      <th>event_type_2</th>\n      <th>snap_CA</th>\n      <th>snap_TX</th>\n      <th>snap_WI</th>\n      <th>sell_price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HOBBIES_1_001_CA_1_evaluation</td>\n      <td>HOBBIES_1_001</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1</td>\n      <td>0</td>\n      <td>2011-01-29</td>\n      <td>11101</td>\n      <td>...</td>\n      <td>1</td>\n      <td>2011</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HOBBIES_1_002_CA_1_evaluation</td>\n      <td>HOBBIES_1_002</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1</td>\n      <td>0</td>\n      <td>2011-01-29</td>\n      <td>11101</td>\n      <td>...</td>\n      <td>1</td>\n      <td>2011</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HOBBIES_1_003_CA_1_evaluation</td>\n      <td>HOBBIES_1_003</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1</td>\n      <td>0</td>\n      <td>2011-01-29</td>\n      <td>11101</td>\n      <td>...</td>\n      <td>1</td>\n      <td>2011</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>HOBBIES_1_004_CA_1_evaluation</td>\n      <td>HOBBIES_1_004</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1</td>\n      <td>0</td>\n      <td>2011-01-29</td>\n      <td>11101</td>\n      <td>...</td>\n      <td>1</td>\n      <td>2011</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HOBBIES_1_005_CA_1_evaluation</td>\n      <td>HOBBIES_1_005</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1</td>\n      <td>0</td>\n      <td>2011-01-29</td>\n      <td>11101</td>\n      <td>...</td>\n      <td>1</td>\n      <td>2011</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 22 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Define Train, Validation and Evaluation sets","metadata":{}},{"cell_type":"code","source":"train_set = sales_train_evaluation_long[sales_train_evaluation_long['d'].isin([f'd_{i}' for i in range(1500, 1914)])]\nprint(\"Train set sample:\")\nprint(f\"len(Train set): {len(train_set)}\")\ntrain_set.head()","metadata":{"execution":{"iopub.status.busy":"2024-11-08T04:38:26.070401Z","iopub.execute_input":"2024-11-08T04:38:26.070793Z","iopub.status.idle":"2024-11-08T04:38:30.683307Z","shell.execute_reply.started":"2024-11-08T04:38:26.070751Z","shell.execute_reply":"2024-11-08T04:38:30.681981Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Train set sample:\nlen(Train set): 12622860\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"                                     id        item_id    dept_id   cat_id  \\\n45704510  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES   \n45704511  HOBBIES_1_002_CA_1_evaluation  HOBBIES_1_002  HOBBIES_1  HOBBIES   \n45704512  HOBBIES_1_003_CA_1_evaluation  HOBBIES_1_003  HOBBIES_1  HOBBIES   \n45704513  HOBBIES_1_004_CA_1_evaluation  HOBBIES_1_004  HOBBIES_1  HOBBIES   \n45704514  HOBBIES_1_005_CA_1_evaluation  HOBBIES_1_005  HOBBIES_1  HOBBIES   \n\n         store_id state_id       d  sales       date  wm_yr_wk  ... month  \\\n45704510     CA_1       CA  d_1500      0 2015-03-08     11506  ...     3   \n45704511     CA_1       CA  d_1500      0 2015-03-08     11506  ...     3   \n45704512     CA_1       CA  d_1500      0 2015-03-08     11506  ...     3   \n45704513     CA_1       CA  d_1500     10 2015-03-08     11506  ...     3   \n45704514     CA_1       CA  d_1500      2 2015-03-08     11506  ...     3   \n\n          year  event_name_1  event_type_1  event_name_2  event_type_2  \\\n45704510  2015            30             4             4             2   \n45704511  2015            30             4             4             2   \n45704512  2015            30             4             4             2   \n45704513  2015            30             4             4             2   \n45704514  2015            30             4             4             2   \n\n          snap_CA  snap_TX  snap_WI  sell_price  \n45704510        1        0        1    8.257812  \n45704511        1        0        1    3.970703  \n45704512        1        0        1    2.970703  \n45704513        1        0        1    4.640625  \n45704514        1        0        1    2.880859  \n\n[5 rows x 22 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>item_id</th>\n      <th>dept_id</th>\n      <th>cat_id</th>\n      <th>store_id</th>\n      <th>state_id</th>\n      <th>d</th>\n      <th>sales</th>\n      <th>date</th>\n      <th>wm_yr_wk</th>\n      <th>...</th>\n      <th>month</th>\n      <th>year</th>\n      <th>event_name_1</th>\n      <th>event_type_1</th>\n      <th>event_name_2</th>\n      <th>event_type_2</th>\n      <th>snap_CA</th>\n      <th>snap_TX</th>\n      <th>snap_WI</th>\n      <th>sell_price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>45704510</th>\n      <td>HOBBIES_1_001_CA_1_evaluation</td>\n      <td>HOBBIES_1_001</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1500</td>\n      <td>0</td>\n      <td>2015-03-08</td>\n      <td>11506</td>\n      <td>...</td>\n      <td>3</td>\n      <td>2015</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>8.257812</td>\n    </tr>\n    <tr>\n      <th>45704511</th>\n      <td>HOBBIES_1_002_CA_1_evaluation</td>\n      <td>HOBBIES_1_002</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1500</td>\n      <td>0</td>\n      <td>2015-03-08</td>\n      <td>11506</td>\n      <td>...</td>\n      <td>3</td>\n      <td>2015</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3.970703</td>\n    </tr>\n    <tr>\n      <th>45704512</th>\n      <td>HOBBIES_1_003_CA_1_evaluation</td>\n      <td>HOBBIES_1_003</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1500</td>\n      <td>0</td>\n      <td>2015-03-08</td>\n      <td>11506</td>\n      <td>...</td>\n      <td>3</td>\n      <td>2015</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2.970703</td>\n    </tr>\n    <tr>\n      <th>45704513</th>\n      <td>HOBBIES_1_004_CA_1_evaluation</td>\n      <td>HOBBIES_1_004</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1500</td>\n      <td>10</td>\n      <td>2015-03-08</td>\n      <td>11506</td>\n      <td>...</td>\n      <td>3</td>\n      <td>2015</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4.640625</td>\n    </tr>\n    <tr>\n      <th>45704514</th>\n      <td>HOBBIES_1_005_CA_1_evaluation</td>\n      <td>HOBBIES_1_005</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1500</td>\n      <td>2</td>\n      <td>2015-03-08</td>\n      <td>11506</td>\n      <td>...</td>\n      <td>3</td>\n      <td>2015</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2.880859</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 22 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Filter the validation set for d_1914 to d_1941\nvalidation_set = sales_train_evaluation_long[sales_train_evaluation_long['d'].isin([f'd_{i}' for i in range(1914, 1942)])]\nprint(\"Validation set sample:\")\nprint(f\"len(Validation set): {len(validation_set)}\")\nvalidation_set.head()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-08T04:38:30.684857Z","iopub.execute_input":"2024-11-08T04:38:30.685237Z","iopub.status.idle":"2024-11-08T04:38:34.004332Z","shell.execute_reply.started":"2024-11-08T04:38:30.685197Z","shell.execute_reply":"2024-11-08T04:38:34.003005Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Validation set sample:\nlen(Validation set): 853720\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                                     id        item_id    dept_id   cat_id  \\\n58327370  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES   \n58327371  HOBBIES_1_002_CA_1_evaluation  HOBBIES_1_002  HOBBIES_1  HOBBIES   \n58327372  HOBBIES_1_003_CA_1_evaluation  HOBBIES_1_003  HOBBIES_1  HOBBIES   \n58327373  HOBBIES_1_004_CA_1_evaluation  HOBBIES_1_004  HOBBIES_1  HOBBIES   \n58327374  HOBBIES_1_005_CA_1_evaluation  HOBBIES_1_005  HOBBIES_1  HOBBIES   \n\n         store_id state_id       d  sales       date  wm_yr_wk  ... month  \\\n58327370     CA_1       CA  d_1914      0 2016-04-25     11613  ...     4   \n58327371     CA_1       CA  d_1914      0 2016-04-25     11613  ...     4   \n58327372     CA_1       CA  d_1914      0 2016-04-25     11613  ...     4   \n58327373     CA_1       CA  d_1914      0 2016-04-25     11613  ...     4   \n58327374     CA_1       CA  d_1914      1 2016-04-25     11613  ...     4   \n\n          year  event_name_1  event_type_1  event_name_2  event_type_2  \\\n58327370  2016            30             4             4             2   \n58327371  2016            30             4             4             2   \n58327372  2016            30             4             4             2   \n58327373  2016            30             4             4             2   \n58327374  2016            30             4             4             2   \n\n          snap_CA  snap_TX  snap_WI  sell_price  \n58327370        0        0        0    8.382812  \n58327371        0        0        0    3.970703  \n58327372        0        0        0    2.970703  \n58327373        0        0        0    4.640625  \n58327374        0        0        0    2.880859  \n\n[5 rows x 22 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>item_id</th>\n      <th>dept_id</th>\n      <th>cat_id</th>\n      <th>store_id</th>\n      <th>state_id</th>\n      <th>d</th>\n      <th>sales</th>\n      <th>date</th>\n      <th>wm_yr_wk</th>\n      <th>...</th>\n      <th>month</th>\n      <th>year</th>\n      <th>event_name_1</th>\n      <th>event_type_1</th>\n      <th>event_name_2</th>\n      <th>event_type_2</th>\n      <th>snap_CA</th>\n      <th>snap_TX</th>\n      <th>snap_WI</th>\n      <th>sell_price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>58327370</th>\n      <td>HOBBIES_1_001_CA_1_evaluation</td>\n      <td>HOBBIES_1_001</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1914</td>\n      <td>0</td>\n      <td>2016-04-25</td>\n      <td>11613</td>\n      <td>...</td>\n      <td>4</td>\n      <td>2016</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.382812</td>\n    </tr>\n    <tr>\n      <th>58327371</th>\n      <td>HOBBIES_1_002_CA_1_evaluation</td>\n      <td>HOBBIES_1_002</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1914</td>\n      <td>0</td>\n      <td>2016-04-25</td>\n      <td>11613</td>\n      <td>...</td>\n      <td>4</td>\n      <td>2016</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3.970703</td>\n    </tr>\n    <tr>\n      <th>58327372</th>\n      <td>HOBBIES_1_003_CA_1_evaluation</td>\n      <td>HOBBIES_1_003</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1914</td>\n      <td>0</td>\n      <td>2016-04-25</td>\n      <td>11613</td>\n      <td>...</td>\n      <td>4</td>\n      <td>2016</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.970703</td>\n    </tr>\n    <tr>\n      <th>58327373</th>\n      <td>HOBBIES_1_004_CA_1_evaluation</td>\n      <td>HOBBIES_1_004</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1914</td>\n      <td>0</td>\n      <td>2016-04-25</td>\n      <td>11613</td>\n      <td>...</td>\n      <td>4</td>\n      <td>2016</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4.640625</td>\n    </tr>\n    <tr>\n      <th>58327374</th>\n      <td>HOBBIES_1_005_CA_1_evaluation</td>\n      <td>HOBBIES_1_005</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1914</td>\n      <td>1</td>\n      <td>2016-04-25</td>\n      <td>11613</td>\n      <td>...</td>\n      <td>4</td>\n      <td>2016</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.880859</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 22 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Create a new DataFrame for the prediction period (d_1942 to d_1969)\nforecast_days = [f'd_{i}' for i in range(1942, 1970)]\nforecast_df = pd.DataFrame({'d': forecast_days})\n\n# Generate one entry per product-store combination for each forecast day\nprediction_set = sales_train_evaluation[['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id']].drop_duplicates()\nprediction_set = prediction_set.merge(forecast_df, how='cross')\n\n# Merge with calendar data to add date information for the forecast period\nprediction_set = prediction_set.merge(calendar, on='d', how='left')\n\n# Merge with sell_prices to add price data, aligning with the correct store, item, and week\nprediction_set = prediction_set.merge(sell_prices, on=['store_id', 'item_id', 'wm_yr_wk'], how='left')\n\nprint(\"Prediction set sample:\")\nprint(f\"len(Prediction set): {len(prediction_set)}\")\nprediction_set.head()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-08T04:38:34.010133Z","iopub.execute_input":"2024-11-08T04:38:34.010635Z","iopub.status.idle":"2024-11-08T04:38:36.205837Z","shell.execute_reply.started":"2024-11-08T04:38:34.010587Z","shell.execute_reply":"2024-11-08T04:38:36.204453Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Prediction set sample:\nlen(Prediction set): 853720\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"                              id        item_id    dept_id   cat_id store_id  \\\n0  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n1  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n2  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n3  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n4  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n\n  state_id       d       date  wm_yr_wk    weekday  ...  month  year  \\\n0       CA  d_1942 2016-05-23     11617     Monday  ...      5  2016   \n1       CA  d_1943 2016-05-24     11617    Tuesday  ...      5  2016   \n2       CA  d_1944 2016-05-25     11617  Wednesday  ...      5  2016   \n3       CA  d_1945 2016-05-26     11617   Thursday  ...      5  2016   \n4       CA  d_1946 2016-05-27     11617     Friday  ...      5  2016   \n\n   event_name_1  event_type_1  event_name_2  event_type_2  snap_CA  snap_TX  \\\n0            30             4             4             2        0        0   \n1            30             4             4             2        0        0   \n2            30             4             4             2        0        0   \n3            30             4             4             2        0        0   \n4            30             4             4             2        0        0   \n\n   snap_WI  sell_price  \n0        0    8.382812  \n1        0    8.382812  \n2        0    8.382812  \n3        0    8.382812  \n4        0    8.382812  \n\n[5 rows x 21 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>item_id</th>\n      <th>dept_id</th>\n      <th>cat_id</th>\n      <th>store_id</th>\n      <th>state_id</th>\n      <th>d</th>\n      <th>date</th>\n      <th>wm_yr_wk</th>\n      <th>weekday</th>\n      <th>...</th>\n      <th>month</th>\n      <th>year</th>\n      <th>event_name_1</th>\n      <th>event_type_1</th>\n      <th>event_name_2</th>\n      <th>event_type_2</th>\n      <th>snap_CA</th>\n      <th>snap_TX</th>\n      <th>snap_WI</th>\n      <th>sell_price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HOBBIES_1_001_CA_1_evaluation</td>\n      <td>HOBBIES_1_001</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1942</td>\n      <td>2016-05-23</td>\n      <td>11617</td>\n      <td>Monday</td>\n      <td>...</td>\n      <td>5</td>\n      <td>2016</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.382812</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HOBBIES_1_001_CA_1_evaluation</td>\n      <td>HOBBIES_1_001</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1943</td>\n      <td>2016-05-24</td>\n      <td>11617</td>\n      <td>Tuesday</td>\n      <td>...</td>\n      <td>5</td>\n      <td>2016</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.382812</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HOBBIES_1_001_CA_1_evaluation</td>\n      <td>HOBBIES_1_001</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1944</td>\n      <td>2016-05-25</td>\n      <td>11617</td>\n      <td>Wednesday</td>\n      <td>...</td>\n      <td>5</td>\n      <td>2016</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.382812</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>HOBBIES_1_001_CA_1_evaluation</td>\n      <td>HOBBIES_1_001</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1945</td>\n      <td>2016-05-26</td>\n      <td>11617</td>\n      <td>Thursday</td>\n      <td>...</td>\n      <td>5</td>\n      <td>2016</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.382812</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HOBBIES_1_001_CA_1_evaluation</td>\n      <td>HOBBIES_1_001</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1946</td>\n      <td>2016-05-27</td>\n      <td>11617</td>\n      <td>Friday</td>\n      <td>...</td>\n      <td>5</td>\n      <td>2016</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.382812</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 21 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Apply the optimized memory reduction function to each dataframe\ntrain_set = reduce_mem_usage(train_set)\nvalidation_set = reduce_mem_usage(validation_set)\nprediction_set = reduce_mem_usage(prediction_set)","metadata":{"execution":{"iopub.status.busy":"2024-11-08T04:38:36.207392Z","iopub.execute_input":"2024-11-08T04:38:36.207784Z","iopub.status.idle":"2024-11-08T04:38:38.309738Z","shell.execute_reply.started":"2024-11-08T04:38:36.207743Z","shell.execute_reply":"2024-11-08T04:38:38.308439Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Memory usage reduced to 531.02 Mb (43.5% reduction)\nMemory usage reduced to 36.34 Mb (44.0% reduction)\nMemory usage reduced to 28.20 Mb (50.3% reduction)\n","output_type":"stream"}]},{"cell_type":"code","source":"train_set","metadata":{"execution":{"iopub.status.busy":"2024-11-08T04:38:38.311491Z","iopub.execute_input":"2024-11-08T04:38:38.311914Z","iopub.status.idle":"2024-11-08T04:38:40.15847Z","shell.execute_reply.started":"2024-11-08T04:38:38.311869Z","shell.execute_reply":"2024-11-08T04:38:40.157101Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"                                     id        item_id    dept_id   cat_id  \\\n45704510  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES   \n45704511  HOBBIES_1_002_CA_1_evaluation  HOBBIES_1_002  HOBBIES_1  HOBBIES   \n45704512  HOBBIES_1_003_CA_1_evaluation  HOBBIES_1_003  HOBBIES_1  HOBBIES   \n45704513  HOBBIES_1_004_CA_1_evaluation  HOBBIES_1_004  HOBBIES_1  HOBBIES   \n45704514  HOBBIES_1_005_CA_1_evaluation  HOBBIES_1_005  HOBBIES_1  HOBBIES   \n...                                 ...            ...        ...      ...   \n58327365    FOODS_3_823_WI_3_evaluation    FOODS_3_823    FOODS_3    FOODS   \n58327366    FOODS_3_824_WI_3_evaluation    FOODS_3_824    FOODS_3    FOODS   \n58327367    FOODS_3_825_WI_3_evaluation    FOODS_3_825    FOODS_3    FOODS   \n58327368    FOODS_3_826_WI_3_evaluation    FOODS_3_826    FOODS_3    FOODS   \n58327369    FOODS_3_827_WI_3_evaluation    FOODS_3_827    FOODS_3    FOODS   \n\n         store_id state_id       d  sales       date  wm_yr_wk  ... month  \\\n45704510     CA_1       CA  d_1500      0 2015-03-08     11506  ...     3   \n45704511     CA_1       CA  d_1500      0 2015-03-08     11506  ...     3   \n45704512     CA_1       CA  d_1500      0 2015-03-08     11506  ...     3   \n45704513     CA_1       CA  d_1500     10 2015-03-08     11506  ...     3   \n45704514     CA_1       CA  d_1500      2 2015-03-08     11506  ...     3   \n...           ...      ...     ...    ...        ...       ...  ...   ...   \n58327365     WI_3       WI  d_1913      1 2016-04-24     11613  ...     4   \n58327366     WI_3       WI  d_1913      0 2016-04-24     11613  ...     4   \n58327367     WI_3       WI  d_1913      0 2016-04-24     11613  ...     4   \n58327368     WI_3       WI  d_1913      3 2016-04-24     11613  ...     4   \n58327369     WI_3       WI  d_1913      0 2016-04-24     11613  ...     4   \n\n          year  event_name_1  event_type_1  event_name_2  event_type_2  \\\n45704510  2015            30             4             4             2   \n45704511  2015            30             4             4             2   \n45704512  2015            30             4             4             2   \n45704513  2015            30             4             4             2   \n45704514  2015            30             4             4             2   \n...        ...           ...           ...           ...           ...   \n58327365  2016            30             4             4             2   \n58327366  2016            30             4             4             2   \n58327367  2016            30             4             4             2   \n58327368  2016            30             4             4             2   \n58327369  2016            30             4             4             2   \n\n          snap_CA  snap_TX  snap_WI  sell_price  \n45704510        1        0        1    8.257812  \n45704511        1        0        1    3.970703  \n45704512        1        0        1    2.970703  \n45704513        1        0        1    4.640625  \n45704514        1        0        1    2.880859  \n...           ...      ...      ...         ...  \n58327365        0        0        0    2.980469  \n58327366        0        0        0    2.480469  \n58327367        0        0        0    3.980469  \n58327368        0        0        0    1.280273  \n58327369        0        0        0    1.000000  \n\n[12622860 rows x 22 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>item_id</th>\n      <th>dept_id</th>\n      <th>cat_id</th>\n      <th>store_id</th>\n      <th>state_id</th>\n      <th>d</th>\n      <th>sales</th>\n      <th>date</th>\n      <th>wm_yr_wk</th>\n      <th>...</th>\n      <th>month</th>\n      <th>year</th>\n      <th>event_name_1</th>\n      <th>event_type_1</th>\n      <th>event_name_2</th>\n      <th>event_type_2</th>\n      <th>snap_CA</th>\n      <th>snap_TX</th>\n      <th>snap_WI</th>\n      <th>sell_price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>45704510</th>\n      <td>HOBBIES_1_001_CA_1_evaluation</td>\n      <td>HOBBIES_1_001</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1500</td>\n      <td>0</td>\n      <td>2015-03-08</td>\n      <td>11506</td>\n      <td>...</td>\n      <td>3</td>\n      <td>2015</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>8.257812</td>\n    </tr>\n    <tr>\n      <th>45704511</th>\n      <td>HOBBIES_1_002_CA_1_evaluation</td>\n      <td>HOBBIES_1_002</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1500</td>\n      <td>0</td>\n      <td>2015-03-08</td>\n      <td>11506</td>\n      <td>...</td>\n      <td>3</td>\n      <td>2015</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3.970703</td>\n    </tr>\n    <tr>\n      <th>45704512</th>\n      <td>HOBBIES_1_003_CA_1_evaluation</td>\n      <td>HOBBIES_1_003</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1500</td>\n      <td>0</td>\n      <td>2015-03-08</td>\n      <td>11506</td>\n      <td>...</td>\n      <td>3</td>\n      <td>2015</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2.970703</td>\n    </tr>\n    <tr>\n      <th>45704513</th>\n      <td>HOBBIES_1_004_CA_1_evaluation</td>\n      <td>HOBBIES_1_004</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1500</td>\n      <td>10</td>\n      <td>2015-03-08</td>\n      <td>11506</td>\n      <td>...</td>\n      <td>3</td>\n      <td>2015</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4.640625</td>\n    </tr>\n    <tr>\n      <th>45704514</th>\n      <td>HOBBIES_1_005_CA_1_evaluation</td>\n      <td>HOBBIES_1_005</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1500</td>\n      <td>2</td>\n      <td>2015-03-08</td>\n      <td>11506</td>\n      <td>...</td>\n      <td>3</td>\n      <td>2015</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2.880859</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>58327365</th>\n      <td>FOODS_3_823_WI_3_evaluation</td>\n      <td>FOODS_3_823</td>\n      <td>FOODS_3</td>\n      <td>FOODS</td>\n      <td>WI_3</td>\n      <td>WI</td>\n      <td>d_1913</td>\n      <td>1</td>\n      <td>2016-04-24</td>\n      <td>11613</td>\n      <td>...</td>\n      <td>4</td>\n      <td>2016</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.980469</td>\n    </tr>\n    <tr>\n      <th>58327366</th>\n      <td>FOODS_3_824_WI_3_evaluation</td>\n      <td>FOODS_3_824</td>\n      <td>FOODS_3</td>\n      <td>FOODS</td>\n      <td>WI_3</td>\n      <td>WI</td>\n      <td>d_1913</td>\n      <td>0</td>\n      <td>2016-04-24</td>\n      <td>11613</td>\n      <td>...</td>\n      <td>4</td>\n      <td>2016</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.480469</td>\n    </tr>\n    <tr>\n      <th>58327367</th>\n      <td>FOODS_3_825_WI_3_evaluation</td>\n      <td>FOODS_3_825</td>\n      <td>FOODS_3</td>\n      <td>FOODS</td>\n      <td>WI_3</td>\n      <td>WI</td>\n      <td>d_1913</td>\n      <td>0</td>\n      <td>2016-04-24</td>\n      <td>11613</td>\n      <td>...</td>\n      <td>4</td>\n      <td>2016</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3.980469</td>\n    </tr>\n    <tr>\n      <th>58327368</th>\n      <td>FOODS_3_826_WI_3_evaluation</td>\n      <td>FOODS_3_826</td>\n      <td>FOODS_3</td>\n      <td>FOODS</td>\n      <td>WI_3</td>\n      <td>WI</td>\n      <td>d_1913</td>\n      <td>3</td>\n      <td>2016-04-24</td>\n      <td>11613</td>\n      <td>...</td>\n      <td>4</td>\n      <td>2016</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.280273</td>\n    </tr>\n    <tr>\n      <th>58327369</th>\n      <td>FOODS_3_827_WI_3_evaluation</td>\n      <td>FOODS_3_827</td>\n      <td>FOODS_3</td>\n      <td>FOODS</td>\n      <td>WI_3</td>\n      <td>WI</td>\n      <td>d_1913</td>\n      <td>0</td>\n      <td>2016-04-24</td>\n      <td>11613</td>\n      <td>...</td>\n      <td>4</td>\n      <td>2016</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>12622860 rows × 22 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"validation_set","metadata":{"execution":{"iopub.status.busy":"2024-11-08T04:38:40.160127Z","iopub.execute_input":"2024-11-08T04:38:40.160745Z","iopub.status.idle":"2024-11-08T04:38:40.29094Z","shell.execute_reply.started":"2024-11-08T04:38:40.160688Z","shell.execute_reply":"2024-11-08T04:38:40.2896Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"                                     id        item_id    dept_id   cat_id  \\\n58327370  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES   \n58327371  HOBBIES_1_002_CA_1_evaluation  HOBBIES_1_002  HOBBIES_1  HOBBIES   \n58327372  HOBBIES_1_003_CA_1_evaluation  HOBBIES_1_003  HOBBIES_1  HOBBIES   \n58327373  HOBBIES_1_004_CA_1_evaluation  HOBBIES_1_004  HOBBIES_1  HOBBIES   \n58327374  HOBBIES_1_005_CA_1_evaluation  HOBBIES_1_005  HOBBIES_1  HOBBIES   \n...                                 ...            ...        ...      ...   \n59181085    FOODS_3_823_WI_3_evaluation    FOODS_3_823    FOODS_3    FOODS   \n59181086    FOODS_3_824_WI_3_evaluation    FOODS_3_824    FOODS_3    FOODS   \n59181087    FOODS_3_825_WI_3_evaluation    FOODS_3_825    FOODS_3    FOODS   \n59181088    FOODS_3_826_WI_3_evaluation    FOODS_3_826    FOODS_3    FOODS   \n59181089    FOODS_3_827_WI_3_evaluation    FOODS_3_827    FOODS_3    FOODS   \n\n         store_id state_id       d  sales       date  wm_yr_wk  ... month  \\\n58327370     CA_1       CA  d_1914      0 2016-04-25     11613  ...     4   \n58327371     CA_1       CA  d_1914      0 2016-04-25     11613  ...     4   \n58327372     CA_1       CA  d_1914      0 2016-04-25     11613  ...     4   \n58327373     CA_1       CA  d_1914      0 2016-04-25     11613  ...     4   \n58327374     CA_1       CA  d_1914      1 2016-04-25     11613  ...     4   \n...           ...      ...     ...    ...        ...       ...  ...   ...   \n59181085     WI_3       WI  d_1941      1 2016-05-22     11617  ...     5   \n59181086     WI_3       WI  d_1941      0 2016-05-22     11617  ...     5   \n59181087     WI_3       WI  d_1941      2 2016-05-22     11617  ...     5   \n59181088     WI_3       WI  d_1941      0 2016-05-22     11617  ...     5   \n59181089     WI_3       WI  d_1941      1 2016-05-22     11617  ...     5   \n\n          year  event_name_1  event_type_1  event_name_2  event_type_2  \\\n58327370  2016            30             4             4             2   \n58327371  2016            30             4             4             2   \n58327372  2016            30             4             4             2   \n58327373  2016            30             4             4             2   \n58327374  2016            30             4             4             2   \n...        ...           ...           ...           ...           ...   \n59181085  2016            30             4             4             2   \n59181086  2016            30             4             4             2   \n59181087  2016            30             4             4             2   \n59181088  2016            30             4             4             2   \n59181089  2016            30             4             4             2   \n\n          snap_CA  snap_TX  snap_WI  sell_price  \n58327370        0        0        0    8.382812  \n58327371        0        0        0    3.970703  \n58327372        0        0        0    2.970703  \n58327373        0        0        0    4.640625  \n58327374        0        0        0    2.880859  \n...           ...      ...      ...         ...  \n59181085        0        0        0    2.980469  \n59181086        0        0        0    2.480469  \n59181087        0        0        0    3.980469  \n59181088        0        0        0    1.280273  \n59181089        0        0        0    1.000000  \n\n[853720 rows x 22 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>item_id</th>\n      <th>dept_id</th>\n      <th>cat_id</th>\n      <th>store_id</th>\n      <th>state_id</th>\n      <th>d</th>\n      <th>sales</th>\n      <th>date</th>\n      <th>wm_yr_wk</th>\n      <th>...</th>\n      <th>month</th>\n      <th>year</th>\n      <th>event_name_1</th>\n      <th>event_type_1</th>\n      <th>event_name_2</th>\n      <th>event_type_2</th>\n      <th>snap_CA</th>\n      <th>snap_TX</th>\n      <th>snap_WI</th>\n      <th>sell_price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>58327370</th>\n      <td>HOBBIES_1_001_CA_1_evaluation</td>\n      <td>HOBBIES_1_001</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1914</td>\n      <td>0</td>\n      <td>2016-04-25</td>\n      <td>11613</td>\n      <td>...</td>\n      <td>4</td>\n      <td>2016</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.382812</td>\n    </tr>\n    <tr>\n      <th>58327371</th>\n      <td>HOBBIES_1_002_CA_1_evaluation</td>\n      <td>HOBBIES_1_002</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1914</td>\n      <td>0</td>\n      <td>2016-04-25</td>\n      <td>11613</td>\n      <td>...</td>\n      <td>4</td>\n      <td>2016</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3.970703</td>\n    </tr>\n    <tr>\n      <th>58327372</th>\n      <td>HOBBIES_1_003_CA_1_evaluation</td>\n      <td>HOBBIES_1_003</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1914</td>\n      <td>0</td>\n      <td>2016-04-25</td>\n      <td>11613</td>\n      <td>...</td>\n      <td>4</td>\n      <td>2016</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.970703</td>\n    </tr>\n    <tr>\n      <th>58327373</th>\n      <td>HOBBIES_1_004_CA_1_evaluation</td>\n      <td>HOBBIES_1_004</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1914</td>\n      <td>0</td>\n      <td>2016-04-25</td>\n      <td>11613</td>\n      <td>...</td>\n      <td>4</td>\n      <td>2016</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4.640625</td>\n    </tr>\n    <tr>\n      <th>58327374</th>\n      <td>HOBBIES_1_005_CA_1_evaluation</td>\n      <td>HOBBIES_1_005</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1914</td>\n      <td>1</td>\n      <td>2016-04-25</td>\n      <td>11613</td>\n      <td>...</td>\n      <td>4</td>\n      <td>2016</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.880859</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>59181085</th>\n      <td>FOODS_3_823_WI_3_evaluation</td>\n      <td>FOODS_3_823</td>\n      <td>FOODS_3</td>\n      <td>FOODS</td>\n      <td>WI_3</td>\n      <td>WI</td>\n      <td>d_1941</td>\n      <td>1</td>\n      <td>2016-05-22</td>\n      <td>11617</td>\n      <td>...</td>\n      <td>5</td>\n      <td>2016</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.980469</td>\n    </tr>\n    <tr>\n      <th>59181086</th>\n      <td>FOODS_3_824_WI_3_evaluation</td>\n      <td>FOODS_3_824</td>\n      <td>FOODS_3</td>\n      <td>FOODS</td>\n      <td>WI_3</td>\n      <td>WI</td>\n      <td>d_1941</td>\n      <td>0</td>\n      <td>2016-05-22</td>\n      <td>11617</td>\n      <td>...</td>\n      <td>5</td>\n      <td>2016</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.480469</td>\n    </tr>\n    <tr>\n      <th>59181087</th>\n      <td>FOODS_3_825_WI_3_evaluation</td>\n      <td>FOODS_3_825</td>\n      <td>FOODS_3</td>\n      <td>FOODS</td>\n      <td>WI_3</td>\n      <td>WI</td>\n      <td>d_1941</td>\n      <td>2</td>\n      <td>2016-05-22</td>\n      <td>11617</td>\n      <td>...</td>\n      <td>5</td>\n      <td>2016</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3.980469</td>\n    </tr>\n    <tr>\n      <th>59181088</th>\n      <td>FOODS_3_826_WI_3_evaluation</td>\n      <td>FOODS_3_826</td>\n      <td>FOODS_3</td>\n      <td>FOODS</td>\n      <td>WI_3</td>\n      <td>WI</td>\n      <td>d_1941</td>\n      <td>0</td>\n      <td>2016-05-22</td>\n      <td>11617</td>\n      <td>...</td>\n      <td>5</td>\n      <td>2016</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.280273</td>\n    </tr>\n    <tr>\n      <th>59181089</th>\n      <td>FOODS_3_827_WI_3_evaluation</td>\n      <td>FOODS_3_827</td>\n      <td>FOODS_3</td>\n      <td>FOODS</td>\n      <td>WI_3</td>\n      <td>WI</td>\n      <td>d_1941</td>\n      <td>1</td>\n      <td>2016-05-22</td>\n      <td>11617</td>\n      <td>...</td>\n      <td>5</td>\n      <td>2016</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>853720 rows × 22 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"prediction_set","metadata":{"execution":{"iopub.status.busy":"2024-11-08T04:38:40.292754Z","iopub.execute_input":"2024-11-08T04:38:40.293182Z","iopub.status.idle":"2024-11-08T04:38:40.403122Z","shell.execute_reply.started":"2024-11-08T04:38:40.293139Z","shell.execute_reply":"2024-11-08T04:38:40.401679Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"                                   id        item_id    dept_id   cat_id  \\\n0       HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES   \n1       HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES   \n2       HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES   \n3       HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES   \n4       HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES   \n...                               ...            ...        ...      ...   \n853715    FOODS_3_827_WI_3_evaluation    FOODS_3_827    FOODS_3    FOODS   \n853716    FOODS_3_827_WI_3_evaluation    FOODS_3_827    FOODS_3    FOODS   \n853717    FOODS_3_827_WI_3_evaluation    FOODS_3_827    FOODS_3    FOODS   \n853718    FOODS_3_827_WI_3_evaluation    FOODS_3_827    FOODS_3    FOODS   \n853719    FOODS_3_827_WI_3_evaluation    FOODS_3_827    FOODS_3    FOODS   \n\n       store_id state_id       d       date  wm_yr_wk    weekday  ...  month  \\\n0          CA_1       CA  d_1942 2016-05-23     11617     Monday  ...      5   \n1          CA_1       CA  d_1943 2016-05-24     11617    Tuesday  ...      5   \n2          CA_1       CA  d_1944 2016-05-25     11617  Wednesday  ...      5   \n3          CA_1       CA  d_1945 2016-05-26     11617   Thursday  ...      5   \n4          CA_1       CA  d_1946 2016-05-27     11617     Friday  ...      5   \n...         ...      ...     ...        ...       ...        ...  ...    ...   \n853715     WI_3       WI  d_1965 2016-06-15     11620  Wednesday  ...      6   \n853716     WI_3       WI  d_1966 2016-06-16     11620   Thursday  ...      6   \n853717     WI_3       WI  d_1967 2016-06-17     11620     Friday  ...      6   \n853718     WI_3       WI  d_1968 2016-06-18     11621   Saturday  ...      6   \n853719     WI_3       WI  d_1969 2016-06-19     11621     Sunday  ...      6   \n\n        year  event_name_1  event_type_1  event_name_2  event_type_2  snap_CA  \\\n0       2016            30             4             4             2        0   \n1       2016            30             4             4             2        0   \n2       2016            30             4             4             2        0   \n3       2016            30             4             4             2        0   \n4       2016            30             4             4             2        0   \n...      ...           ...           ...           ...           ...      ...   \n853715  2016            30             4             4             2        0   \n853716  2016            30             4             4             2        0   \n853717  2016            30             4             4             2        0   \n853718  2016            30             4             4             2        0   \n853719  2016            16             3             2             0        0   \n\n        snap_TX  snap_WI  sell_price  \n0             0        0    8.382812  \n1             0        0    8.382812  \n2             0        0    8.382812  \n3             0        0    8.382812  \n4             0        0    8.382812  \n...         ...      ...         ...  \n853715        1        1    1.000000  \n853716        0        0    1.000000  \n853717        0        0    1.000000  \n853718        0        0    1.000000  \n853719        0        0    1.000000  \n\n[853720 rows x 21 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>item_id</th>\n      <th>dept_id</th>\n      <th>cat_id</th>\n      <th>store_id</th>\n      <th>state_id</th>\n      <th>d</th>\n      <th>date</th>\n      <th>wm_yr_wk</th>\n      <th>weekday</th>\n      <th>...</th>\n      <th>month</th>\n      <th>year</th>\n      <th>event_name_1</th>\n      <th>event_type_1</th>\n      <th>event_name_2</th>\n      <th>event_type_2</th>\n      <th>snap_CA</th>\n      <th>snap_TX</th>\n      <th>snap_WI</th>\n      <th>sell_price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HOBBIES_1_001_CA_1_evaluation</td>\n      <td>HOBBIES_1_001</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1942</td>\n      <td>2016-05-23</td>\n      <td>11617</td>\n      <td>Monday</td>\n      <td>...</td>\n      <td>5</td>\n      <td>2016</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.382812</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HOBBIES_1_001_CA_1_evaluation</td>\n      <td>HOBBIES_1_001</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1943</td>\n      <td>2016-05-24</td>\n      <td>11617</td>\n      <td>Tuesday</td>\n      <td>...</td>\n      <td>5</td>\n      <td>2016</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.382812</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HOBBIES_1_001_CA_1_evaluation</td>\n      <td>HOBBIES_1_001</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1944</td>\n      <td>2016-05-25</td>\n      <td>11617</td>\n      <td>Wednesday</td>\n      <td>...</td>\n      <td>5</td>\n      <td>2016</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.382812</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>HOBBIES_1_001_CA_1_evaluation</td>\n      <td>HOBBIES_1_001</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1945</td>\n      <td>2016-05-26</td>\n      <td>11617</td>\n      <td>Thursday</td>\n      <td>...</td>\n      <td>5</td>\n      <td>2016</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.382812</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HOBBIES_1_001_CA_1_evaluation</td>\n      <td>HOBBIES_1_001</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1946</td>\n      <td>2016-05-27</td>\n      <td>11617</td>\n      <td>Friday</td>\n      <td>...</td>\n      <td>5</td>\n      <td>2016</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.382812</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>853715</th>\n      <td>FOODS_3_827_WI_3_evaluation</td>\n      <td>FOODS_3_827</td>\n      <td>FOODS_3</td>\n      <td>FOODS</td>\n      <td>WI_3</td>\n      <td>WI</td>\n      <td>d_1965</td>\n      <td>2016-06-15</td>\n      <td>11620</td>\n      <td>Wednesday</td>\n      <td>...</td>\n      <td>6</td>\n      <td>2016</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>853716</th>\n      <td>FOODS_3_827_WI_3_evaluation</td>\n      <td>FOODS_3_827</td>\n      <td>FOODS_3</td>\n      <td>FOODS</td>\n      <td>WI_3</td>\n      <td>WI</td>\n      <td>d_1966</td>\n      <td>2016-06-16</td>\n      <td>11620</td>\n      <td>Thursday</td>\n      <td>...</td>\n      <td>6</td>\n      <td>2016</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>853717</th>\n      <td>FOODS_3_827_WI_3_evaluation</td>\n      <td>FOODS_3_827</td>\n      <td>FOODS_3</td>\n      <td>FOODS</td>\n      <td>WI_3</td>\n      <td>WI</td>\n      <td>d_1967</td>\n      <td>2016-06-17</td>\n      <td>11620</td>\n      <td>Friday</td>\n      <td>...</td>\n      <td>6</td>\n      <td>2016</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>853718</th>\n      <td>FOODS_3_827_WI_3_evaluation</td>\n      <td>FOODS_3_827</td>\n      <td>FOODS_3</td>\n      <td>FOODS</td>\n      <td>WI_3</td>\n      <td>WI</td>\n      <td>d_1968</td>\n      <td>2016-06-18</td>\n      <td>11621</td>\n      <td>Saturday</td>\n      <td>...</td>\n      <td>6</td>\n      <td>2016</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>853719</th>\n      <td>FOODS_3_827_WI_3_evaluation</td>\n      <td>FOODS_3_827</td>\n      <td>FOODS_3</td>\n      <td>FOODS</td>\n      <td>WI_3</td>\n      <td>WI</td>\n      <td>d_1969</td>\n      <td>2016-06-19</td>\n      <td>11621</td>\n      <td>Sunday</td>\n      <td>...</td>\n      <td>6</td>\n      <td>2016</td>\n      <td>16</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>853720 rows × 21 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Transform train_set into AutoGluon's TimeSeriesDataFrame","metadata":{}},{"cell_type":"code","source":"train_set.info()","metadata":{"execution":{"iopub.status.busy":"2024-11-08T04:38:40.405439Z","iopub.execute_input":"2024-11-08T04:38:40.40608Z","iopub.status.idle":"2024-11-08T04:38:40.446311Z","shell.execute_reply.started":"2024-11-08T04:38:40.406032Z","shell.execute_reply":"2024-11-08T04:38:40.445047Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 12622860 entries, 45704510 to 58327369\nData columns (total 22 columns):\n #   Column        Dtype         \n---  ------        -----         \n 0   id            category      \n 1   item_id       category      \n 2   dept_id       category      \n 3   cat_id        category      \n 4   store_id      category      \n 5   state_id      category      \n 6   d             category      \n 7   sales         int16         \n 8   date          datetime64[ns]\n 9   wm_yr_wk      int16         \n 10  weekday       category      \n 11  wday          int8          \n 12  month         int8          \n 13  year          int16         \n 14  event_name_1  int8          \n 15  event_type_1  int8          \n 16  event_name_2  int8          \n 17  event_type_2  int8          \n 18  snap_CA       int8          \n 19  snap_TX       int8          \n 20  snap_WI       int8          \n 21  sell_price    float16       \ndtypes: category(8), datetime64[ns](1), float16(1), int16(3), int8(9)\nmemory usage: 531.0 MB\n","output_type":"stream"}]},{"cell_type":"code","source":"# Step 1: Convert the 'date' column to datetime format\ntrain_set['date'] = pd.to_datetime(train_set['date'])\n\n# Step 2: Select only the relevant columns for AutoGluon, including target and covariates\ncovariate_columns = ['dept_id', 'store_id','sales', 'wday', 'snap_CA', 'snap_TX', 'snap_WI', 'sell_price', \n                     'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']\ntrain_set_for_autogluon = train_set[['id', 'date'] + covariate_columns].copy()\n\n# Step 3: Sort the DataFrame by 'id' and 'date' to ensure correct order\ntrain_set_for_autogluon = train_set_for_autogluon.sort_values(by=['id', 'date'])\n\n# Step 4: Convert to AutoGluon TimeSeriesDataFrame format, specifying id_column and timestamp_column\ntrain_set_for_autogluon = TimeSeriesDataFrame.from_data_frame(\n    df=train_set_for_autogluon,\n    id_column='id',\n    timestamp_column='date'\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-08T04:38:40.448071Z","iopub.execute_input":"2024-11-08T04:38:40.448603Z","iopub.status.idle":"2024-11-08T04:38:45.027483Z","shell.execute_reply.started":"2024-11-08T04:38:40.448547Z","shell.execute_reply":"2024-11-08T04:38:45.026178Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"train_set_for_autogluon = reduce_mem_usage(train_set_for_autogluon)","metadata":{"execution":{"iopub.status.busy":"2024-11-08T04:38:45.029123Z","iopub.execute_input":"2024-11-08T04:38:45.029553Z","iopub.status.idle":"2024-11-08T04:38:45.317289Z","shell.execute_reply.started":"2024-11-08T04:38:45.029509Z","shell.execute_reply":"2024-11-08T04:38:45.316014Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Memory usage reduced to 218.00 Mb (0.0% reduction)\n","output_type":"stream"}]},{"cell_type":"code","source":"train_set_for_autogluon","metadata":{"execution":{"iopub.status.busy":"2024-11-08T04:38:45.319268Z","iopub.execute_input":"2024-11-08T04:38:45.319708Z","iopub.status.idle":"2024-11-08T04:38:45.347805Z","shell.execute_reply.started":"2024-11-08T04:38:45.319664Z","shell.execute_reply":"2024-11-08T04:38:45.34628Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"                                                dept_id store_id  sales  wday  \\\nitem_id                         timestamp                                       \nFOODS_1_001_CA_1_evaluation     2015-03-08      FOODS_1     CA_1      1     2   \n                                2015-03-09      FOODS_1     CA_1      0     3   \n                                2015-03-10      FOODS_1     CA_1      1     4   \n                                2015-03-11      FOODS_1     CA_1      0     5   \n                                2015-03-12      FOODS_1     CA_1      1     6   \n...                                                 ...      ...    ...   ...   \nHOUSEHOLD_2_516_WI_3_evaluation 2016-04-20  HOUSEHOLD_2     WI_3      0     5   \n                                2016-04-21  HOUSEHOLD_2     WI_3      0     6   \n                                2016-04-22  HOUSEHOLD_2     WI_3      0     7   \n                                2016-04-23  HOUSEHOLD_2     WI_3      0     1   \n                                2016-04-24  HOUSEHOLD_2     WI_3      0     2   \n\n                                            snap_CA  snap_TX  snap_WI  \\\nitem_id                         timestamp                               \nFOODS_1_001_CA_1_evaluation     2015-03-08        1        0        1   \n                                2015-03-09        1        1        1   \n                                2015-03-10        1        0        0   \n                                2015-03-11        0        1        1   \n                                2015-03-12        0        1        1   \n...                                             ...      ...      ...   \nHOUSEHOLD_2_516_WI_3_evaluation 2016-04-20        0        0        0   \n                                2016-04-21        0        0        0   \n                                2016-04-22        0        0        0   \n                                2016-04-23        0        0        0   \n                                2016-04-24        0        0        0   \n\n                                            sell_price  event_name_1  \\\nitem_id                         timestamp                              \nFOODS_1_001_CA_1_evaluation     2015-03-08    2.240234            30   \n                                2015-03-09    2.240234            30   \n                                2015-03-10    2.240234            30   \n                                2015-03-11    2.240234            30   \n                                2015-03-12    2.240234            30   \n...                                                ...           ...   \nHOUSEHOLD_2_516_WI_3_evaluation 2016-04-20    5.941406            30   \n                                2016-04-21    5.941406            30   \n                                2016-04-22    5.941406            30   \n                                2016-04-23    5.941406            30   \n                                2016-04-24    5.941406            30   \n\n                                            event_type_1  event_name_2  \\\nitem_id                         timestamp                                \nFOODS_1_001_CA_1_evaluation     2015-03-08             4             4   \n                                2015-03-09             4             4   \n                                2015-03-10             4             4   \n                                2015-03-11             4             4   \n                                2015-03-12             4             4   \n...                                                  ...           ...   \nHOUSEHOLD_2_516_WI_3_evaluation 2016-04-20             4             4   \n                                2016-04-21             4             4   \n                                2016-04-22             4             4   \n                                2016-04-23             4             4   \n                                2016-04-24             4             4   \n\n                                            event_type_2  \nitem_id                         timestamp                 \nFOODS_1_001_CA_1_evaluation     2015-03-08             2  \n                                2015-03-09             2  \n                                2015-03-10             2  \n                                2015-03-11             2  \n                                2015-03-12             2  \n...                                                  ...  \nHOUSEHOLD_2_516_WI_3_evaluation 2016-04-20             2  \n                                2016-04-21             2  \n                                2016-04-22             2  \n                                2016-04-23             2  \n                                2016-04-24             2  \n\n[12622860 rows x 12 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>dept_id</th>\n      <th>store_id</th>\n      <th>sales</th>\n      <th>wday</th>\n      <th>snap_CA</th>\n      <th>snap_TX</th>\n      <th>snap_WI</th>\n      <th>sell_price</th>\n      <th>event_name_1</th>\n      <th>event_type_1</th>\n      <th>event_name_2</th>\n      <th>event_type_2</th>\n    </tr>\n    <tr>\n      <th>item_id</th>\n      <th>timestamp</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">FOODS_1_001_CA_1_evaluation</th>\n      <th>2015-03-08</th>\n      <td>FOODS_1</td>\n      <td>CA_1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2.240234</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2015-03-09</th>\n      <td>FOODS_1</td>\n      <td>CA_1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2.240234</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2015-03-10</th>\n      <td>FOODS_1</td>\n      <td>CA_1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.240234</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2015-03-11</th>\n      <td>FOODS_1</td>\n      <td>CA_1</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2.240234</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2015-03-12</th>\n      <td>FOODS_1</td>\n      <td>CA_1</td>\n      <td>1</td>\n      <td>6</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2.240234</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">HOUSEHOLD_2_516_WI_3_evaluation</th>\n      <th>2016-04-20</th>\n      <td>HOUSEHOLD_2</td>\n      <td>WI_3</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5.941406</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2016-04-21</th>\n      <td>HOUSEHOLD_2</td>\n      <td>WI_3</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5.941406</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2016-04-22</th>\n      <td>HOUSEHOLD_2</td>\n      <td>WI_3</td>\n      <td>0</td>\n      <td>7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5.941406</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2016-04-23</th>\n      <td>HOUSEHOLD_2</td>\n      <td>WI_3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5.941406</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2016-04-24</th>\n      <td>HOUSEHOLD_2</td>\n      <td>WI_3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5.941406</td>\n      <td>30</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>12622860 rows × 12 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Check for missing values in each column of the DataFrame\nmissing_values = train_set_for_autogluon.isna().sum()\n\n# Filter to show only columns with missing values\nmissing_values = missing_values[missing_values > 0]\n\n# Display the missing values\nprint(\"Missing values in each column:\")\nprint(missing_values)","metadata":{"execution":{"iopub.status.busy":"2024-11-08T04:38:45.349442Z","iopub.execute_input":"2024-11-08T04:38:45.349881Z","iopub.status.idle":"2024-11-08T04:38:45.527854Z","shell.execute_reply.started":"2024-11-08T04:38:45.349835Z","shell.execute_reply":"2024-11-08T04:38:45.526426Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Missing values in each column:\nsell_price    55736\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# TimeSeriesPredictor","metadata":{}},{"cell_type":"code","source":"# Step 1: Initialize the TimeSeriesPredictor with a primary eval_metric\npredictor = TimeSeriesPredictor(\n    prediction_length=28,\n    target=\"sales\",\n    known_covariates_names=['dept_id', 'store_id','wday', 'snap_CA', 'snap_TX', 'snap_WI', 'sell_price', 'event_name_1','event_type_1','event_name_2', 'event_type_2'] ,\n    eval_metric=\"RMSSE\"  # Primary metric for training\n)\n\n# Step 2: Fit the predictor with all models in the model zoo using default hyperparameters\npredictor.fit(\n    train_data=train_set_for_autogluon,\n    presets=\"high_quality\",\n    excluded_model_types=[\n        'AutoARIMA','Chronos[base]', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST'\n                         ]  \n)","metadata":{"execution":{"iopub.status.busy":"2024-11-08T04:38:45.529529Z","iopub.execute_input":"2024-11-08T04:38:45.52995Z","iopub.status.idle":"2024-11-08T09:24:55.7631Z","shell.execute_reply.started":"2024-11-08T04:38:45.529907Z","shell.execute_reply":"2024-11-08T09:24:55.759359Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"No path specified. Models will be saved in: \"AutogluonModels/ag-20241108_043845\"\nBeginning AutoGluon training...\nAutoGluon will save models to 'AutogluonModels/ag-20241108_043845'\n=================== System Info ===================\nAutoGluon Version:  1.1.1\nPython Version:     3.10.14\nOperating System:   Linux\nPlatform Machine:   x86_64\nPlatform Version:   #1 SMP Thu Jun 27 20:43:36 UTC 2024\nCPU Count:          4\nGPU Count:          0\nMemory Avail:       18.87 GB / 31.36 GB (60.2%)\nDisk Space Avail:   19.50 GB / 19.52 GB (99.9%)\n===================================================\nSetting presets to: high_quality\n\nFitting with arguments:\n{'enable_ensemble': True,\n 'eval_metric': RMSSE,\n 'hyperparameters': 'default',\n 'known_covariates_names': ['dept_id',\n                            'store_id',\n                            'wday',\n                            'snap_CA',\n                            'snap_TX',\n                            'snap_WI',\n                            'sell_price',\n                            'event_name_1',\n                            'event_type_1',\n                            'event_name_2',\n                            'event_type_2'],\n 'num_val_windows': 1,\n 'prediction_length': 28,\n 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n 'random_seed': 123,\n 'refit_every_n_windows': 1,\n 'refit_full': False,\n 'skip_model_selection': False,\n 'target': 'sales',\n 'verbosity': 2}\n\nInferred time series frequency: 'D'\nProvided train_data has 12622860 rows, 30490 time series. Median time series length is 414 (min=414, max=414). \n\nProvided data contains following columns:\n\ttarget: 'sales'\n\tknown_covariates:\n\t\tcategorical:        ['dept_id', 'store_id']\n\t\tcontinuous (float): ['wday', 'snap_CA', 'snap_TX', 'snap_WI', 'sell_price', 'event_name_1', ...]\n\nTo learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n\nAutoGluon will gauge predictive performance using evaluation metric: 'RMSSE'\n\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n===================================================\n\nStarting training. Start time is 2024-11-08 04:39:11\nModels that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'CrostonSBA', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'AutoARIMA', 'Chronos[base]', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST']\nTraining timeseries model SeasonalNaive. \n\t-1.2474       = Validation score (-RMSSE)\n\t25.76   s     = Training runtime\n\t61.53   s     = Validation (prediction) runtime\nTraining timeseries model RecursiveTabular. \n\t-1.0195       = Validation score (-RMSSE)\n\t998.34  s     = Training runtime\n\t95.82   s     = Validation (prediction) runtime\nTraining timeseries model DirectTabular. \n\t-1.0006       = Validation score (-RMSSE)\n\t100.50  s     = Training runtime\n\t56.56   s     = Validation (prediction) runtime\nTraining timeseries model CrostonSBA. \n\t-1.0267       = Validation score (-RMSSE)\n\t22.28   s     = Training runtime\n\t81.18   s     = Validation (prediction) runtime\nTraining timeseries model NPTS. \n\t-1.0231       = Validation score (-RMSSE)\n\t21.91   s     = Training runtime\n\t2219.35 s     = Validation (prediction) runtime\nTraining timeseries model DynamicOptimizedTheta. \n\t-1.0073       = Validation score (-RMSSE)\n\t29.89   s     = Training runtime\n\t1074.57 s     = Validation (prediction) runtime\nTraining timeseries model AutoETS. \n\t-1.0273       = Validation score (-RMSSE)\n\t31.19   s     = Training runtime\n\t1871.47 s     = Validation (prediction) runtime\nTraining timeseries model AutoARIMA. \n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[24], line 10\u001b[0m\n\u001b[1;32m      2\u001b[0m predictor \u001b[38;5;241m=\u001b[39m TimeSeriesPredictor(\n\u001b[1;32m      3\u001b[0m     prediction_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m28\u001b[39m,\n\u001b[1;32m      4\u001b[0m     target\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msales\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     known_covariates_names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdept_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstore_id\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwday\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msnap_CA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msnap_TX\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msnap_WI\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msell_price\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent_name_1\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent_type_1\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent_name_2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent_type_2\u001b[39m\u001b[38;5;124m'\u001b[39m] ,\n\u001b[1;32m      6\u001b[0m     eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRMSSE\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Primary metric for training\u001b[39;00m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Step 2: Fit the predictor with all models in the model zoo using default hyperparameters\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set_for_autogluon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpresets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhigh_quality\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/autogluon/core/utils/decorators.py:31\u001b[0m, in \u001b[0;36munpack.<locals>._unpack_inner.<locals>._call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     30\u001b[0m     gargs, gkwargs \u001b[38;5;241m=\u001b[39m g(\u001b[38;5;241m*\u001b[39mother_args, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/autogluon/timeseries/predictor.py:742\u001b[0m, in \u001b[0;36mTimeSeriesPredictor.fit\u001b[0;34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, hyperparameter_tune_kwargs, excluded_model_types, num_val_windows, val_step_size, refit_every_n_windows, refit_full, enable_ensemble, skip_model_selection, random_seed, verbosity)\u001b[0m\n\u001b[1;32m    737\u001b[0m val_splitter \u001b[38;5;241m=\u001b[39m ExpandingWindowSplitter(\n\u001b[1;32m    738\u001b[0m     prediction_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_length, num_val_windows\u001b[38;5;241m=\u001b[39mnum_val_windows, val_step_size\u001b[38;5;241m=\u001b[39mval_step_size\n\u001b[1;32m    739\u001b[0m )\n\u001b[1;32m    741\u001b[0m time_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m time_limit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m time_limit \u001b[38;5;241m-\u001b[39m (time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m time_start)\n\u001b[0;32m--> 742\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_learner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    744\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtuning_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    745\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhyperparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhyperparameter_tune_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhyperparameter_tune_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexcluded_model_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexcluded_model_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_left\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_splitter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_splitter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrefit_every_n_windows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefit_every_n_windows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_model_selection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_model_selection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    753\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_ensemble\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_ensemble\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    755\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m refit_full:\n\u001b[1;32m    757\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tuning_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/autogluon/timeseries/learner.py:64\u001b[0m, in \u001b[0;36mTimeSeriesLearner.fit\u001b[0;34m(self, train_data, val_data, hyperparameters, hyperparameter_tune_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     58\u001b[0m     train_data: TimeSeriesDataFrame,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m     63\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhyperparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhyperparameter_tune_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhyperparameter_tune_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/autogluon/timeseries/learner.py:123\u001b[0m, in \u001b[0;36mTimeSeriesLearner._fit\u001b[0;34m(self, train_data, val_data, hyperparameters, hyperparameter_tune_kwargs, time_limit, val_splitter, refit_every_n_windows, random_seed, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    118\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mThis metric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    119\u001b[0m     )\n\u001b[1;32m    121\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m===================================================\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 123\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhyperparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhyperparameter_tune_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhyperparameter_tune_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexcluded_model_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexcluded_model_types\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time_fit_training \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m time_start\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/autogluon/timeseries/trainer/auto_trainer.py:67\u001b[0m, in \u001b[0;36mAutoTimeSeriesTrainer.fit\u001b[0;34m(self, train_data, hyperparameters, val_data, hyperparameter_tune_kwargs, excluded_model_types, time_limit, random_seed)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     36\u001b[0m     train_data: TimeSeriesDataFrame,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m     random_seed: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     43\u001b[0m ):\n\u001b[1;32m     44\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;124;03m    Fit a set of timeseries models specified by the `hyperparameters`\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03m    dictionary that maps model names to their specified hyperparameters.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m        Random seed that will be set to each model during training\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_multi\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhyperparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhyperparameter_tune_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhyperparameter_tune_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexcluded_model_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexcluded_model_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/autogluon/timeseries/trainer/abstract_trainer.py:644\u001b[0m, in \u001b[0;36mAbstractTimeSeriesTrainer._train_multi\u001b[0;34m(self, train_data, hyperparameters, models, val_data, hyperparameter_tune_kwargs, excluded_model_types, time_limit, random_seed)\u001b[0m\n\u001b[1;32m    640\u001b[0m             fit_log_message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    641\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining for up to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime_left_for_model\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms of the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime_left\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms of remaining time.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    642\u001b[0m             )\n\u001b[1;32m    643\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(fit_log_message)\n\u001b[0;32m--> 644\u001b[0m         model_names_trained \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_and_save\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_left_for_model\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable_ensemble:\n\u001b[1;32m    649\u001b[0m     models_available_for_ensemble \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_model_names(level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/autogluon/timeseries/trainer/abstract_trainer.py:516\u001b[0m, in \u001b[0;36mAbstractTimeSeriesTrainer._train_and_save\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    513\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mSkipping \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m due to lack of time remaining.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m model_names_trained\n\u001b[0;32m--> 516\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_limit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    517\u001b[0m fit_end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    518\u001b[0m model\u001b[38;5;241m.\u001b[39mfit_time \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit_time \u001b[38;5;129;01mor\u001b[39;00m (fit_end_time \u001b[38;5;241m-\u001b[39m fit_start_time)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/autogluon/timeseries/trainer/abstract_trainer.py:432\u001b[0m, in \u001b[0;36mAbstractTimeSeriesTrainer._train_single\u001b[0;34m(self, train_data, model, val_data, time_limit)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_train_single\u001b[39m(\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    425\u001b[0m     train_data: TimeSeriesDataFrame,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    428\u001b[0m     time_limit: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    429\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AbstractTimeSeriesModel:\n\u001b[1;32m    430\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train the single model and return the model object that was fitted. This method\u001b[39;00m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;124;03m    does not save the resulting model.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 432\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_splitter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_splitter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrefit_every_n_windows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrefit_every_n_windows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/autogluon/timeseries/models/abstract/abstract_timeseries_model.py:247\u001b[0m, in \u001b[0;36mAbstractTimeSeriesModel.fit\u001b[0;34m(self, train_data, val_data, **kwargs)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcan_use_val_data\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m val_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    246\u001b[0m     val_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(val_data, is_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 247\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py:856\u001b[0m, in \u001b[0;36mAbstractModel.fit\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate_fit_resources(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    855\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_fit_memory_usage(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 856\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    858\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/autogluon/timeseries/models/multi_window/multi_window_model.py:139\u001b[0m, in \u001b[0;36mMultiWindowBacktestingModel._fit\u001b[0;34m(self, train_data, val_data, time_limit, val_splitter, refit_every_n_windows, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m model_fit_start_time\n\u001b[1;32m    138\u001b[0m     most_recent_refit_window \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwindow_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 139\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore_and_cache_oof\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore_val_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore_predict_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m oof_predictions_per_window\u001b[38;5;241m.\u001b[39mappend(model\u001b[38;5;241m.\u001b[39mget_oof_predictions()[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    143\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mval_score\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m<7.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mljust(\u001b[38;5;241m15\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m= Validation score (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39meval_metric\u001b[38;5;241m.\u001b[39mname_with_sign\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    145\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/autogluon/timeseries/models/local/abstract_local_model.py:180\u001b[0m, in \u001b[0;36mAbstractLocalModel.score_and_cache_oof\u001b[0;34m(self, val_data, store_val_score, store_predict_time, **predict_kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscore_and_cache_oof\u001b[39m(\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    174\u001b[0m     val_data: TimeSeriesDataFrame,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;66;03m# All computation happens during inference, so we provide the time_limit at prediction time\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore_and_cache_oof\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore_val_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore_predict_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime_limit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpredict_kwargs\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/autogluon/timeseries/models/abstract/abstract_timeseries_model.py:383\u001b[0m, in \u001b[0;36mAbstractTimeSeriesModel.score_and_cache_oof\u001b[0;34m(self, val_data, store_val_score, store_predict_time, **predict_kwargs)\u001b[0m\n\u001b[1;32m    379\u001b[0m past_data, known_covariates \u001b[38;5;241m=\u001b[39m val_data\u001b[38;5;241m.\u001b[39mget_model_inputs_for_scoring(\n\u001b[1;32m    380\u001b[0m     prediction_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_length, known_covariates_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mknown_covariates\n\u001b[1;32m    381\u001b[0m )\n\u001b[1;32m    382\u001b[0m predict_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 383\u001b[0m oof_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpast_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mknown_covariates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mknown_covariates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpredict_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_oof_predictions \u001b[38;5;241m=\u001b[39m [oof_predictions]\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m store_predict_time:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/autogluon/timeseries/models/abstract/abstract_timeseries_model.py:304\u001b[0m, in \u001b[0;36mAbstractTimeSeriesModel.predict\u001b[0;34m(self, data, known_covariates, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(data, is_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    303\u001b[0m known_covariates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_known_covariates(known_covariates)\n\u001b[0;32m--> 304\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mknown_covariates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mknown_covariates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicting with model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    306\u001b[0m \u001b[38;5;66;03m# \"0.5\" might be missing from the quantiles if self is a wrapper (MultiWindowBacktestingModel or ensemble)\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/autogluon/timeseries/models/local/abstract_local_model.py:155\u001b[0m, in \u001b[0;36mAbstractLocalModel._predict\u001b[0;34m(self, data, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m warning_filter():\n\u001b[0;32m--> 155\u001b[0m         predictions_with_flags \u001b[38;5;241m=\u001b[39m \u001b[43mexecutor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_wrapper\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_time\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mts\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mall_series\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m:\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m TimeLimitExceeded\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"# Predict for Validation set ","metadata":{}},{"cell_type":"code","source":"# Step 1: Ensure 'date' is in datetime format\nvalidation_set['date'] = pd.to_datetime(validation_set['date'])\n\n# Step 2: Select only the relevant columns, ensuring 'sales' is included and filled with NaN\ncovariate_columns = ['dept_id', 'store_id','sales', 'wday', 'snap_CA', 'snap_TX', 'snap_WI', 'sell_price', \n                     'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']\nvalidation_set_for_autogluon = validation_set[['id', 'date'] + covariate_columns].copy()\n\n# Step 3: Sort the DataFrame by 'id' and 'date' to ensure correct order\nvalidation_set_for_autogluon = validation_set_for_autogluon.sort_values(by=['id', 'date'])\n\n# Step 4: Convert to AutoGluon TimeSeriesDataFrame, specifying `id_column` and `timestamp_column`\nvalidation_set_for_autogluon = TimeSeriesDataFrame(\n    data=validation_set_for_autogluon,\n    id_column='id',\n    timestamp_column='date'\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-08T09:24:55.766088Z","iopub.status.idle":"2024-11-08T09:24:55.766762Z","shell.execute_reply.started":"2024-11-08T09:24:55.766463Z","shell.execute_reply":"2024-11-08T09:24:55.766495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_set_for_autogluon","metadata":{"execution":{"iopub.status.busy":"2024-11-08T09:24:55.769591Z","iopub.status.idle":"2024-11-08T09:24:55.770112Z","shell.execute_reply.started":"2024-11-08T09:24:55.769872Z","shell.execute_reply":"2024-11-08T09:24:55.769895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Step 5: Make predictions using the validation set as known covariates\n\n%time\nvalidation_preds = predictor.predict(train_set_for_autogluon, known_covariates=validation_set_for_autogluon)","metadata":{"execution":{"iopub.status.busy":"2024-11-08T09:24:55.77297Z","iopub.status.idle":"2024-11-08T09:24:55.774119Z","shell.execute_reply.started":"2024-11-08T09:24:55.773561Z","shell.execute_reply":"2024-11-08T09:24:55.77361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_preds","metadata":{"execution":{"iopub.status.busy":"2024-11-08T09:24:55.775872Z","iopub.status.idle":"2024-11-08T09:24:55.776605Z","shell.execute_reply.started":"2024-11-08T09:24:55.776227Z","shell.execute_reply":"2024-11-08T09:24:55.776259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_preds.info()","metadata":{"execution":{"iopub.status.busy":"2024-11-08T09:24:55.778575Z","iopub.status.idle":"2024-11-08T09:24:55.779504Z","shell.execute_reply.started":"2024-11-08T09:24:55.778936Z","shell.execute_reply":"2024-11-08T09:24:55.778974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_item_id = 'FOODS_3_586_TX_1_evaluation'","metadata":{"execution":{"iopub.status.busy":"2024-11-08T09:24:55.782195Z","iopub.status.idle":"2024-11-08T09:24:55.782992Z","shell.execute_reply.started":"2024-11-08T09:24:55.782597Z","shell.execute_reply":"2024-11-08T09:24:55.782636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictor.plot(\n    data=train_set_for_autogluon,\n    predictions=validation_preds,\n    item_ids=[target_item_id],\n    max_history_length=100  # Adjust as needed to display more or fewer historical points\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-08T09:24:55.78508Z","iopub.status.idle":"2024-11-08T09:24:55.785665Z","shell.execute_reply.started":"2024-11-08T09:24:55.785391Z","shell.execute_reply":"2024-11-08T09:24:55.785423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictor.plot(\n    data=validation_set_for_autogluon,\n    predictions=validation_preds,\n    item_ids=[target_item_id],\n    max_history_length=28 \n)","metadata":{"execution":{"iopub.status.busy":"2024-11-08T09:24:55.787488Z","iopub.status.idle":"2024-11-08T09:24:55.788261Z","shell.execute_reply.started":"2024-11-08T09:24:55.787953Z","shell.execute_reply":"2024-11-08T09:24:55.787988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Step 1: Extract the mean predictions\nmean_predictions = validation_preds['mean']\n\n# Step 2: Reshape the data\nmean_predictions = mean_predictions.reset_index()\nmean_predictions['forecast_day'] = mean_predictions.groupby('item_id').cumcount() + 1\nvalidation_df = mean_predictions.pivot(index='item_id', columns='forecast_day', values='mean').reset_index()\n\n# Step 3: Rename columns\nvalidation_df.columns = ['id'] + [f'F{i}' for i in range(1, 29)]\n\n# Step 4: Modify 'id' for submission\nvalidation_df['id'] = validation_df['id'].str.replace('evaluation', 'validation')\n","metadata":{"execution":{"iopub.status.busy":"2024-11-08T09:24:55.789912Z","iopub.status.idle":"2024-11-08T09:24:55.790478Z","shell.execute_reply.started":"2024-11-08T09:24:55.790198Z","shell.execute_reply":"2024-11-08T09:24:55.790224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_df","metadata":{"execution":{"iopub.status.busy":"2024-11-08T09:24:55.794301Z","iopub.status.idle":"2024-11-08T09:24:55.794904Z","shell.execute_reply.started":"2024-11-08T09:24:55.794622Z","shell.execute_reply":"2024-11-08T09:24:55.794646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict for Prediction set","metadata":{}},{"cell_type":"code","source":"# Step 1: Ensure 'date' is in datetime format\nprediction_set['date'] = pd.to_datetime(prediction_set['date'])\n\n# Step 2: Select only the relevant columns, ensuring 'sales' is included and filled with NaN\ncovariate_columns = ['dept_id', 'store_id', 'wday', 'snap_CA', 'snap_TX', 'snap_WI', 'sell_price', \n                     'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']\nprediction_set_for_autogluon = prediction_set[['id', 'date'] + covariate_columns].copy()\n\n# Step 4: Convert to AutoGluon TimeSeriesDataFrame, specifying `id_column` and `timestamp_column`\nprediction_set_for_autogluon = TimeSeriesDataFrame(\n    data=prediction_set_for_autogluon,\n    id_column='id',\n    timestamp_column='date'\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-08T09:24:55.79669Z","iopub.status.idle":"2024-11-08T09:24:55.797209Z","shell.execute_reply.started":"2024-11-08T09:24:55.796967Z","shell.execute_reply":"2024-11-08T09:24:55.796991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Concatenate the training and validation sets\ncombined_df = pd.concat([train_set_for_autogluon, validation_set_for_autogluon])\n\n# Convert the concatenated DataFrame back to a TimeSeriesDataFrame\ncombined_tsdf = TimeSeriesDataFrame(combined_df)","metadata":{"execution":{"iopub.status.busy":"2024-11-08T09:24:55.79993Z","iopub.status.idle":"2024-11-08T09:24:55.800564Z","shell.execute_reply.started":"2024-11-08T09:24:55.800242Z","shell.execute_reply":"2024-11-08T09:24:55.800269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%time\n# Step 4: Make predictions using the prediction set as known covariates\nprediction_preds = predictor.predict(combined_tsdf, known_covariates=prediction_set_for_autogluon)","metadata":{"execution":{"iopub.status.busy":"2024-11-08T09:24:55.802937Z","iopub.status.idle":"2024-11-08T09:24:55.803534Z","shell.execute_reply.started":"2024-11-08T09:24:55.803236Z","shell.execute_reply":"2024-11-08T09:24:55.803265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictor.plot(\n    data=combined_tsdf,\n    predictions=prediction_preds,\n    item_ids=[target_item_id],\n    max_history_length=100  # Adjust as needed to display more or fewer historical points\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-08T09:24:55.805772Z","iopub.status.idle":"2024-11-08T09:24:55.806315Z","shell.execute_reply.started":"2024-11-08T09:24:55.806061Z","shell.execute_reply":"2024-11-08T09:24:55.806085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Step 1: Extract the mean predictions\nmean_predictions1 = prediction_preds['mean']\n\n# Step 2: Reshape the data\nmean_predictions1 = mean_predictions1.reset_index()\nmean_predictions1['forecast_day'] = mean_predictions1.groupby('item_id').cumcount() + 1\nprediction_df = mean_predictions1.pivot(index='item_id', columns='forecast_day', values='mean').reset_index()\n\n# Step 3: Rename columns\nprediction_df.columns = ['id'] + [f'F{i}' for i in range(1, 29)]","metadata":{"execution":{"iopub.status.busy":"2024-11-08T09:24:55.808959Z","iopub.status.idle":"2024-11-08T09:24:55.809498Z","shell.execute_reply.started":"2024-11-08T09:24:55.809225Z","shell.execute_reply":"2024-11-08T09:24:55.809247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction_df","metadata":{"execution":{"iopub.status.busy":"2024-11-08T09:24:55.811085Z","iopub.status.idle":"2024-11-08T09:24:55.811629Z","shell.execute_reply.started":"2024-11-08T09:24:55.811376Z","shell.execute_reply":"2024-11-08T09:24:55.811403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# For Submission","metadata":{}},{"cell_type":"code","source":"# Combine validation and evaluation for submission\nsubmit = pd.concat([validation_df, prediction_df]).reset_index(drop=True)\nsubmit.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-11-08T09:24:55.813008Z","iopub.status.idle":"2024-11-08T09:24:55.813547Z","shell.execute_reply.started":"2024-11-08T09:24:55.813267Z","shell.execute_reply":"2024-11-08T09:24:55.813292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit.head(10)","metadata":{"execution":{"iopub.status.busy":"2024-11-08T09:24:55.817119Z","iopub.status.idle":"2024-11-08T09:24:55.817705Z","shell.execute_reply.started":"2024-11-08T09:24:55.817436Z","shell.execute_reply":"2024-11-08T09:24:55.817463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit.tail(10)","metadata":{"execution":{"iopub.status.busy":"2024-11-08T09:24:55.820293Z","iopub.status.idle":"2024-11-08T09:24:55.820862Z","shell.execute_reply.started":"2024-11-08T09:24:55.820604Z","shell.execute_reply":"2024-11-08T09:24:55.820629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}